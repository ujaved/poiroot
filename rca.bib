%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for choffnes at 2013-01-31 15:43:56 -0800 


%% Saved with string encoding Unicode (UTF-8) 

@inproceedings{loup,
	Author = {Nikola Gvozdiev and Brad Karp and Mark Handley},
        Title = {{LOUP}: The Principles and Practice of Intra-Domain Route Dissemination},
	Booktitle = {NSDI},
	Year = {2013}}

@article{labovitz-instability,
	Abstract = {This paper examines the network interdomain rout- ing information exchanged between backbone service providers at the major U.S. public Internet exchange points. Internet rout- ing instability, or the rapid fluctuation of network reachability information, is an important problem currently facing the In- ternet engineering community. High levels of network instability can lead to packet loss, increased network latency and time to convergence. At the extreme, high levels of routing instability have led to the loss of internal connectivity in wide-area, national networks. In this paper, we describe several unexpected trends in routing instability, and examine a number of anomalies and pathologies observed in the exchange of inter-domain routing information. The analysis in this paper is based on data collected from BGP routing messages generated by border routers at five of the Internet core's public exchange points during a nine month period. We show that the volume of these routing updates is several orders of magnitude more than expected and that the majority of this routing information is redundant, or pathological. Furthermore, our analysis reveals several unexpected trends and ill-behaved systematic properties in Internet routing. We finally posit a number of explanations for these anomalies and evaluate their potential impact on the Internet infrastructure.},
	Author = {Craig Labovitz and G. Robert Malan and Farnam Jahanian},
	Date-Added = {2011-10-19 16:15:58 -0700},
	Date-Modified = {2011-10-19 16:21:11 -0700},
	Journal = {IEEE/ACM TON},
	Keywords = {bgp,failures,monitoring,passive},
	Title = {{I}nternet Routing Instability},
	Year = {1998},
         volume = {6},
          number = {5},
              pages = {515--528}
}

@article{latlong,
title = {LatLong: Diagnosing Wide-Area Latency Changes for CDNs},
author  = {Yaping Zhu and Benjamin Helsley and Jennifer Rexford and Aspi Siganporia and Sridhar Srinivasan},
year  = 2012,
journal = {IEEE Transactions on Network and Service Management},
volume  = {9}
}

@misc{linden-amazon,
	Author = {Greg Linden},
	Date-Added = {2011-10-19 19:55:24 -0700},
	Date-Modified = {2011-10-19 20:11:53 -0700},
	Howpublished = {\url{http://sites.google.com/site/glinden/Home/StanfordDataMining.2006-11-28.ppt}},
	Title = {Make Data Useful},
	Year = {2006}}

@inproceedings{yahoo-slow,
	Annote = {400ms slower = 5-9% drop in full-page traffic (Yahoo).  Users leave before the page finishes loading

Yahoo! speaker},
	Author = {Stoyan Stefanov},
	Booktitle = {CSDN SD2C},
	Date-Added = {2011-10-19 21:45:27 -0700},
	Date-Modified = {2011-10-19 22:05:35 -0700},
	Title = {YSlow 2.0},
	Year = {2008}}

@article{oliveira09exploration,
	Acmid = {1552200},
	Address = {Piscataway, NJ, USA},
	Author = {Oliveira, Ricardo and Zhang, Beichuan and Pei, Dan and Zhang, Lixia},
	Doi = {10.1109/TNET.2009.2016390},
	Issn = {1063-6692},
	Issue_Date = {April 2009},
	Journal = {IEEE/ACM Trans. Netw.},
	Keywords = {AS topology completeness, border gateway protocol (BGP), inter-domain routing, internet topology},
	Number = {2},
	Numpages = {14},
	Pages = {445--458},
	Publisher = {IEEE Press},
	Title = {Quantifying path exploration in the internet},
	Url = {http://dx.doi.org/10.1109/TNET.2009.2016390},
	Volume = {17},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/TNET.2009.2016390}}

@inproceedings{teixeira04omni,
	Author = {Teixeira, Renata and Rexford, Jennifer},
	Booktitle = {ACM SIGCOMM Workshop on Network Troubleshooting},
	Title = {A measurement framework for pin-pointing routing changes},
	Year = {2004}}

@inproceedings{muhlbauer:quasi-router,
	Author = {M\"{u}hlbauer, Wolfgang and Feldmann, Anja and Maennel, Olaf and Roughan, Matthew and Uhlig, Steve},
	Booktitle = {{SIGCOMM}},
	Optacmid = {1159937},
	Optaddress = {New York, NY, USA},
	Optdoi = {10.1145/1159913.1159937},
	Optisbn = {1-59593-308-5},
	Optkeywords = {BGP, inter-domain routing, policies, route diversity, routing},
	Optlocation = {Pisa, Italy},
	Optnumpages = {12},
	Optpages = {195--206},
	Optpublisher = {ACM},
	Opturl = {http://doi.acm.org/10.1145/1159913.1159937},
	Title = {Building an {AS}-topology model that captures route diversity},
	Year = {2006}}

@misc{gill:nanog,
	Author = {Phillipa Gill and Sharon Goldberg and Michael Schapira},
	Howpublished = {{NANOG} 56},
	Note = {\url{http://www.nanog.org/meetings/nanog56/presentations/Monday/mon.general.gill.11.pdf}},
	Title = {A Survey of Interdomain Routing Policies},
	Year = {2012}}

@misc{bgpsec,
	Author = {Rob Austein and Steven Bellovin and Randy Bush and Russ Housley and Matt Lepinski and Stephen Kent and Warren Kumari and Doug Montgomery and Kotikalapudi Sriram and Samuel Weiler},
	Date-Added = {2011-10-28 20:34:27 -0700},
	Date-Modified = {2011-10-28 20:34:27 -0700},
	Howpublished = {http://tools.ietf.org/html/draft-ietf-sidr-bgpsec-protocol},
	Title = {{BGPSEC} Protocol}}

@misc{rpki-route-origin,
	Author = {Pradosh Mohapatra and John Scudder and David Ward and Randy Bush and Rob Austein},
	Date-Added = {2011-10-28 20:34:12 -0700},
	Date-Modified = {2011-10-28 20:34:12 -0700},
	Howpublished = {http://tools.ietf.org/html/draft-ietf-sidr-pfx-validate},
	Title = {{BGP} Prefix Origin Validation}}

@inproceedings{mach-hotnets,
	Author = {Ethan Katz-Bassett and David R. Choffnes and Colin Scott and Italo Cunha and Thomas Anderson and Arvind Krishnamurthy},
	Booktitle = {HotNets},
	Date-Added = {2011-10-28 19:10:54 -0700},
	Date-Modified = {2011-10-28 19:12:36 -0700},
	Title = {Machiavellian Routing: Improving {I}nternet Availability with {BGP} Poisoning},
	Year = {2011}}

@misc{communities,
	Annote = {Several tens of ASes have documented their support for this kind of [do not announce to a specified peer, at a specified
   interconnection point or to a given set of peers]
   community values [QB02]

 Many ASes utilize community values to
   indicate that a route should not be announced to a given AS or  at a
   given interconnection point. Some ASes also allow the utilization of
   such communities to indicate that a route should not be announced
   outside a given region or continent.

 Based on the content of the RIPE whois database in October 2001, many
   ISPs rely on remotely attached export communities to allow their
   customers to request the utilization of AS-Path prepending when
   announcing some routes to specified external peers, at specified
   interconnection points or  in specified regions [QB02].

The BGP Community attribute is a transitive optional attribute.  ASes
   that do not utilize BGP community values in their router's
   configurations usually do not change the content of the BGP community
   attribute of received UPDATE messages.

If the AS supports signalling community values, then it would
   typically configure its ingress filters to only allow those community
   values over  eBGP sessions with customers and remove such communities
   from UPDATE messages received over eBGP sessions with peers and
   providers. Since those community values have only a local meaning,
   they should be removed from the UPDATE messages sent to any external
   peer.

[QB02]  B. Quoitin and O. Bonaventure. A survey of the
     utilization of the BGP community attribute. Technical report
     Infonet-TR-2002-02,  http://www.infonet.fundp.ac.be/doc/tr/,
     March 2002.


In addition to these techniques, several ISPs have been using the communities attribute to give their customers a finer control
on the redistribution of their routes. 

 The redistribution communities can directly influence sources
located at two AS-hops away and indirectly sources at 3 or 4 AS hops},
	Author = {Bruno Quoitin and Olivier Bonaventure},
	Date-Added = {2011-09-30 04:22:26 -0700},
	Date-Modified = {2011-10-01 01:48:33 -0700},
	Howpublished = {{Internet draft, draft-quoitin-bgp-comm-survey-00}},
	Title = {A survey of the utilization of the {BGP} community attribute},
	Year = {2002}}

@article{redistribution-communities,
	Author = {Quoitin, B. and Tandel, S. and Uhlig, S. and Bonaventure, O},
	Date-Added = {2011-09-30 04:00:13 -0700},
	Date-Modified = {2011-10-01 01:48:20 -0700},
	Journal = {Computer Communications Journal},
	Title = {Interdomain traffic engineering with Redistribution Communities},
	Year = {2004}}

@misc{ponemon,
	Author = {{Ponemon Institute}},
	Note = {\url{http://www.emersonnetworkpower.com/en-US/Brands/Liebert/Documents/White\%20Papers/data-center-costs_24659-R02-11.pdf}},
	Title = {Calculating the Cost of Data Center Outages},
	Year = {2011}}

@misc{bgpmux-web,
	Date-Modified = {2011-07-21 12:22:17 -0700},
	Key = {TransitPortal},
	Note = {http://tp.gtnoise.net/},
	Title = {{Transit Portal}}}

@misc{pch,
	Date-Added = {2011-07-21 12:21:27 -0700},
	Date-Modified = {2011-07-21 12:22:17 -0700},
	Key = {PCH},
	Note = {http://www.pch.net/home/index.php},
	Title = {Packet Clearing House}}

@misc{abilene,
	Date-Added = {2011-07-21 12:21:27 -0700},
	Date-Modified = {2011-07-21 12:22:17 -0700},
	Key = {Abilene},
	Note = {http://www.internet2.edu/network/},
	Title = {Abilene Internet2 Network}}

@inproceedings{ono-sidewalk-ends,
	Author = {Kai Chen and David R. Choffnes and Rahul Potharaju and Yan Chen and Fabi{\'a}n E. Bustamante and Dan Pei and Yao Zhao},
	Booktitle = {CoNEXT},
	Date-Added = {2011-07-18 15:36:53 -0700},
	Date-Modified = {2011-07-18 15:38:54 -0700},
	Keywords = {active,bgp,measurement infrastructure,p2p,policy inference,representativeness,topology,tr-topo},
	Title = {Where the Sidewalk Ends: Extending the {I}nternet {AS} Graph Using Traceroutes From {P2P} Users},
	Year = {2009}}

@inproceedings{renesys-captivity,
	Author = {Martin A. Brown and Clint Hepner and Alin C. Popescu},
	Booktitle = {{NANOG}},
	Date-Added = {2011-07-18 15:35:10 -0700},
	Date-Modified = {2011-07-21 20:19:04 -0700},
	Title = {{I}nternet Captivity and the De-peering Menace},
	Year = {2009}}

@inproceedings{overlay-vs-multihome,
	Abstract = {The limitations of BGP routing in the Internet are often blamed for poor end-to-end performance and prolonged connectivity interrup- tions. Recent work advocates using overlays to effectively bypass BGP's path selection in order to improve performance and fault tolerance. In this paper, we explore the possibility that BGP route control, when coupled with ISP multihoming, can provide compet- itive end-to-end performance and reliability. Using extensive mea- surements of paths between nodes in a large content distribution network, we compare the relative benefits of overlay routing and multihoming route control in terms of round-trip latency, through- put of 1MB TCP transfers, and path availability. We observe that the performance from route control employed in conjunction with multihoming to three ISPs (3-multihoming), is within 5-15% of that from overlay routing employed in conjunction 3-multihoming, in terms of both end-to-end RTT and throughput. We also show that while multihoming cannot offer the nearly perfect resilience of overlays, it can eliminate almost all failures experienced by a singly-homed end-network. Our results demonstrate that, by lever- aging the capability of multihoming route control, it is not neces- sary to circumvent BGP routing to extract good wide-area perfor- mance and availability from the existing routing system.},
	Annote = {Following a similar methodology to that described in [3], we emulate a multihoming scenario by selecting a few nodes in a metropolitan area, each singly-homed to a different ISP, and use them collectively as a stand-in for a multihomed network. 

Since we wait for three consecutive losses, we cannot detect fail- ures that last less than 3 minutes despite recent work showing many failures lasting less than two minutes [9]. A significant fraction of these failures (more than two-thirds), however, occur in the net- works of small ISPs (e.g., DSL providers). Since the nodes in our testbed are connected to large ISPs, we believe the likelihood of short outages that escape detection is low. 


When no multihoming is employed, we see that all paths have at least 91% availability (not shown in the figure). Fewer than 5% of all paths have an availabil- ity less than 99.5%. Route control with multihoming significantly improves the availability on the end-to-end paths, as shown by the 2- and 3-multihoming availability distributions. Here, for both 2- and 3-multihoming, we consider the ISPs providing the best round- trip time performance in a city. Notice from this figure, that even when route control uses only 2 ISPs, less than 1% of the paths origi- nating from the cities we studied have an availability under 99.9%. The minimum availability across all the paths is 99.85%, which is much higher than without multihoming. Also, more than 94% of the paths from the various cities to the respective destinations do not experience any observable failures during the 5 day period (i.e.,availability of 100%). With three providers, the availability is improved further.   Overlay routing may be able to circumvent even the few failures that route control could not avoid. However, as we show above, this would result in only a marginal improvement over route control which already offers very good availability.

In most cases, 1-overlays have slightly higher availability (at most about 0.07%). Since a 1-overlay has arbitrary flexibility in choosing intermediate hops, only about 2.7 routers are common (on average) between all possible overlay paths, compared to about 4.2 in the 3-multihoming case. However, note that a 1-overlay path us- ing a single provider is more vulnerable to access link failures than when multihoming is employed.


As expected, our results show that overlay routing outperforms route control with multihoming for latency, throughput, and reliability. We found that overlay routing's per- formance gains arise primarily from the ability to find routes that are physically shorter (i.e. shorter propagation delay). In addition, its reliability advantages come from having at its disposal a super- set of the routes available to standard routing. The surprise in our results is that, while past studies of overlay routing have shown this advantage to be large, we found that careful use of a few additional routes via multihoming at the end-network was enough to signifi- cantly reduce the advantage of overlays. Since their performance is similar, the question remains whether overlays or multihoming is the better choice. To answer this, we must look at other factors such as cost and deployment issues.

Also, most current overlays, especially RON [6] only facilitate communication between participants in the overlay.

Discusses Cost of operation, Deployment and operational overhead, 

Violation of policies by overlay paths. One of the concerns that overlay routing raises is its circumvention of routing policies insti- tuted by intermediate AS hops. For example, a commercial end- point could route data across the relatively well-provisioned, aca- demic Internet2 backbone by using an overlay hop at a nearby university. While each individual overlay hop would not violate any policies (i.e., the nearby university node is clearly allowed to transmit data across Internet2), the end-to-end policy may be vio- lated. 
},
	Author = {Aditya Akella and Jeffrey Pang and Bruce Maggs and Srinivasan Seshan and Anees Shaikh},
	Booktitle = {SIGCOMM},
	Date-Added = {2011-07-15 16:35:18 -0700},
	Date-Modified = {2011-07-15 17:07:49 -0700},
	Keywords = {bgp,failures,multihoming,},
	Title = {A Comparison of Overlay Routing and Multihoming Route Control},
	Year = {2004}}

@inproceedings{iplane-imc,
	Author = {Harsha V. Madhyastha and Thomas Anderson and Arvind Krishnamurthy and Neil Spring and Arun Venkataramani},
	Booktitle = {IMC},
	Date-Added = {2011-07-06 22:24:51 -0700},
	Date-Modified = {2011-07-06 22:25:32 -0700},
	Title = {A Structural Approach to Latency Prediction},
	Year = {2006}}

@phdthesis{lorenzo-thesis,
	Author = {Lorenzo Colitti},
	Date-Added = {2011-07-06 22:20:22 -0700},
	Date-Modified = {2011-07-06 22:21:05 -0700},
	School = {University di Roma Tre},
	Title = {Internet Topology Discovery Using Active Probing},
	Year = {2006}}

@inproceedings{wiser,
	Author = {Ratul Mahajan and David Wetherall and and Thomas Anderson},
	Booktitle = {NSDI},
	Date-Added = {2011-07-06 22:18:40 -0700},
	Date-Modified = {2011-07-06 22:19:37 -0700},
	Title = {Mutually Controlled Routing with Independent {ISP}s},
	Year = {2007}}

@inproceedings{MIRO,
	Author = {Wen Xu and Jennifer Rexford},
	Booktitle = {SIGCOMM},
	Date-Added = {2007-10-08 18:56:07 -0700},
	Date-Modified = {2007-10-08 18:56:56 -0700},
	Title = {{MIRO}: Multi-path interdomain routing},
	Year = {2006}}

@inproceedings{deflections,
	Author = {Xiaowei Yang and David Wetherall},
	Booktitle = {SIGCOMM},
	Date-Added = {2007-10-09 11:10:53 -0700},
	Date-Modified = {2007-10-09 11:11:43 -0700},
	Title = {Source Selectable Path Diversity via Routing Deflections},
	Year = {2006}}

@inproceedings{consensus-routing,
	Author = {John P. John and Ethan Katz-Bassett and Arvind Krishnamurthy and Thomas Anderson and Arun Venkataramani},
	Booktitle = {NSDI},
	Title = {Consensus Routing : The {I}nternet as a Distributed System},
	Year = {2008}}

@misc{ec2_web,
	Date-Modified = {2011-07-06 21:15:59 -0700},
	Key = {ec2},
	Note = {\texttt{http://aws.amazon.com/ec2/}},
	Title = {ec2}}

@inproceedings{rbgp,
	Author = {Nate Kushman and Srikanth Kandula and Dina Katabi},
	Booktitle = {NSDI},
	Date-Modified = {2007-10-07 18:43:36 -0700},
	Title = {{R-BGP}: Staying Connected in a Connected World},
	Year = 2007}

@inproceedings{fcp,
	Author = {Karthik Kalambur Lakshminarayanan and Matthew Chapman Caesar and Murali Rangan and Thomas Anderson and Scott Shenker and Ion Stoica},
	Booktitle = {SIGCOMM},
	Date-Modified = {2007-10-07 21:38:23 -0700},
	Title = {Achieving Convergence-Free Routing using Failure-Carrying Packets},
	Year = {2007}}

@inproceedings{italo-path-changes,
	Annote = {- best predictors: route prevalence, number of past route changes, number of times a route appears in the past, route age
- predicting based on these is no highly accurate, but can help track path changes, as can predict paths that are more likely to change in the short term
- DTRACK adapts path sampling rates to minimize number of missed changes.  Sends a single probe per samle in a temporally striped form of traceroute 
- detects up to 73% more path changes
- map with MDA (full paris traceroute) at beginning, then remap when a change is detected (when you observe a new IP)
- 60% of routes have durations under one hour

- they do NN4, nearest neighbor based on 4 features
-- hard to define metric across the 4, since the domains differ, they have different semantics, and they impact paths differently
-- they use equally-spaced percentiles of each distribution, computed over all training set, and create cubes, then find which cube a test point is in and have the training data in the cube vote

try to predict 3 things
- residual lifetime
-- inaccurate, but estimate order of magnitude well in most cases, enough to get some benefit in change tracking
- number of changes
-- most are accurate, especially over short time periods, but predicting 0 changes is often accurate
- whether there will be a change in the next time interval
-- easiest for short time periods and high prevalence, which is good in that most routes are long-lived with high prevalence, and topo mapping wants to predict changes over short time periods
-- however, doesn't do much better than just predicting no changes over 1hr or 4 hr periods
-- and not that much better than random over 25 hr periods
--- for routes with prevalence below 0.7, 0.29 -> 0.23 over 4 hours and 0.16->0.13 over 1 hour

- DTRACK chooses path sampling rates based on NN4 (based on trying to minimize number of missed changes)
-- updates whenever a path changes its NN4 partition (either on a change or on aging)

the range on their graphs seems to be 0 to 60 (probes / sec / path x 10^-3)
- at 1000 pings per minute, 15 hops per path, we get 16 pings per second, so we are talking about monitoring like 1000 paths

- what is the distribution of # of changes in 1 / 4 / 24 hrs?
- how much do changes differ by source?  by destination?
- if anyway we are trying to keep particular paths up to date, does it make sense to learn that particular path?   or, at the least, might some features that weren't useful overall (such as the last time this route showed up) be useful for some?
- I was surprised that the paper didn't use cross-monitor signals.  Also cross destination
- The predictions based on bins seem somewhat arbitrary - a majority vote, but the test point might be close to a boundary of the bin and hence much closer to values in the next bin.
- Related, what's the distribution of how bins "vote"?  Are most close to 0.5?  Do results change much if you slightly jiggle the bin boundaries?
- Can I train on PL sources, then apply the results to traceroute servers, say (where I can't really do the high rate probes necessary to train)?  Or will the path changes have different properties?
- 5.2 confused me.  I thought 4 showed that predicting residual life and # of changes was hard, then these are used to allocate probe budget.

-------------
my notes that I sent to Renata based on an early draft:
Main high level comment:
Most of the paper is down in the details.  I think it would benefit from more time spent higher up: I think the problem could be motivated more (as i think it applies in many areas), both in terms of other problem areas and in terms of more detail on what is wrong now / how this paper improves it.  I don't think topology mapping is a super compelling use, as you can accumulate topology over long time periods where maybe it doesn't matter if I miss changes (as long as I see them once in awhile).  I think stuff where you need up-to-date routes is more compelling: tomography, failure detection / isolation, route prediction, path intersections for reverse traceroute.  Because so much of the paper was in the details, I ended up coming away with the main conclusions being that the system only yields relatively small % improvements.  It would help if the paper stepped back and discussed why that mattered, ideally with an example / application / use case (not necessarily fully real or fleshed out) where those extra changes make a difference in what you conclude or something.  Along the same lines, what should the reader learn about how paths change or how the network operates?

Smaller points:
- The title suggested to me that you'd be predicting what the path would change to, not just that it had changed
- Might want some motivation in the abstract
- Abstract uses both "a simple predictor" and "nearest-neighbor predictor" and it was unclear if those were the same (before reading the paper)
- I was surprised that the paper didn't use cross-monitor signals.  As some of the comments say, I would acknowledge this as an area for future improvement.
- I was curious how this fit with Demystifying Service Discovery (IMC10) which I think showed we can probe much faster than we do
- Dataset could use more explanation.  Why so few PL sources?  Did you use commercial ones?  If so, did they behave similarly?  How were the 34K targets chosen?
- first sentence of 2.3 says "why changes in virtual paths occur."  The way I would interpret "why a change occurs" is outside the scope of the paper.  Maybe use a different word?
- The paper introduces a lot of notation.  It would be helpful to have a glossary / table explaining it all, plus it would be great to explain the terms as much as possible where they are used.  For example, the caption of Fig 4 could say what E4h is.
- 4.1.1 I don't understand the sentence starting "In this way we ensure that the projected..."
- If you set the percentiles for bin boundaries based on the full dataset, does that amount to training on your test data?
- The predictions based on bins seem somewhat arbitrary - a majority vote, but the test point might be close to a boundary of the bin and hence much closer to values in the next bin.
- Related, what's the distribution of how bins "vote"?  Are most close to 0.5?  Do results change much if you slightly jiggle the bin boundaries?
- In the end of 4.1.2, I assume the final average over all paths ends up being normalized / weighted by the amount of time each path is in the partition, but I wasn't positive.
- First para in 4.2.2 says A > 12h, but I think it is supposed to be <
- All through Section 4, I wanted a comparison to something simpler.  No Change in figure 7 finally gives this, and I was left feeling like there was little gain over it.  Except on the rarest routes, the technique only picks up a few percentage points over No Change.  I think this suggests it will be really hard to ever see rare routes unless we get lucky. The paper needs to convince the reader that this improvement matters, and I think an application is the best way to do that.
- Fig6 Bottom should be labeled NN4 somewhere, since the top graph shows both.
- 4.2.3 says that Fig7 Top give 6min, but I don't understand where. 
- The sentence starting "Fig. 7 shows that NN4 predicts..." is confusing, as it starts talking about accuracy, then moves to talking about misses instead.
- I wonder how these results would translate to non-PL sources.  Can I train on PL sources, then apply the results to traceroute servers, say (where I can't really do the high rate probes necessary to train)?  Or will the path changes have different properties?
- 5.2 confused me.  I thought 4 showed that predicting residual life and # of changes was hard, then these are used to allocate probe budget.
- In 5.3, I wasn't sure how remapping works in the per-link sampling.  Do you remap all paths that share the link?
- Next-to-last para in 5.3, I didn't understand the reference to prefix-based routing
- The max probe rates in Fig 10 are fairly low - half the cited Ark rate, for instance.  I don't know that this changes anything, just surprised me.  It might be nice to discuss a bit what the targets/budget ratio needs to be for the system to make much difference.
- 5.5 states that the misses of optimum are unavoidable, but wouldn't an oracle decide what to probe based on what was going to change the soonest (not what came up on the queue)?
- 5.6 refers to a line "minimize changes" but I think it should say "minimize misses."
- Citation 6 says Atlanta, FL.  Should be Atlanta, GA.  The citations are inconsistent in terms of whether or not they give cities.},
	Author = {Italo Cunha and Renata Teixeira and Christophe Diot},
	Booktitle = {SIGCOMM},
	Date-Added = {2011-06-06 23:17:55 -0700},
	Date-Modified = {2011-06-06 23:20:55 -0700},
	Keywords = {active,measurement tools,monitoring,stability,tr-paths},
	Title = {Predicting and Tracking {I}nternet Path Changes},
	Year = {2011}}

@inproceedings{preferred-path-changes,
	Abstract = {Previous studies on inferring the origin of routing changes in the Internet are limited to failure events that generate a large number of routing changes. In this paper, we present a novel approach to origin inference of small failure events. Our scheme focuses on routing changes imposed on preferred paths of prefixes and not on transient paths trig- gered by path exploration. We first infer the preferred path of each prefix and measure the stability of each inter-AS link over this preferred path. The stability is measured based on routing changes of specific prefixes that regularly use the link and are advertised by the AS adjacent to the link. We then correlate the stability of other links over this path and infer the instability boundary as the origin. Our analysis using Oregon Route- Views data and trouble tickets from operational networks shows that our inference scheme can identify the origins of small failure events with very high accuracy.},
	Author = {Masafumi Watari and Atsuo Tachibana and and Shigehiro Ano},
	Booktitle = {PAM},
	Date-Added = {2011-03-28 19:45:28 -0700},
	Date-Modified = {2011-03-28 19:46:05 -0700},
	Keywords = {rootcause},
	Title = {Inferring the Origin of Routing Changes based on Preferred Path Changes},
	Year = {2011}}

@inproceedings{clock-sync-inaccuracy,
	Abstract = {
Synchronizing clocks is an integral part of modern network and security
architectures. However, the ability to synchronize clocks in modern networks
is not well-understood. 
In this work, we use testbeds equipped with a
high-accuracy GPS receiver to acquire ground truth, to study the accuracy of
probe-based synchronization techniques to over 1861 public time servers.
 We
find that existing synchronization protocols provide a median error of 2-5
ms, but suffer from a long-tail. We analyze sources of inaccuracy by
decoupling and quantifying different network factors. We found that most
inaccuracies stem from asymmetry of propagation delay and queueing delay. We
discuss possible schemes to compensate these errors to improve synchronization
accuracy.},
	Annote = {we find that synchroniza- tion accuracy is well-correlated with some path
properties that can be probed by end-hosts. To address this, we evaluate
several heuristics that compensate for this error (by estimating the error and
correcting for it).


I only skimmed it, but I think basically they used revtr + tr, then estimated
the geographic prop delay between NTP servers and used that to correct
inaccuracies due to asymmetry.  With this technique, they were able to reduce
the delay from 2.8ms to 1ms.
},
	Author = {Chi-Yao Hong and Chia-Chi Lin and Matthew Caesar},
	Booktitle = {PAM},
	Date-Added = {2011-03-28 19:36:50 -0700},
	Date-Modified = {2011-03-28 19:43:13 -0700},
	Title = {Clockscalpel: Understanding root causes of Internet clock synchronization inaccuracy},
	Year = {2011}}

@inproceedings{bgpmux,
	Author = {Vytautas Valancius and Nick Feamster and Jennifer Rexford and Akhiro Nakao},
	Booktitle = {ATC},
	Date-Added = {2010-08-28 18:34:49 -0700},
	Date-Modified = {2011-07-18 15:34:21 -0700},
	Keywords = {bgp,measurement infrastructure,multihoming,testbed},
	Title = {Wide-Area Route Control for Distributed Services},
	Year = {2010}}

@techreport{choffnes-positioning,
	Abstract = {Network positioning systems provide an important service to large-scale P2P systems, potentially enabling clients to achieve higher performance, reduce cross-ISP traffic and improve the robustness of the system to failures. Because traces representative of this environment are generally unavailable, and there is no platform suited for experimentation at the appropriate scale, network positioning systems have been commonly implemented and evaluated in simulation and on research testbeds. The performance of network positioning remains an open question for large deployments across
hosts located at the edges of the network.
This paper evaluates how four key classes of network positioning systems fare when deployed at scale and measured in P2P systems where they are used. Using 2 billion network measurements gathered from more than 43,000 IP addresses probing over 8 million other IPs worldwide, we show that network positioning exhibits noticeably worse performance than previously reported in studies conducted on research testbeds. To explain this result, we identify several key properties of this environment that call into question fundamental assumptions driving network positioning research.},
	Annote = {based on Ono extension to Vuze bittorrent client.  
vuze provides:
- vivaldi
- vivaldi v2 (network coordinates in the wild)
- CRP, their CDN-redirection coordinates
- also evaluate meridian and GNP

4 classes of coordinate systems
- landmark-based embeddings (GNP)
- landmark-free embeddings (vivaldi)
- direct measurements (meridian)
- measurement reuse (CRP)

sources of error
- network embedding (is actually high dimensional)
- triangle inequalities
- first and last mile

conclude:
- need to use topology as basis for appropriate abstraction of network positioning
- believe need only relative proximity info
- each peer can build its local topology then compare this to find those w similar ones},
	Author = {David Choffnes and Mario Sanchez and Fabian Bustamante},
	Date-Added = {2010-05-09 00:07:02 -0700},
	Date-Modified = {2010-05-09 00:10:25 -0700},
	Institution = {NWU},
	Keywords = {coordinates},
	Title = {Network Positioning From the Edge: An empirical study of the effectiveness of network positioning in P2P systems},
	Year = {2009}}

@inproceedings{nanog-captivity,
	Author = {Martin A. Brown and Clint Hepner and and Alin Popescu},
	Booktitle = {{NANOG} 45},
	Date-Added = {2010-05-01 02:39:37 -0700},
	Date-Modified = {2010-05-01 02:41:04 -0700},
	Title = {Internet Captivity and De-peering},
	Year = {2009}}

@inproceedings{ming-nsdi2010,
	Author = {Zheng Zhang and Ming Zhang and Albert Greenberg and Y. Charlie Hu and Ratul Mahajan and Blaine Christian},
	Booktitle = {NSDI},
	Date-Added = {2010-05-01 02:33:52 -0700},
	Date-Modified = {2010-05-01 02:36:19 -0700},
	Title = {Optimizing Cost and Performance in Online Service Provider Networks},
	Year = {2010}}

@inproceedings{bgp-mux,
	Annote = {- "Unfortunately, although today's cloud-computing platforms offer elastic computing and bandwidth resources, they do not give services control over wide-area routing"
- EC2 has at least 58 upstream BGP peers for its Virginia DC and at least 17 for its Seattle DC (via RouteViews)
- "Previous studies have shown that DNS lookup latency is a significat contributor to the overall latency for short sessions (eg, short HTTP requests)"
- can use routing to migrate services - they give reasons why DNS-based migration is not idea
- they use BGP community 174:10 to signal to Cogent (174) to prefer this route less than other routes
Cogent Communications BGP Communities
www.onesc.net/communities/as174
},
	Author = {Vytautas Valancius and Nick Feamster and Jennifer Rexford and Akihiro Nakao},
	Booktitle = {USENIX Technical},
	Date-Added = {2010-05-01 02:19:04 -0700},
	Date-Modified = {2010-08-28 18:36:13 -0700},
	Keywords = {bgp,multihoming,testbed},
	Title = {Wide-Area Route Control for Distributed Services},
	Year = {2010}}

@unpublished{midar,
	Author = {Ken Keys and Young Hyun and Matthew Luckie},
	Date-Added = {2010-03-04 22:20:35 -0800},
	Date-Modified = {2010-03-04 22:24:53 -0800},
	Note = {Under preparation},
	Title = {{I}nternet-Scale Alias Resolution with {MIDAR}},
	Year = {2010}}

@techreport{caesar,
	Annote = {To Read:
What is the sound of one route flapping?  T. Griffin

PROBLEM
- lack clear understanding of BGP dynamics, restricting abilityto address shortcomings
- "BGP health inferencing system" that localizes the root causes fo routing changes: What is the cause of a routing change?  Where does a routing change originate?

APPROACH
- targeted towards the 80% of prefixes that are relatively stable, containing most popular destinations on Internet
- does not use traceroute, but mentions it could enhance precision

validation:
- analytically and empirically show correctness of key steps
- detect well-known events

KEY IDEAS
- publishes results online in realtime at www.cs.berkeley.edu/~mccaesar/hmon.htm

based on 2 assumptions:
- "an as that triggers any route change should be embedded in one or more route updates in the burst (previous path, intermediate path, final path)."  claim that only violations of this require preferring peer or provider to customer 
- artificial damping (due to rate limiting and flap damping) of updates has little effect on updates during minor events

DETAILS
applications:
- net ops for debugging and troubleshooting
- set bgp policies based on historical stats of stability
- bgp use online to improve path selection and dampen instability
- choose upstreams

challenges:
- correlated vs simultaneous observations
- bgp policies
- multiple peering links (2 AS paths may intersect, but actually not intersect in network topology)
- i-bgp/e-bgp interactions

methodology
- separate stable from continuously flapping.  stable, 2 properties hold: routing events visible, not affecting by damping, and 2 different events are separable in time
- equivalence classes of causes
-- hard vs soft, worsen vs improve gives 4 equivalence classes, 5th is changes to community attribute (which can cause a change to be triggered several hops away from AS that undergoes the event)
-- 6 patterns of advertise/withdrawn you can observe (complete), and rules to map the ASes in each to the 5 equivalence classes
-- assume by default that 2 paths sharing an AS link actually traverse different peering sessions
- correlation of routing updates (across time [ O(minutes) sync between VPs), prefix, view)
-- a burst of updates for a single prefix at a given VP is assumed to have a single event if the mean-separation time between bursts is at least 10x the duration of this burst
-- prefixes: - turbulent vs quiescent periods, with most events falling in one or the other and very few in the gap in between (in this case, counting by # of prefix events observed on a given link), so if you see more than the # for the turbulent period, you assume it is a single major event
-- all views that observe a burst for prefix at overlapping times assuming to be same event, provided none of the views are affected by a major event

RESULTS
- for 70% of observed updates to these stable prefixes, approach can pinpoint the location of origin to a single inter-AS link
- detect nearly 1,400 high magnitude (many prefixes) events per month and found certain inter-AS links to be perennially unstable

PROS

CONS 

QUESTIONS FOR THEM

QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK
- if we are doing this approach of continuously measuring paths back to somewhere, how do we know where the paths might change to, to have what their pre-change path was?
- what does RouteViews give us?  maybe a view of what else we should monitor? 
- our advantages... potential coverage to edge, router-level},
	Author = {M. Caesar and  L. Subramanian and R. H. Katz},
	Date-Added = {2009-12-10 10:49:48 -0800},
	Date-Modified = {2009-12-10 10:52:03 -0800},
        Institution = {University of California, Berkeley},
        Year ={2003},
	Keywords = {bgp,failures,monitoring,passive,rootcause,stability},
	Title = {Towards Localizing Root Causes of {BGP} Dynamics}}

@inproceedings{msr-measuring-datacenter,
	Annote = {measure datacenter from endhosts (feasibly, possibly necessary)
traffic stays mostly within high bandwidth regions
slows small, short-lived, turnover quickly
net highly utilized often with moderate impact on apps

a map/reduce datacenter},
	Author = {Srikanth Kandula and Sudipta Sengupta and Albert Greenberg and Parveen Patel},
	Booktitle = {IMC},
	Date-Added = {2009-11-05 09:34:37 -0800},
	Date-Modified = {2009-11-06 20:21:40 -0800},
	Title = {The Nature of Datacenter Traffic: Measurements and Analysis},
	Year = {2009}}

@inproceedings{ratul-sampling-biases,
	Annote = {current internet path values suffer from bias
can correct post measurement

current:
property of interest -> sample paths and measure -> estimate mean, percentile, knee
widely used to characterize, optimize common case, evaluate ideas
methodology: measure few paths, use available biases

biased samples not representative, can't tell what they missed, may systematically miss some types of paths (based on your bias)

bias removal elsewhere:
1. remove impact due to source selection (figure out how to start random)

2. re-weigh using properties of the system (figure out overall distrubtion of source types)
3. compute source contribution

they use cooridinates or decomposition
- decompose values of compontents along path, src-code-dst, then stitch together components of umeasured ones
-- do as an optimization: goal: approximate measurements, constraints: succinctness
-- good for average, not for percentiles},
	Author = {Srikanth Kandula and Ratul Mahajan},
	Booktitle = {IMC},
	Date-Added = {2009-11-05 07:03:50 -0800},
	Date-Modified = {2009-11-06 20:22:39 -0800},
	Title = {Sampling Biases in Network Path Measurements and What To Do About It},
	Year = {2009}}

@inproceedings{arbor-2009-nanog-report,
	Annote = {

"Largest Internet monitoring infrastructure in the world"

110+ ISPs/ content providers
- near real-time traffic and routing
- leverages commercial security/ traffic engineering infrastructure

First global traffic engineering study of Internet evolution 
- quantitative measures of observations from other reports

within given ISP,
- monitor netflow/ jflow/ etc and routing across routers
- probes topo aware of ISP, backbone, customer boundaries
- routers include most peering/ transit edge
- send anonymous XML file to central servers, including self-categorization of primary geo region and type
- coarse-grain anonymized traffic engineering stats

measures:
- relative inter-domain traffic between ISPs (focus on market share as opposed to absolute volumes)

inter-domain traffic volume/ratios provide:
- important design/ engineering metric
- negotiation/ business strategy

does not measure internal or private costumer traffic

major findings:
- consolidation of content contributors (migrating from enterprise / edge to aggregators)
-- 150 ASNs contribute 50% of traffic
- consolidation of apps
-- browser is app bront end (migrating to HTTP/flash)
- evolution of core and economic innovation
-- majority traffic direct between consumer and ___<missing word, probably content>___
XXXX--- driven by cost and increasingly performance!!!
-- Market shifts focus to higher value services (MSSP, VPN, CDN, etc)
-- emperimentation w paid transit (what does this mean? paid peering, i think is what they mean) / paid content (espn 360 is example)

big content providers now account for tons of traffic
- in 2007, top 10 (in terms of weighted traffic) are the tier-1s (led by Level3)
- changed now
- 2005-2010 --- collapse of price of wholesale transit, growth of ad-supported content, collapse of price of cloud / hosting / cdn / video, scarcity of data center capacity
- graph shows big growth in revenue from ads, big drop in revenue from transit
- suddenly google and comcast in top 10 (level3 still #1)
- in 2007, 1000s of ASNs contributed 50% of content
- in 2009, 150 ASNs contribute 50% of traffic

CDNs
- top 5 pure-play CDNs - limelight, akamai, panther, bitgravity, highwinds (first 2 dominate others)
- what is pure play?
- "increasingly blurred lines between ISP and CDN"
- only includes akamai inter-domain (likely 1/4 or less or akamai)
- CDNs account for almost 10% of traffic

new internet
- core of interconnected content and consumer networks (giant content, consumer, hosting CDNs that participate in many IXPs and use that to get close to most smaller networks)
- new commercial models between content, consumer, and transit
- improvements in capacity and performance

google - 6% of all traffic

comcast
- 2007, traditional MSO (?)
-- no nationwide backbone, focus on residential, depend on upstream transit provider
- 2009, net contributor of traffic, new business models (triple play, cell backhaul, wholesale voice/IP transit, video for other cable operators, metro ethernet)

p2p significant, but maybe declining as %
- mainly eclipsed by streaming, cdn, direct download
-- carpathia grew a ton once it took on megaupload

Conclusion 
- Internet is at an inflection point 
- Transition from focus on connectivity to content 
-- Old global Internet economic models are evolving 
-- New entrants are reshaping definition / value of connectivity 
- New technologies are reshaping definition of network 
-- ``Web'' / Desktop Applications, Cloud computing, CDN 
- Changes mean significant new commercial, security and engineering challenges 
- This is just the beginning...

--Related work 
Bill Norton ``Video Internet: The Next Wave of Massive Disruption to the US Peering 
Ecosystem'', Equinix White Paper 2008. 
Akamai, ``State of the Internet''. White Paper 2009. 
Andrew Odlyzko, ``Minnesota Internet Traffic Studies (MINTS)'' 
Nate Anderson, ``P2P traffic drops as streaming video grows in popularity''. Ars Techica, 
September, 2008. 
P. Faratin and D. Clark and P. Gilmore and S. Bauer and A. Berger and W. Lehr, ``Complexity 
of Internet interconnections: Technology, incentives and implications for policy''. The 35th 
Research Conference on Communication, Information and Internet Policy (TPRC), 2007. 
},
	Author = {C. Labovitz and S. Iekel-Johnson and D. McPherson and J. Oberheide and F. Jahanian and M. Karir},
	Booktitle = {NANOG 47},
	Date-Added = {2009-11-03 15:47:49 -0800},
	Date-Modified = {2009-11-09 15:29:11 -0800},
	Title = {{ATLAS} {Internet} Observatory 2009 Annual Report},
	Year = {2009}}

@misc{ucla-topology,
	Date-Added = {2009-09-28 01:23:58 -0700},
	Date-Modified = {2010-03-07 10:58:46 -0800},
	Key = {ucla},
	Note = {\url{http://irl.cs.ucla.edu/topology/}},
	Title = {{UCLA} {I}nternet Topology Collection}}

@misc{sprint-map,
	Date-Added = {2009-09-27 22:21:12 -0700},
	Date-Modified = {2009-09-28 01:23:20 -0700},
	Key = {sprint},
	Note = {\url{https://www.sprint.net/performance/}},
	Title = {{S}print {IP} Network Performance}}

@misc{sprint-lg,
	Date-Added = {2009-09-27 22:21:12 -0700},
	Date-Modified = {2009-09-28 01:23:20 -0700},
	Key = {sprint},
	Note = {\url{https://www.sprint.net/lg/}},
	Title = {Sprint.net Looking Glass}}

@inproceedings{tomo-towsley,
	Author = {T. Bu and N. Duffield and F. Presti and D. Towsley},
	Booktitle = {SIGMETRICS},
	Date-Added = {2009-08-15 17:28:16 -0700},
	Date-Modified = {2010-03-07 10:56:03 -0800},
	Title = {Network Tomography on General Topologies},
	Year = 2002}

@inproceedings{dipzoom,
	Annote = {mentioned in responsiveness paper as large scale distributed measurement platform like ark and dimes iplane etc},
	Author = {S. Triukose and Z. Wen and A. Derewecki and M. Rabinovich},
	Booktitle = {INFOCOM},
	Date-Added = {2009-07-24 13:01:32 -0700},
	Date-Modified = {2009-07-24 13:03:04 -0700},
	Keywords = {to read},
	Title = {Dipzoom: An open ecosystem for network measurements}}

@article{topology-inference,
	Annote = {scalable discovery of underlying network topology among a group of nodes in an overlay.  utilized network coordinate system to identify path traces to collect to issue minimum number of probes},
	Author = {X. Jin and W. Tu and S.-H. Chan},
	Date-Added = {2009-07-24 12:59:56 -0700},
	Date-Modified = {2009-07-24 13:04:42 -0700},
	Journal = {{IEEE} Transactions on Parallel and Distributed Systems},
	Keywords = {to read},
	Title = {Scalable and efficient end-to-end network topology inference},
	Year = {2008}}

@inproceedings{increasing-coverage,
	Annote = {windowed doubletree that extracts missing links/nodes},
	Author = {Benoit Donnet and Bradley Huffaker and Timur Friedman and kc claffy},
	Booktitle = {IFIP NETWORKING},
	Date-Added = {2009-07-24 12:58:50 -0700},
	Date-Modified = {2009-07-24 13:04:14 -0700},
	Keywords = {to read},
	Title = {Increasing the Coverage of a Cooperative {I}nternet topology discovery algorithm},
	Year = {2007}}

@inproceedings{responsiveness,
	Annote = {overall: pretty limited in meat
PROBLEM
how responsive are routers to active probes, and how has this changed over time

APPROACH
- look at IP addresses in skitter and iplane, resolve the anonymous stars to routers

KEY IDEAS

DETAILS
types of anonymity:
- type 1: (always anonymous) configured to ignore certain probes, or border router configred to filter certain types of packets or outgoing ICMP responses
- type 2: (changing responsiveness) ICMP rate limiting or ignoring probes when congested 
- type 3: private IP address, so can't guarantee uniqueness, so must be considered anonymous
RESULTS
- anonymity seems to have increased over time, though it might be largely due to changes in skitter in 2005
- after resolving, 8-13% are anonymous (from 2005-2008 data), and 2-7% are type 2 (changing responsiveness)
- of routers in iplane/skitter traceroutes, 82% respond to ICMP
- they only use a single VP
 - only 124 of 536K probes respond to ICMP w RR.
PROS

CONS 
- pretty limited in meat
- limited assessment of rate limiting
- only probe from a single VP, vs skitter/iplane use multiple. esp a problem w RR-- this must just be dallas specific filtering
QUESTIONS FOR THEM
- mention that CAIDA/skitter is only historical topology data they are aware of.  make sure they know of iplane archives
- before resolving anonymous routers, the anonymous % they report is to high- 60-87%!  part of this is that 2 IPs that show up over and over, one anonymous, one not, the first counts for each time, whereas the second only counts once.  what happens if the TR trails off with *?  do they count each of these?
- how do they measure the type 2?  they say "these anonymous routers had IP addresses aliased to anonymous nodes in different path traces."  how do you differentiate it from load balancing?  b/c you see it on the same interface?
- in Table 3, how do they decide router vs end-host?  Is end-host just "appeared at the end of a traceroute," bc iplane is specifically TRYING to probe routers.
QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK
- how does the rate limiting value we measure change over time
- increasing rate limiting, increasing filtering-- look into using indirect probes, and careful w rate limits},
	Author = {Mehmet H. Gunes and Kamil Sarac},
	Booktitle = {PAM},
	Date-Added = {2009-07-24 12:20:34 -0700},
	Date-Modified = {2009-07-24 14:02:38 -0700},
	Keywords = {active,tr-reach,rate-limiting},
	Title = {Analyzing Router Responsiveness to Active Measurement Probes},
	Year = {2009}}

@misc{mit-spoofer,
	Date-Modified = {2008-02-13 21:51:01 -0700},
	Key = {spoofer},
	Note = {\url{http://spoofer.csail.mit.edu/}},
	Title = {The {S}poofer Project}}

@misc{gilmore-tiers,
	Author = {Patrick Gilmore},
	Key = {Gilmore},
	Note = {Private communication with Patrick Gilmore, Akamai Technologies},
	Title = {List of Tier 1 and 2 networks}}

@misc{wiki-tiers,
	Key = {tier},
	Note = {\url{http://en.wikipedia.org/wiki/Tier_1_network}},
	Title = {{Tier 1 networks Wikipedia}}}

@article{brazil-owd,
	Annote = {assumes identical fwd and rev prop delay, but varying queuing and transmission times

Our approach to estimate the transmission and propagation times is based on 
the generation of probes with two distinct sizes following the three step procedure 
described bellow. First, n probes with identical sizes l are sent from A to D. 
Consequently, the ICMP protocol send ICMP packets back to A with the same 
size l . Second, the same procedure is repeated but using probes sizes one order of 
magnitude greater than that used in the first step, that is 10l . Finally, n probes 
of size 10l are sent from A to D. However, this time we would like to get a return 
reply of size l . 
The method con- 
sists of sending two back to back probes(packet pair): the first is an ICMP Echo 
reply message of size equal to 10l bytes and the second is an ICMP Echo re- 
quest message of size l .delayed at each hop by the transmission time of the first probe, since the first 
is a packet 10 times greater than the second. 
From the three steps above, we can estimate the RTT of a packet with the same 
size in the forward and reverse directions and the RTT of a packet with size 10l 
in the forward direction and l in the reverse direction. From these estimates we 
obtain extra equations to solve our problem. 


also has a technique for dealing w clock sync

In all experiments the probe generation rates for each source are1,000 pack- 
ets/s and 100 packets/s.

issues:
- assumes symmetric prop delay!
- requires sending many packets/s... what happens if rate limited?},
	Author = {Antonio A. de A. Rocha and Rosa M. M. Leao and Edmundo de Souza e Silva},
	Date-Added = {2009-07-24 10:39:44 -0700},
	Date-Modified = {2009-07-24 10:42:12 -0700},
	Journal = {NETWORKING},
	Keywords = {one-way delay},
	Title = {A Non-cooperative Active Measurement Technique for Estimating the Average and Variance of the One-Way Delay},
	Year = {2007}}

@inproceedings{optometry,
	Annote = {"Obtaining reverse paths using the record route option and by correlating traceroutes, as in [2], is not a general solution to the problem."
"Our measurments don't at present tell us which provider is being used as the default" needs REVTR
use REVTR to followup on hidden upstream discovery and see what links are being used
"Recall that we cannot rigourously determine where probes are dropped, as we do not see the reverse paths \footnote{Relying on a tool such as [2] may partly solve this problem.}"
"Predicting this return path can be done only very partially by leveraging the record-route option and using forward probing from different locations [2].  The limited number of locations from which probing can be done in practice imples that guessing the reverse path of traceroutes will typically be a highly underconstrainted inference problem.  Only a tool that will record the full path of the probe and its answer will solve this limitation."
"Those tools suffer from important limitations, which

both in the default tests and in the hidden provider study in the paper, you use path poisoning to test reverse path connectivity.  i was wondering if you'd though about the effects of loose spoof filtering on the forward path, where the poisoned ASes might drop your forward packets bc the prefix isnt in their routing tables, causing the forward test probe to not have the same properties as the forward anchor probe},
	Author = {Randy Bush and Olaf Maennel and Matthew Roughan and Steve Uhlig},
	Booktitle = {IMC},
	Date-Added = {2009-07-06 18:28:30 -0700},
	Date-Modified = {2010-05-01 02:12:20 -0700},
	Keywords = {active,asymmetry,bgp,failures,measurement tools,multihoming,passive,reverse,tr-paths,tr-reach},
	Title = {{I}nternet optometry: assessing the broken glasses in {I}nternet reachability},
	Year = {2009}}

@unpublished{maars,
	Annote = {improvements to apar (kapar) and radargun to make them more accurate, more efficient, and scale to Ark topology


OVERALL
- the techniques are really nice and many of them are clever.  they seem like they would make radargun and apar scalable and accurate.  however, it requires reading between the lines to get the motivation for the paper, and i'm not sure i would have bought it if i didn't know the material really well.  you are proposing (though even this isn't that clear in the paper) an internet-scale (aka, everything seen in traceroutes from Ark), ongoing alias service, and you're presenting improved techniques towards that goal.  my questions going into the paper are things like (currently not really explicitly addressed):
-- why current Internet-scale, ongoing alias efforts (iPlane) don't suffice
-- why current techniques need to be improved to fit your goal.  your point is some combination of scalability, accuracy, and completeness, but i think the paper would benefit from being more explicit-- "RadarGun would take this long to run on our dataset," say, or "It is not feasible to run RadarGun on our dataset bc XXX."  could their scaling issues be solved with more vantage points?  how many false pos/neg would they cause?  for instance, alias information changes only at a very slow rate (i assume), so why does it matter if a technique (Radargun, DisCarte) takes a long time to run?  how often do you need to refresh your data?  is it bc aliases change or bc you uncover new topology?
-- is your goal more accurate CAIDA topologies, or an alias service?  i hope the 2nd-- it's a larger goal and something i would use.  if the 2nd, then do traceroutes from Ark suffice, or do you need measurements from PlanetLab (which many alias consumers will use)?  do you need to use record route to get more complete data?  is DisCarte really infeasible to run, or do we just not know how to run it?  
MORE SPECIFIC POINTS
- abstract could capture more why we need to improve, what you did, and/or how much you improved things
- similarly, the intro could provide stronger motivation for the work.  since i know you're tight on space, you could cut the traceroute detail from the intro
- i felt like the intro undersold your work on RadarGun/APAR and slightly oversold your work combining techniques (which will work out but for now is preliminary)
- might want to cite iplane, as i think it is the current biggest ongoing alias effort and the most used one.  make the point why it doesn't suffice for your needs (not comprehensive enough, not validated or tuned).  our 2009 NSDI paper is not the thing to cite.  it would be either harsha's dissertation or one of his earlier papers (probably the OSDI one, though i'm not sure if the alias stuff was in the IMC one).  it also implements the source-address finger print technique, so might want to cite in 2.1
- 2 doesn't define fingerprint technique.  also, why isn't discarte in the section?
- 2.2 doesn't really mention Ally's problems, then says that RadarGun addresses them
- 2.2, you haven't really given the context for "Internet graphes generated by CAIDA" and why that is the goal
- 2.2, in my reading of the RadarGun paper and in my use of their tool, the biggest problem is unresponsive routers, and that's what you start 4.1 with, but not mentioned here.
- 2.3 is pretty confusing.  i think this could be partly addressed by first talking about address assignment, the relationship between prefixes and links, how point-to-point subnets fit in.  it isn't immediately clear why you can't go through the same prefix-- i guess you just mean if that prefix corresponds to an assigned subnet, but even why that can't happen won't be clear to many people.  
- 2.3 is the 1/2 cutoff for completeness completely arbitrary, or based on some measurements?  standard practices?  what about unused or unresponsive addresses?
- 2.3 loops show up in measurements all the time.  how does that relate to the "no loop" condition?
- 2.3 i assume you mean the TTL of the response packets.  why can't they have different reverse paths?  we regularly observe different paths from aliases, so not immediately clear why subnet neighbors couldn't also differ.  "Must differ" seems strong given that and your point about inconsistencies.
- 4.3.1 how much did TTL expansion help?  might be clearer to start by saying you use +-1, and that further expansion did not help.
- 4.3.2 why did you use such a different threshold than Radargun for classifying unresponsive?
- 4.3.2 FWIW, with TCP/UDP, we observed most of the TTL=zero and TTL reflectors to be at/near endhosts and in educational networks.  Not sure if that holds over larger datasets.
- 4.3.3 You might also point out that the %s in table 2 show that they sometimes reply off different counters-- for instance, some of the 15% non-linear for TCP must be responsive and not non-linear for indirect.
- 4.4 Your argument for the max velocity is nice.
- 4.6 Randy Bush, Rob Sherwood, and Olaf Maennel mentioned to me that they observed time-of-day effects in the velocity of IP IDs from a large number of routers.  How does this fit in with your 4.6?  Did you not observe that at all?
- 4.7 Not sure if I just missed it, but I wasn't sure how many the 30 points was out of-- what is p?  Also wasn't sure where 2/3 came from in that section
- 4.7 The inexpensive tests are nice improvements.
- 4 could benefit from a conclusion
- 5.1 You could use record route to reject more false paths-- since it measures 9 hops in a single packet, it would catch places where traceroute inferred false links due to per-packet load balancing or path changes.
- 5.1 Does the MM stuff assume dense IP use and responsiveness?
- 5.1 I had trouble following the example in the para starting "Third," just as I did with the Apar stuff.  Not sure if it can be made clearer?
- 5.2 The paragraph about iffinder took me by surprise-- it hadn't really been introduced, and I didn't understand the context for this or the results in the following paragraphs-- are they based on known topologies?
- Table 3 Anyway to simplify this or help highlight the interesting parts?
- 6 It was a surprise, after you made so many improvements, that Radargun didn't come up in 6 and that you never had any alias results using RadarGun.
- 6 mentions discarte and DNS techniques, but they haven't really been introduced much.
- 6 How might biases in using academic networks affect your results?  Would you expect differences in commercial networks?
- 6.1 Do you have to worry about a router responding on behalf of an IP address not on it?  I thought someone had shown this once.
TYPOS ETC
- Intro, last para "section 6" missing capitalization
- 2.1 says "Most routers respond from the source address..." when I believe that actually very few do (and I think your numbers show that)
- 2.3 Might want "First," to correspond with "Second," and "Third,"
- 2.3 in the inline figure bottom of page 2, not that clear what arrows mean
- 2.3 "because subnet" missing "the"
- 4.6 "when end of the window" missing "the"
- 4.7 "scaling to a millions" extra "a"
- 4.8 "overlaping" -> "overlapping" (this appears twice)
- 5.1 In terms of saving space, a paragraph you could consider cutting is the one about how MM probes won't generate complaints.  I don't think many people wil be dubious of them.
- 5.2 The reference "as described in section 5" could more precisely point to 5.1.
- 6 missing comma before NLR
- 6.1 "columns... in the table illustrates" should be "illustrate"
- 6.1 "were were" should be "we were"
- 6.1 "addtional" spelling 
- Table 2 is far from where you discuss it, and you discuss it before table 1.
- There are many places in the paper where you mention that you will address things later-- would be nice to have forward points or maybe try to restructure.
},
	Author = {Ken Keys and Young Hyun},
	Date-Added = {2009-07-06 15:49:42 -0700},
	Date-Modified = {2009-07-06 18:11:23 -0700},
	Keywords = {imc 2009 submission, active,alias,coordination,measurement infrastructure,service,},
	Note = {Unpublished draft},
	Title = {Toward MAARS: a Multi-Approach Alias Resolution System},
	Year = {2009}}

@misc{stun,
	Author = {J. Rosenberg and J. Weinberger and C. Huiteme and R. Mahy},
	Date-Added = {2009-06-08 14:29:51 -0700},
	Date-Modified = {2009-06-08 14:32:15 -0700},
	Howpublished = {RFC 3489},
	Keywords = {to read},
	Title = {{STUN} - Simple Traversal of {U}ser {D}atagram {P}rotocol {(UDP)} through Network Address Translators ({NAT}s)},
	Year = {2003}}

@inproceedings{spring-coordinates,
	Author = {C. Lumezanu and Neil Spring},
	Booktitle = {ICDCS},
	Date-Added = {2009-06-08 14:28:16 -0700},
	Date-Modified = {2009-06-08 14:29:44 -0700},
	Keywords = {coordinates, to read},
	Title = {Measurement Manipulation and Space Selection in Network Coordinates},
	Year = {2008}}

@inproceedings{coordinates-wild,
	Author = {J. Ledlie and P. Gardner and M. Seltzer},
	Booktitle = {NSDI},
	Date-Added = {2009-06-08 14:27:21 -0700},
	Date-Modified = {2010-05-09 00:08:32 -0700},
	Keywords = {to read, coordinates},
	Title = {Network Coordinates in the Wild},
	Year = {2007}}

@inproceedings{matchmaking,
	Annote = {met w jay lorch when we spoke at systems lunch about their trusted trinket paper, he gave me this paper

PROBLEM
want to match players for online games (they use XBox Halo 3 trace) for latency without having to make a huge number of measurements

It isn't super clear, but I think the motivation is to consider more potential peers without issuing a large number of probes (bc users don't want to wait).

APPROACH
pair coordinates with geoloc data
- use geoloc data (from maxmind) to boostrap starting locations for vivaldi (they use pyxida, a "practical implementation of the vivaldi algo for azureus bittorrent client-- "Network Coordinates in the Wild" NSDI 2007)
- a few other optimizations, many (all?) of which they admit are adaptations of others work

KEY IDEAS
bootstrapping coordinates w geoloc gets the advantages of both while avoiding drawbacks
- geoloc is usually but not always right
- geoloc is often but not always a good predictor of latency
- coordinates give decent latency predictions
- but can take awhile to converge
- and can get stuck in local min

good data set (but lacks traceroutes, making their comparison to iplane unfair)

Report the result of an RTT to the destination as well.

DETAILS
lag annoys game players, and latency is primary cause of lag

Pyxida (essentially vivaldi), plus:
- geographic bootstrapping
- throw out measurements that excede predicted by more than 100ms, as long as you have some confidence in node's coordinates
- if you have prior measurement, use it rather than predicting
- if 2 nodes in same AS and within 225 miles, ignore 20% of heights of heights of nodes when computing latency
- symmetric updates-- when i measure RTT, report it to destination as well

RESULTS
find much better results than iplane or oasis.  include graphs both with and without pairs when the other systems had no prediction (in which case they give them a random prediction!) 

almost all their boost is from geographic.  then some from symmetric updates, and AS, triangle, and history give little
PROS
lots of little tweaks to vivaldi to make it work better

CONS 
comparison to iPlane is sorta unfair since they dont include measurements from clients for iplane but do for their system

idea is pretty small-- mostly just the geoloc idea

they make a similar observation to "On the Difficulty of Finding the Nearest Peer in P2P Systems " but do not cite it

lots of magic constants tuned to their dataset

not well motivated, since xbox is currently probing.  i guess idea is that you can consider more potential peers

training and test dataset include some of the same pairs!

unclear how much gegraphic bootstrapping helps once peers have been in the system for a long time, though i guess you always have new people joining

5.5 starts by claiming "So far, our analyses have assumed that matchmaking relies solely on prediction for latency estimation, i.e. that there is no time to perform network probing to determine latency." but their system gets coordinates from probes!!

QUESTIONS FOR THEM
I like how you work through various details needed to make coordinates work in practice.

The central observation is a nice one-- that geoloc and coordinates have different, but complementary, advantages, and that they can be used to overcome some of each others' disadvantages.  It seems like there might be other ways to use this to your advantage.  First, as I mentioned before, it might be possible to use coordinates (or prediction accuracy) to temper your confidence in some geoloc info or to adjust it (possibly leading to faster convergence or finding better mins).  Some correct geolocations are bad predictors of latency, and some geolocations are wrong.  Many of these are likely to be systematic (for example, we found many Australian MaxMind locations were placed on the wrong continent), and once coordinates show you a bad geoloc value, you might be able to apply that knowledge to future peers (say, by prefix) by either starting them in the final location of the first peer or by adjusting the elasticity/initial confidence of their starting point based on how bad it proved for the first peer.  Or, in cases, like the Redmond machine in Fig 26, where the DB only knows country, you have a good idea where other machines in that network might be after you place that first one.  And in many cases, the DB gives you some confidence/granularity info to start.  Second, it seems like you might achieve better performance by deciding which probes to issue based on geoloc/coordinate data-- probe into areas that you need more info on, where your confidence is low or things are moving a lot.

Are there peers for which a geographic locations (even after moving with your coordinate system) are never good predictors of latency-- wherever you stick them, they get some very bad locations, and you seemingly need another dimension?

I think the central issue with the comparison to iPlane is that the dataset you had forced you to compare them in slightly different settings.  In evaluating Htrae, you assumed you had control of the peers you cared about and could issue measurements from them, and you assumed you knew the set of servers and issued measurements directly to them.  On the other hand, iPlane did not have measurements from the peers, and it did not generally issue measurements directly to the servers.  Coordinate systems do not generally have a way to predict between arbitrary endhosts (they need measurements to or from both), which is what iPlane was doing.  The way to use iPlane in a setting of a deployed app with clients who return over time would be to have those clients contribute a small number of traceroutes into the system (for which iPlane includes an API).  I am curious to see how iPlane would compare in that setting (esp given the constants you've tuned to that particular setting, it is essentially running a trained model vs an untrained one), or in a setting where all your measurements were from PlanetLab too.  We found that including just 10 random traceroutes per peer improves the number of AS paths we can predict perfectly from 60% to 80%, and presumably it helps the router-level and latency accuracy of some of the 60% too (as you hint at in related work, not entirely clear how the atlas will scale.  We found a median prediction error of ~5ms vs ~20ms for Vivaldi, whereas your dataset observed iPlane and Pyxida being equivalent to each other.  Your observation of symmetric updates is a nice one, though-- in settings where you care about RTT, you can get the same measurements regardless of which endpoint you control, whereas paths (traceroute) do not have that advantage.

QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK


QUESTIONS FROM THE SIGCOMM PRESENTATION
part of the motivation is to be able to consider more possible peers than are currently probed, but of course your trace can only contain the ones that were probed
can you talk about how this sparseness might affect any of your results?
geoloc weakness- inflexible
coordinates  weakness - sensitive to initial conditions
fails to cite geoloc papers that use geo databases at a starting point, then move based on measurements
AS corrections, heights done before
triangle inequality violations done before
lots of fitting on the dataset
symmetric updates are nice
iplane trained on probes to routers, not to endhosts

as he notes, they have node-specific data, and iplane doesn't
he points out that they don't have the data, plus that iplane might not be able to scale to receiving data from 10Ms of clients
anja: if you take set of possible peers, wouldn't using the isp-specific p2p systems that exist solve the problem of returning a subset to use?  would take too long, we haven't looked at it
q2: why not just send 100 pings?  we would like to parallelize it
q3: didn't you train on your own dataset?  how would it work in the wild, where would the numbers come from?  A: we dont anticipate them changing.  the training was from 6 months before
dave chothnes: only 13 probes per user?  isn't it really sparse?  how representative is it?  this is the data we got, randomly selected by the current deployment

This paper presents Htrae, a new technique for estimating Internet latency, based on existing coordinate techniques.  The high level motivation is to match players of online games to low latency peers, without having to make a huge number of measurements.  Specifically, I believe the goal is to allow consideration of more potential peers without requiring more probes.  The technique essentially bootstraps an existing coordinate system (Pyxida, an implementation of Vivaldi) with geolocation data from a database.  Coordinate systems assign each node coordinates and use them to predict latency between any two nodes; locations are updated based on differences between predicted and observed latency.  Whereas, in traditional coordinate systems, locations might be initialized randomly, Htrae initializes them to the geographic location of the node according to a location database.  Similar to geolocation techniques like TBG or Octant, Htrae views the DB-derived locations as suggestions, changing coordinates to better suit measurements.  This approach helps Htrae overcome limitations the 2 approaches have on their own-- coordinate systems' susceptibility to local mins and slow convergence, and the incompleteness and inaccuracies of geolocation DBs-- and benefit from the strengths of both approaches-- geolocation data is quite often right and is often a decent predictor of latency, and coordinates provide a good mechanism to adapt to prediction errors.  Htrae incorporates a number of other optimizations, some identified as adapted from others' work, to the basic coordinate approach.  For example, the system tries to account for triangle inequality violations, the inelastic latency from an endhost to its PoP, and the difference between paths between nodes in the same ISP and those that traverse multiple ISPs.  They also make the nice observation that a client should report the latency it measures to a possible peer to that peer, allowing them both to benefit.

The authors use an impressively large XBox Halo 3 trace to evaluate their system in comparison to other approaches.  In Halo 3 currently, a server sends a client a small number of prospective peers, and the client pings them and selects the one with lowest latency.  The trace is a down-sampling of this data.  Replaying this data, the authors find that Htrae performs much better than coordinate systems without their optimizations, both in terms of the accuracy of latency prediction and in terms of choosing low latency peers from a set, with the biggest gain coming from the geographic bootstrapping.  They also compare their system to iPlane and Oasis, systems that take other approaches to predicting latency (note: I've worked some on the iPlane project), and they find that these systems do not currently provide predictions for many of the XBox players and that, even on the ones they can predict, Htrae provides more accurate predictions.

I like this paper-- it shows how to build a coordinate system that works in a real application.  The observation of the benefit of combining geolocation and coordinate systems is nice.  Although many of the other tweaks were borrowed from existing systems, there is real value in showing the set of modifications necessary to make coordinates work.  The motivation comes from an actual problem, and the evaluation dataset is large and real, lending weight to the results-- it would be great if some of this data were made public.  However, I think some limitations of the dataset make it hard to draw strong conclusions about the system.  First, because clients currently only ping a small number of peers (the reason Htrae is needed!) and the dataset down samples that, the data includes, for each client, measurements to only a small number of potential peers (on average), and so Htrae can only choose from these small sets.  It is unclear how well Htrae would work given larger sets of potential peers, and it is possible that a coordinate system might benefit less from geographic bootstrapping if given more measurements (though geolocations would still speed convergence).  Second, the system includes a number of magic constants tuned to the dataset, and (I believe) the training and test datasets even include measurements between some of the same pairs of peers.  While this makes sense given that the system is intended for this particular setting, it makes it harder to draw conclusions from comparisons to other, non-tuned systems.  Third, Htrae trains on measurements issued from the clients needing predictions, but the comparison is to systems that do not have measurements from those clients, making it hard to compare the systems.  For instance, the version of iPlane evaluated against only includes measurements to routers, not to endhosts.  Jay Lorch, one of the authors, has expressed interest in working with us to conduct an evaluation on a dataset in which both Htrae and iPlane have measurements from the clients.  In our experience, access to even a handful of measurements from a host greatly improves the quality of iPlane predictions, and it would be interesting to see whether the various improvements in Htrae allow coordinate systems to achieve or beat the accuracy of iPlane's more heavy-weight structural approach.  As Jay pointed out in his talk, we have not evaluated how iPlane works at the scale of the Htrae dataset. 

It might be possible to improve the system further by pushing more on the connections between the geolocation and coordinate approaches.  Since many errors in geolocation databases are systematic (for instance, an entire prefix placed in the wrong country), the final positioning (or prediction accuracy) of one node could be used to temper confidence or adjust starting positions for related nodes in the database.  And, it seems like it might be possible to achieve better performance by deciding which probes to issue based on geoloc/coordinate data-- probe into areas that you need more info on, where your confidence is low or things are moving a lot.

UPDATE: I wrote the review above on the plane to SIGCOMM, but failed to post it until now, so I thought I would update with some observations from the presentation.  I expect whoever scribes the session will do a more complete job (for instance, I couldn't tell from where I was sitting who a few of the questions were asked by), and anyone should feel free to correct my notes.  Anja Feldmann asked the first question, something like, if the input is a set of possible peers, couldn't we solve the problem of returning which subset to use by employing an existing system to reduce inter-ISP traffic in P2P systems by having peers query their ISP?  Jay replied that such an approach would likely take too long and that they hadn't looked at it.  Later, David Choffnes asked a similar question: since the goal is to return the best subset, rather than to predict the latency, wouldn't an existing system (such as his, Ono) to do so for P2P systems work?  I am not an expert on either Anja or David's systems. It seems to me that the difference in the goals-- reducing inter-ISP traffic without affecting performance, vs (for Htrae) finding the peer with the best performance-- are different enough that the solutions may not directly apply.  Further, at least in the SIGCOMM 08 paper, Ono recommends peers only a fraction of the time, otherwise resulting to default BitTorrent behavior.  The setting for Htrae demands answers all the time.  So, I am unsure how directly these existing systems apply (hopefully their authors can weigh in in more detail).

Various audience members asked the questions I'd had about the work.  Someone asked why a client couldn't just decide based on sending 100 pings.  Jay answered that they would like to parallelize the setup with the decision.  I would be curious to see the difference in a) setup time and b) latency to the peer in Htrae vs. such a system.  Another person asked about whether the configuration values were trained from the same dataset, and if so how it would work in the wild when individual clients would not have all the data.  Jay mentioned that the training was from data gathered 6 months before, and that they don't anticipate the values changing often-- they could be hardcoded in, then changed only when early software updates are pushed out.  Finally, Dave Choffnes asked about the sparseness of the measurements matrix-- an average of only 13 probes per user-- and whether it could still be representative.  Jay replied that that was all that was recorded, based on the limited peers considered by the current system and the sampled logging employed.  

iplane comparison
One experiment would be to plug PlanetLab probe results into both iPlane and Htrae to compare them.  I would expect and hope that iPlane would do much better here, but it would be good to check.  If you have a trace of <time, endpoint1, endpoint2, end-to-end latency> from PlanetLab I could run that through Htrae to make predictions and we could compare it to what iPlane would do with traceroutes taken at the same time.
Authors should have shown proper discretion in interpreting the results. In the paper, authors also reported that 'OASIS produces estimates for only 22% of the requets, while iPlane does 23%'. If their training set contained traceroute results as well, and they used the same training set for the iPlane, the argument of coverage could be changed.

It is strongly recommended that authors take the binary code of iPlane and evaluate the performance under the same condition with their system. 

},
	Author = {Sharad Agarwal and Jacob R. Lorch},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-06-08 12:03:51 -0700},
	Date-Modified = {2009-09-02 01:32:36 -0700},
	Keywords = {active, geolocation, coordinates, tr-delay, tr-geo},
	Title = {Matchmaking for Online Games and Other Latency-Sensitive {P2P} Systems},
	Year = {2009}}

@inproceedings{netquest,
	Author = {Han Hee Song and Lili Qiu and Yin Zhang},
	Booktitle = {SIGMETRICS},
	Date-Added = {2009-05-28 15:44:25 -0700},
	Date-Modified = {2009-05-28 15:46:01 -0700},
	Keywords = {to read},
	Title = {NetQuest: A Flexible Framework for Large-Scale Network Measurement},
	Year = {2006}}

@article{network-kriging,
	Author = {David B. Chua and Eric D. Kolaczyk and Mark Crovella},
	Date-Added = {2009-05-28 15:39:02 -0700},
	Date-Modified = {2009-05-28 15:40:26 -0700},
	Journal = {IEEE JSAC},
	Keywords = {to read},
	Title = {Network Kriging},
	Year = {2006}}

@unpublished{prophecy,
	Annote = {This paper presents Prophecy, a system that attempts to address the performance overhead and integration complexity issues that may be keeping BFT replication from being widely adopted. The system inserts a "sketcher" between clients and a replicated service. The sketcher first tries a read from a single replica and, if it matches the cached sketch, returns it. Only when this fails does the sketcher fall back on a replicated read. The authors term the guarantees this provides "delay-once consistency," and they evaluate the performance of their system, as well as measuring its suitability for major websites. 

Strengths 
This paper attempts to address some of the limitations that keep BFT replication from being widely adopted, and the authors do a good job making their argument. The consistency guarantee they provide and the mechanism they use to do so seem reasonable for many real applications. The separation of their sketcher from the actual means of replication seems like a good design decision. 


Weaknesses 
There has been a lot of work in this general area, and it is unclear that another proposal in the space, without a real deployment or a toolkit others can use (as far as I can tell) will have much impact.

Most of the paper is well written. 

The introduction did a good job making the case for the system, and I liked examples like the PNUTS one in 2.3. 

I think the paper could use more discussion of how Prophecy affects ease of implementation. The point that many systems consist of coupled components is a good one, and there is analysis of Prophecy composition and how it scales, but not as much about how easy it would be to get it right in these types of situations. 

Why is fetching the main page of the top 25 websites the right evaluation? How often is the interesting content hidden in internal pages and most accesses are to internal pages? The Harvard Facebook analysis got at this a bit. Section 6 could use a conclusion or some way of contextualizing the results and the argument it makes for your system (and for the limitations of when your system applies). 

6.1 was a bit hard to follow. I think it could be explained better. 

Typos and minor issues 
2.2 "there is no causually-dependent writs" I think it should be "there ARE no CAUSALLY-dependent WRITES." I didn't notice many typos in the paper, but there seem to be 3 in this sentence. 

5.2 Refers to Table 5.2, when I think it should say Table 1. 

Table 1 caption should explain what the variables are. 

Figure 6 legend should switch the order of the labels to match the order of the lines (3rd party line is on top, so putting it on top in the legend makes the graph easier to read).},
	Author = {48},
	Date-Added = {2009-05-27 15:42:56 -0700},
	Date-Modified = {2009-05-27 15:43:31 -0700},
	Keywords = {590L spring 2009 SOSP shadow PC},
	Note = {SOSP submission},
	Year = {2009}}

@unpublished{hermes,
	Annote = {This paper presents Hermes, a system that uses the social network induced by emails (sender-receiver and receiver-receiver relationships) to periodically cluster users and migrate closely tied users onto the same servers.  The migration allows them to store only a single copy of an email on each server, reducing the amount of space required.  The system is designed mainly for corporate settings hosting their own servers, though the authors talk a bit about other settings.  Using a 3 month trace of a corporation with 120K users, the authors demonstrate that Hermes saves 40% storage vs current approaches.

STRENGTHS
This system is based on a nice idea.  The authors give a straightforward presentation, and they have a good dataset on which to evaluate.  The results are impressive compared to a theoretical lower bound.  I am convinced that the system could work in that setting.

WEAKNESSES
This approach, as described in the paper, seems very specific to the problem of saving space on email servers.  Although the authors claim to have shown that we can improve system performance by exploiting social networks, the paper does not seem to present any general principles that would let us extend it.  The paper could also do a better job motivating the need to reduce email storage space.  Do corporations really care?  I'm not sure.

I was not convinced by the attempts to cast the paper as a demonstration of the ability of social networks to improve systems, beyond this one instance.  However, it is a nice paper on reducing email storage.  I think it should be retitled something closer to "Exploiting social networks to optimize email storage," the first paragraph of the abstract should be cut, and it would be a good publication for a different venue.  I don't think it is broad or deep enough for this conference.

How well could we do by periodically migrating based on organization charts?

In the intro, the end of the paragraph starting "In many applications" and the following paragraph are repetitive and can be combined/reduced.

4.1 "especially as e-mails sent to multiple..." Isn't that the only reason you need to capture the relationship?  Also, it does not seem to make much difference in your results.

Fig 6: Am I missing something, or is fan-out just # of recipients?  If so, I think it would be clearer if the caption said that.

Fig 3 shows only 30% savings from emails with 10 or fewer recipients.  How does this relate to a cut-off of 10?  Why can you use this cut-off and still get the savings? 

The 2nd paragraph of section 5 is too detailed.  Or, if you want that much detail, include section #s for where each evaluation is.

It would be nice to find a way to evaluate the effect of deletions, at least at a small scale.  How common are policies like the 6 month one you mention?

Can you separate the effects of new users vs changing relationships over time (for figure 8)?  Even over 12 weeks, ClusterOnce only cases a few percentage points, which doesn't seem like a huge deal.  How well could you do if you were just able to smartly cluster newcomers?  I also did not think the paper did a good job explaining why ClusterAlways did worse, esp since Figure 8 does not capture migration costs.  To me, the fact that it does seems to suggest a problem with some underlying assumption.

The text claims that Table 2 is normalized, but I don't understand how it is if it is.

Section 6- Expected more from the discussion of Hotmail/Gmail.  Might want to either add more or set up readers' expectations better in the first para of section.

TYPOS AND NITS
The evaluation section seemed sloppy, with a number of typos and awkward phrasings.  I have not listed all of them.

Intro first para  "RATE of per-user I/O operations (IOP) RATE"
Intro para 3 "Enabling storage coalescing..." you have an unnecessary comma that makes it hard to parse the sentence
3.1 para that begins "Note that the total..." appear -> appears.  And the sentence needs to be rewritten otherwise, as I think there is another typo or something and it doesn't parse right.

The 4th para under bandwidth savings no longer seems to be about that subject, so could be set off better.

Would be nice to show the math a bit for the 0.6 MB/s/ 0.5 MB/s calculations (just note what numbers you're dividing to arrive at that).

},
	Author = {96},
	Date-Added = {2009-05-27 15:41:29 -0700},
	Date-Modified = {2009-05-27 15:44:13 -0700},
	Keywords = {590L spring 2009 SOSP shadow PC},
	Note = {SOSP submission},
	Title = {Hermes: exploiting social networks to optimize systems},
	Year = {2009}}

@inproceedings{brice-ixp,
	Author = {Brice Augustin and Balachander Krishnamurthy and Walter Willinger},
	Booktitle = {IMC},
	Date-Added = {2009-05-26 15:56:18 -0700},
	Date-Modified = {2009-09-28 00:24:01 -0700},
	Keywords = {active, asymmetry, topology,tr-topo},
	Title = {{IXP}s: Mapped?},
	Year = {2009}}

@unpublished{planetlab-experience,
	Author = {Larry Peterson},
	Date-Added = {2009-05-26 15:54:37 -0700},
	Date-Modified = {2009-05-26 15:54:50 -0700},
	Keywords = {to read},
	Title = {PlanetLab Experience paper}}

@unpublished{glue-logic,
	Date-Added = {2009-05-26 15:54:02 -0700},
	Date-Modified = {2009-05-26 15:54:29 -0700},
	Keywords = {to read},
	Title = {glue logic papers}}

@unpublished{msr-coordinates,
	Date-Added = {2009-05-26 15:52:37 -0700},
	Date-Modified = {2009-05-26 15:53:58 -0700},
	Keywords = {to read},
	Title = {Jay Lorch SIGCOMM 2009 paper on coordinates w Geoloc info}}

@unpublished{ratul-measurements,
	Date-Added = {2009-05-26 15:51:55 -0700},
	Date-Modified = {2009-05-26 15:52:32 -0700},
	Keywords = {to read},
	Title = {Ratul's IMC09 paper on which measurements you need}}

@unpublished{caida-alias,
	Date-Added = {2009-05-26 15:51:27 -0700},
	Date-Modified = {2009-05-26 15:51:52 -0700},
	Keywords = {to read},
	Title = {CAIDA Alias}}

@inproceedings{mit-spoofer-imc09,
	Author = {Robert Beverly and Arthur Berger and Young Hyun and and k claffy},
	Booktitle = {IMC},
	Date-Added = {2009-05-26 15:51:00 -0700},
	Date-Modified = {2010-03-07 10:55:47 -0800},
	Keywords = {spoofing,active,},
	Title = {Understanding the Efficacy of Deployed {I}nternet Source Address Validation Filtering},
	Year = {2009}}

@unpublished{macepc,
	Annote = {The observation that many of the problems are correctness bugs masked by recovery mechanisms was interesting.

I liked that the authors used the tool on a number of deployed, mature systems.  This part of the paper was interesting and added to the case. 

Although the issue is mentioned briefly, it would be nice to have some discussion of what it might take to deploy a similar tool for existing, non-Mace systems.

The authors explicitly assume that the durations of events in a particular execution are independent.  This is a big assumption, but seems like a reasonable approach.

In the example on page 6, you still have to pay attention to 8000 events.  Any ideas on cutting this down further?  Certainly pointing to an anomalous execution and shaving off some of the events is a good start, but can you do more?

What happens with massively distributed apps?  Do you think most bugs will manifest at the relatively small number of nodes you use, or do you think MacePC (and a programmer's ability to understand logs) will scale?

------
Numerous small typos, repeated words, grammar errors (noun/verb agreement), etc.  Pretty sloppy.

I didn't like the use of the word ingredients.  Sorta cutesy.  Components?  
},
	Author = {125},
	Date-Added = {2009-05-20 10:35:19 -0700},
	Date-Modified = {2009-05-20 10:48:27 -0700},
	Keywords = {590L spring 2009 SOSP shadow PC},
	Note = {SOSP submission},
	Title = {Finding Performance Bugs in Systems Implementations Using Automated State Space Exploration},
	Year = {2009}}

@inproceedings{icmp-quotations,
	Abstract = {RFC 792 requires most ICMP error messages to quote the IP header and the next eight bytes of the packet to which the ICMP error message applies. The quoted packet is used by the receiver to match the ICMP message to an appropriate process. An operating system may examine the quoted source and destination IP addresses, IP protocol, and source and destination port numbers to determine the socket or process corresponding to the ICMP message. In an idealised end-to-end Internet, the portion of the packet quoted should be the same as that which was sent, except for the IP TTL, DSCP, ECN bits, and checksum fields. In the modern Internet, this may not always be the case. This paper presents an analysis of ICMP quotations where the quote does not match the probe.},
	Annote = {Using tcptraceroute, the paths to 84393 web servers used in a previous study [1] 
were traced serially between the 6th and 12th of May 2005. All TCP SYN packets 
sent from the measurement source, as well as all ICMP time exceeded, unreach- 
able, source quench, redirect, and parameter problem messages were recorded 
using tcpdump. 1190351 probes were sent, and 858090 ICMP replies were re- 
ceived and matched to a probe from 53768 unique IP addresses. 836456 ICMP 
responses were of type time exceeded, 21525 were of type unreachable, and 109 
were of type source quench. A further 9 ICMP messages were unmatched. 


. If an ICMP response can be matched by IP-ID or 
byte-swapped IP-ID to one of the 25 most recently sent probes, then it is deemed 
a match.

Many in-flight changes are able to be attributed to known packet rewrit- 
ing techniques. In the data collected for this paper, relatively few quoters are 
inferred to modify packets in-flight, or indeed to modify them during processing.},
	Author = {David Malone and Matthew Luckie},
	Booktitle = {PAM Poster Session},
	Date-Added = {2009-04-27 01:10:21 -0700},
	Date-Modified = {2009-04-27 01:24:23 -0700},
	Keywords = {active, poster},
	Title = {Analysis of ICMP Quotations},
	Year = {2007}}

@inproceedings{coral-experiences,
	Annote = {submitted

Summary
This paper presents a retrospective analysis of the design of CoralCDN after 5 years of deployment.  CoralCDN is a self-organizing PlanetLab-based CDN designed such that a simple URL modification allows any site to make use of the service.  The goal of the system was to help content providers deal with situations such as flash crowds.  The paper draws lessons from the authors' experience with the system, including design choices that worked well, design choices that worked poorly, and what changes they made to deal with some problems that came up.

Strengths
These types of papers can be very interesting and helpful, and I appreciate the willingness of the authors to reflect on their work and share with the community.  The fact that a section is called "CoralCDN's design was mostly wrong" shows their willingness to try to honestly assess the work.  Despite that, the system is in many ways a successful PlanetLab service (accounting for the majority of traffic/users), and the lessons of the systems should be valuable to the community.  By describing, for instance, how they overdesigned for what they needed in the end, how they dealt with challenges with using PL, and how their simple API led to unanticipated uses, this paper could benefit future research.  In general, the paper is well organized and easy to read.

Weaknesses
Some of the lessons are fairly specific to the system.  I wonder if the authors could more explicitly draw broad lessons more often (they do a good job in places, like 3.3).  How could they have come up with a better design up front?  Was it impossible without the experience of observing the workload and the problems that came up?  The paper might benefit from a discussion section at the end that steps back a level in a way that is directed at more general system design.

Explain Rating
It is valuable to the community to have retrospective analysis of previous work, based on experience with real deployments.

Comments to authors
One discussion I was expecting but did not find was lessons in dealing with complaints and users.  It seems like many complaints to PL Support often stem from the CDNs, and you only briefly touch on this when discussing blacklists in the background/security section at the beginning.  Larry Peterson's recent paper dealt with these issues, but do you have any lessons to teach users from your experience?

In 3.1.2, can you provide some sense of how common non-transitive connectivity problems are?  Presumably reference [18] does that, but it would be nice if you could include a quick takeaway from that paper/ the operation of Coral, just to set the context for the modifications/discussion.

minor points to clarify
3.1, 2nd para.  Unclear what you mean by "Mostly simultaneously."
Figure 3: The origin server line is hard to read, being so close to 0.  Are all points on the graph above 0?  Would a log Y scale make it more readable?

3.3.2 refers to a PlanetLab limit of 17.2 GB/day per slice.  I think that you might be using the PL terms differently than how I am used to them being used.  Is it actually per sliver (meaning, per node, rather than per service in aggregate across all nodes)?  Otherwise, I do not understand the comparison to your 10 GB/day limit, which you say is per node.

typos etc
2.1, #3 "to a one of the returned proxy" -> "to one of the returned proxies"
2.3.2, first para "origin server to those arriving later" should it be "origin serve to those arriving later?"  Seems to be missing a verb.
3.2, footnote 3.  The footnote would be better placed after "expiry times" or at the end of the sentence rather than after "mostly."  Also, it says "and thus does not" but I think should be "and thus do not" to agree with the noun proxies.
3.3.2 looks like you might be missing a space in "lowest priority.This"
},
	Author = {164},
	Date-Added = {2009-04-15 17:00:18 -0700},
	Date-Modified = {2009-05-27 15:44:08 -0700},
	Keywords = {590L spring 2009 SOSP shadow PC},
	Title = {Experiences with CoralCDN: A Five-Year Operational View},
	Year = {2009}}

@inproceedings{treeness,
	Date-Added = {2009-04-14 11:31:21 -0700},
	Date-Modified = {2009-04-14 11:31:39 -0700},
	Keywords = {to read},
	Title = {On the Treeness of Internet Latency and Bandwidth}}

@inproceedings{collecting-topology,
	Date-Added = {2009-04-14 11:31:20 -0700},
	Date-Modified = {2009-04-14 11:32:40 -0700},
	Keywords = {to read},
	Title = {Collecting the Internet AS-level Topology}}

@inproceedings{cite-key,
	Date-Added = {2009-04-14 11:31:12 -0700},
	Date-Modified = {2009-04-14 11:31:12 -0700}}

@inproceedings{route-monitor-selection,
	Author = {Zhang,, Ying and Zhang,, Zheng and Mao,, Zhuoqing Morley and Hu,, Charlie and MacDowell Maggs,, Bruce},
	Booktitle = {IMC},
	Date-Added = {2009-04-10 17:57:11 -0700},
	Date-Modified = {2009-04-10 17:58:16 -0700},
	Keywords = {representativeness},
	Title = {On the impact of route monitor selection},
	Year = {2007}}

@inproceedings{vivaldi,
	Author = {Russ Cox and Frank Dabek and Frans Kaashoek and Jinyang Li and Robert Morris},
	Booktitle = {HotNets},
	Date-Added = {2009-04-10 11:11:21 -0700},
	Date-Modified = {2009-04-10 11:13:54 -0700},
	Keywords = {tr-delay},
	Title = {Practical, Distributed Network Coordinates},
	Year = {2003}}

@inproceedings{neti,
	Author = {Simpson, Jr., Charles Robert and George F. Riley},
	Booktitle = {PAM},
	Date-Added = {2009-04-10 07:04:31 -0700},
	Date-Modified = {2009-04-10 07:05:01 -0700},
	Title = {{NETI@home}: A Distributed Approach to Collecting End-to-End Network Performance Measurements},
	Year = {2004}}

@inproceedings{onehop-nsdi08,
	Author = {Piatek,, Michael and Isdal,, Tomas and Krishnamurthy,, Arvind and Anderson,, Thomas},
	Booktitle = {NSDI},
	Date-Added = {2009-04-10 07:01:20 -0700},
	Date-Modified = {2009-04-10 07:01:56 -0700},
	Title = {One hop reputations for peer to peer file sharing workloads},
	Year = {2008}}

@inproceedings{phas,
	Author = {Mohit Lad and Dan Massey and Dan Pei and Yiguo Wu and Beichuan Zhang and Lixia Zhang},
	Booktitle = {USENIX Security},
	Date-Added = {2009-04-10 06:59:43 -0700},
	Date-Modified = {2009-04-10 07:00:37 -0700},
	Keywords = {hijack},
	Title = {{PHAS}: A prefix hijack alert system},
	Year = {2006}}

@inproceedings{darpa,
	Annote = {- top level goal - effective technique for multiplexed utilization of existing interconnected networks
"the local area network had not yet emerged"
- each network is an adminstrative boundary of control, and even then a goal of the project was to come to grips with the problem of integrating separately administrated entities

2nd level goals (order of importance
- communication must continue despite loss of networks or gateways - survibability
- multiple types of communication service
- variety of networks
--- above had a large impact on design, below were less effectively met or not completely engineered-----
- distributed management of resources
- cost effective
- host attachment with low level of effort
- resources used in architecture must be accountable

"This network was designed to operate in a military context, which implied{\ldots} accountability as a last goal.  An architecture primarily for commercial deployment would clearly place these goals at the opposite end of the list."

"In other words, at the top of transport, there is only one failure, and it is total partition.  The architecture was to mask completely any transient failure"

goal 1 interconnection
goal 2 survivability
goal n accountability

"The Internet makes very weak assumptions about the ability of a network to report that it has failed.  Internet is thus forced to detect network failures using Interent level mechanisms, with the potential for a slower and less specific error detection"

To make it easier to incorporate a variety of networks, "There are a number of services which are explicitly not assumed from the network, [including] internal knowledge of failures, speeds, or delays."

Although the Internet has been successful in allowing different organizations to administer different parts, "some of the most significant problems with the Internet today relate to lack of sufficient tools for distributed management, especially in the area of routing.  [The current approach to routing] is error-prone and at the same time not sufficiently powerful.  The most important change in the Internet architecture over the next few years will probably be the development of a new generation of tools for management of resources in the context of multiple administrations."

"Wide flexibility in the service offered.  Different transport protocols could be used to provide different types of service, and different networks could be incorporated."

"Its success has made clear that in certain situations, the priorities of the designers do not match the needs of actual users.  More attention to such things as accounting, resource management, and operatoin of regions with separate administrations are needed."

},
	Author = {David D. Clark},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-10 06:32:25 -0700},
	Date-Modified = {2010-11-24 17:39:23 -0500},
	Title = {The Design Philosophy of the {DARPA} {I}nternet Protocols},
	Year = {1988}}

@misc{nanog,
	Author = {\url{http://www.merit.edu/mail.archives/nanog/}},
	Date-Added = {2009-04-10 06:32:08 -0700},
	Date-Modified = {2009-04-10 06:32:08 -0700},
	Title = {North {A}merican {N}etwork {O}perators {G}roup mailing list}}

@inproceedings{rcc,
	Author = {N. Feamster and H. Balakrishnan},
	Booktitle = {NSDI},
	Date-Added = {2009-04-10 06:31:45 -0700},
	Date-Modified = {2009-04-10 06:31:45 -0700},
	Title = {Detecting {BGP} Configuration Faults with Static Analysis},
	Year = 2005}

@inproceedings{feldman,
	Author = {Anja Feldmann and Olaf Maennel and Z. Morley Mao and Arthur Berger and Bruce Maggs},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-10 06:30:33 -0700},
	Date-Modified = {2009-04-10 06:30:33 -0700},
	Title = {Locating {I}nternet routing instabilities},
	Year = {2004}}


@inproceedings{labovitz00,
	Annote = {Tup and Tshort events converged within 90 seconds, while only 5% of Tdown and Tlong events converged within 90 seconds, and 20% required longer than 2 minutes},
	Author = {Craig Labovitz and Abha Ahuja and Abhijit Bose and Farnam Jahanian},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-10 06:29:54 -0700},
	Date-Modified = {2011-07-15 18:18:21 -0700},
	Title = {Delayed {I}nternet routing convergence},
	Year = {2000}}

@inproceedings{wang2006,
	Author = {Feng Wang and Zhuoqing Morley Mao and Jia Wang and Lixin Gao and Randy Bush},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-10 06:29:34 -0700},
	Date-Modified = {2009-04-10 06:29:34 -0700},
	Title = {A measurement study on the impact of routing events on end-to-end {I}nternet path performance},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1151659.1159956}}

@article{hearme,
	Author = {N. Kushman and S. Kandula and D. Katabi},
	Date-Added = {2009-04-10 06:28:41 -0700},
	Date-Modified = {2009-04-10 06:29:02 -0700},
	Journal = {SIGCOMM CCR},
	Title = {Can You Hear Me Now?! {I}t Must Be {BGP}},
	Year = {2007}}

@misc{google,
	Date-Added = {2009-04-10 06:27:02 -0700},
	Date-Modified = {2009-04-10 06:27:02 -0700},
	Key = {google},
	Note = {\url{http://www.google.com}},
	Title = {Google}}

@inproceedings{ripe-ttm,
	Author = {F. Georgatos and F. Gruber and D. Karrenberg and M. Santcroos and A. Susanj and H. Uijterwaal and R. Wilhem},
	Booktitle = {PAM},
	Date-Added = {2009-04-10 06:26:10 -0700},
	Date-Modified = {2009-04-10 06:26:10 -0700},
	Title = {Providing Active Measurements as a Regular Service for {ISP}s},
	Year = 2001}

@inproceedings{venkat-tomography,
	Author = {Venkata N. Padmanabhan and Lili Qiu and Helen Wang},
	Booktitle = {INFOCOM},
	Date-Added = {2009-04-10 06:25:49 -0700},
	Date-Modified = {2009-04-10 06:25:49 -0700},
	Title = {Server-based Inference of {I}nternet Link Lossiness},
	Year = {2003}}

@inproceedings{SPAND,
	Author = {S. Seshan and M. Stemm and R. Katz},
	Booktitle = {USITS},
	Date-Added = {2009-04-10 06:25:37 -0700},
	Date-Modified = {2009-04-10 06:25:37 -0700},
	Title = {{SPAND}: Shared passive network performance discovery},
	Year = {1997}}

@article{mincloss,
	Author = {Ram\'on C\'aceres and N. G. Duffield and Joseph Horowitz and Donald F. Towsley},
	Date-Added = {2009-04-10 06:25:23 -0700},
	Date-Modified = {2009-04-10 06:25:23 -0700},
	Journal = {{IEEE} TIT},
	Title = {Multicast-Based Inference of Network-Internal Loss Characteristics},
	Year = {1999}}

@inproceedings{minclossunicast,
	Author = {N. G. Duffield and F. Lo Presti and V. Paxson and D. Towsley},
	Booktitle = {INFOCOM},
	Date-Added = {2009-04-10 06:24:57 -0700},
	Date-Modified = {2009-04-10 06:24:57 -0700},
	Title = {Inferring Link Loss Using Striped Unicast Probes},
	Year = {2001}}

@inproceedings{biswas,
	Author = {Pratik Biswas and Yinyu Ye},
	Booktitle = {Information Processing in Sensor Networks},
	Date-Added = {2009-04-10 06:23:43 -0700},
	Date-Modified = {2009-04-10 06:23:57 -0700},
	Title = {Semidefinite Programming for Ad Hoc Wireless Sensor Network Localization},
	Year = 2004}

@inproceedings{doherty,
	Author = {L. Doherty and K. S. J. Pister and L. E. Ghaoui},
	Booktitle = {Infocom},
	Date-Added = {2009-04-10 06:23:12 -0700},
	Date-Modified = {2009-04-10 06:23:29 -0700},
	Title = {Convex position estimation in wireless sensor networks},
	Year = 2001}

@inproceedings{placelab,
	Author = {Anthony LaMarca and Yatin Chawathe and Sunny Consolvo and Jeffrey Hightower and Ian Smith and James Scott and Timothy Sohn and James Howard and Jeff Hughes and Fred Potter and Jason Tabert and Pauline Powledge and Gaetano Borriello and Bill Schilit},
	Booktitle = {Pervasive},
	Date-Added = {2009-04-10 06:22:00 -0700},
	Date-Modified = {2009-04-10 06:22:12 -0700},
	Title = {{P}lace {L}ab: Device Positioning Using Radio Beacons in the Wild},
	Year = {2005}}

@article{clark-ccr-july-2005,
	Author = {D. Clark and C. Partridge and R. Braden and B. Davie and S. Floyd and V. Jacobson and K. Kitabi and G. Minshall and K. Ramakrishnan and T. Roscoe and I. Stoica and J. Wroclawski and L. Zhang},
	Date-Added = {2009-04-10 06:21:02 -0700},
	Date-Modified = {2009-04-10 06:21:28 -0700},
	Journal = {SIGCOMM CCR},
	Title = {{Making the World (of Communication) a Different Place}},
	Year = 2005}

@article{minclatency,
	Author = {Francesco Lo Presti and N. G. Duffield and Joe Horowitz and Don Towsley},
	Date-Added = {2009-04-10 06:18:33 -0700},
	Date-Modified = {2009-04-10 06:18:33 -0700},
	Journal = {IEEE/ACM ToN},
	Title = {Multicast-Based Inference of Network-Internal Delay Distributions},
	Year = {2002}}

@inproceedings{feamster07,
	Author = {Yiyi Huang and Nick Feamster and Anukool Lakhina and Jim (Jun) Xu},
	Booktitle = {SIGMETRICS},
	Date-Added = {2009-04-10 06:17:59 -0700},
	Date-Modified = {2009-04-10 06:17:59 -0700},
	Title = {Diagnosing network disruptions with network-wide analysis},
	Year = {2007}}

@inproceedings{needle,
	Author = {Jian Wu and Zhuoqing Morley Mao and Jennifer Rexford and Jia Wang},
	Booktitle = {NSDI},
	Date-Added = {2009-04-10 06:17:36 -0700},
	Date-Modified = {2009-12-10 12:37:08 -0800},
	Keywords = {BGP,rootcause,to read},
	Title = {Finding a Needle in a Haystack: Pinpointing Significant {BGP} Routing Changes in an {IP} Network},
	Year = {2005}}

@inproceedings{ipapproach,
	Author = {Ramana Rao Kompella and Jennifer Yates and Albert Greenberg and Alex C. Snoeren},
	Booktitle = {NSDI},
	Date-Added = {2009-04-10 06:16:14 -0700},
	Date-Modified = {2009-04-10 06:16:14 -0700},
	Title = {{IP} Fault Localization Via Risk Modeling},
	Year = {2005}}

@inproceedings{shaikh:nsdi04,
	Author = {Aman Shaikh and Albert Greenberg},
	Booktitle = {NSDI},
	Date-Added = {2009-04-10 06:15:14 -0700},
	Date-Modified = {2009-04-10 06:15:14 -0700},
	Title = {{OSPF} Monitoring: Architecture, Design and Deployment Experience},
	Year = 2004}

@inproceedings{feamster,
	Author = {Nick Feamster and David G. Andersen and Hari Balakrishnan and M. Frans Kaashoek},
	Booktitle = {SIGMETRICS},
	Date-Modified = {2007-10-09 05:20:18 -0700},
	Title = {Measuring the effects of {I}nternet path faults on reactive routing},
	Year = {2003}}

@inproceedings{netdiagnoser,
	Author = {Amogh Dhamdhere and Renata Teixeira and Constantine Dovrolis and Christophe Diot},
	Booktitle = {CoNEXT},
	Date-Added = {2009-04-10 06:14:02 -0700},
	Date-Modified = {2009-04-10 13:30:55 -0700},
	Keywords = {tr-reach},
	Title = {{NetDiagnoser: Troubleshooting network unreachabilities using end-to-end probes and routing data}},
	Year = {2007}}

@techreport{not-an-option,
	Abstract = {A wide variety of enhancements to the Internet architecture have been proposed over the past several years, many of which require attaching metadata, or state, to packets as they flow through the network. Examples of such extensions are IP traceback and XCP. The IP specification supports an "options" mechanism as an extensible way to couple state with packets. However, as we will show in this paper, IP options are not well supported in the Internet. We make use of the PlanetLab planetary scale network testbed to quantify the fate of IP-option enabled packets in the wide-area. We measured wide-area paths with both standard IP packets and packets with options. We discovered that approximately half of Internet paths drop packets with options, raising serious dependability issues. Surprisingly, our findings indicate that it is feasible to restore support for options in the wide-area. We discovered that the core of the network drops very few options packets, with the vast majority of those drops occurring in edge AS networks. Furthermore, these drops are concentrated in a minority of the ASes.},
	Annote = {- vast majority of path drops are concentrated in only 15% of ASes they observed
- 139 PL sites to 160 PL sites
- 67% success w NOP option, 54% w RR, 35% w TS
 - between 85 and 92% of the drops of packets with options occur at the edge ASes.
},
	Author = {Fonseca, R. and Porter, G. and Katz, R.H. and Shenker, S. and Stoica, I.},
	Date-Added = {2009-04-10 03:48:06 -0700},
	Date-Modified = {2010-05-16 17:16:46 -0700},
	Institution = {EECS Department, University of California, Berkeley},
	Title = {{IP} Options are not an option},
	Year = {2005}}

@misc{renesys-brazil-leak,
	Date-Added = {2009-04-10 00:00:36 -0700},
	Date-Modified = {2009-04-10 00:01:06 -0700},
	Key = {renesys},
	Note = {\url{http://www.renesys.com/blog/2008/11/brazil-leak-if-a-tree-falls-in.shtml}},
	Title = {{R}enesys blog, {B}razil Leak}}

@misc{renesys-youtube-hijack,
	Date-Added = {2009-04-10 00:00:36 -0700},
	Date-Modified = {2009-04-10 00:01:06 -0700},
	Key = {renesys},
	Note = {\url{http://www.renesys.com/blog/2008/02/pakistan-hijacks-youtube-1.shtml}},
	Title = {{R}enesys blog, {P}akistan hijacks {Y}ou{T}ube}}

@misc{planetlab,
	Date-Added = {2009-04-10 00:00:36 -0700},
	Date-Modified = {2009-04-10 00:01:06 -0700},
	Key = {planetlab},
	Note = {\url{http://www.planet-lab.org}},
	Title = {{P}lanet{L}ab Website}}

@misc{mlab,
	Date-Added = {2009-04-10 00:00:36 -0700},
	Date-Modified = {2009-04-10 00:01:06 -0700},
	Key = {measurement lab},
	Note = {\url{http://www.measurementlab.net/}},
	Title = {{M}easurement {L}ab Website}}

@misc{isi-hitlist,
	Date-Added = {2009-04-09 23:59:22 -0700},
	Date-Modified = {2010-02-28 18:27:06 -0800},
	Key = {internet address hitlist dataset},
	Note = {\url{http://www.isi.edu/ant/lander}},
	Title = {{Internet address hitlist dataset, PREDICT ID USC LANDER internet\_address\_hitlist\_it28w\-beta\-20090914.}}}

@misc{iplane-website,
	Date-Added = {2009-04-09 23:59:22 -0700},
	Date-Modified = {2009-04-09 23:59:22 -0700},
	Key = {iplane},
	Note = {\url{http://iplane.cs.washington.edu}},
	Title = {{iPlane}}}

@inproceedings{chen04,
	Author = {Yan Chen and David Bindel and Hanhee Song and Randy H. Katz},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-09 23:58:03 -0700},
	Date-Modified = {2009-05-28 15:37:33 -0700},
	Keywords = {to read},
	Title = {An algebraic approach to practical and scalable overlay network monitoring},
	Year = {2004}}

@inproceedings{policy-routing-inflation,
	Author = {Hongsuda Tangmunarunkit and Ramesh Govindan and Scott Shenker},
	Booktitle = {SPIE ITCOM Workshop on Scalability and Traffic Control in IP Networks},
	Date-Added = {2009-04-09 11:16:59 -0700},
	Date-Modified = {2009-04-09 11:17:21 -0700},
	Keywords = {policy inference},
	Title = {{I}nternet path inflation due to policy routing},
	Year = {2001}}

@inproceedings{pathselection,
	Abstract = {The path taken by a packet traveling across the Internet depends on a large number of factors, including routing protocols and per-network routing policies. The impact of these factors on the end-to-end performance experienced by users is poorly understood. In this paper, we conduct a measurement-based study comparing the performance seen using the "default" path taken in the Internet with the potential performance available using some alternate path. Our study uses five distinct datasets containing measurements of "path quality", such as round-trip time, loss rate, and bandwidth, taken between pairs of geographically diverse Internet hosts. We construct the set of potential alternate paths by composing these measurements to form new synthetic paths. We find that in 30-80% of the cases, there is an alternate path with significantly superior quality. We argue that the overall result is robust and we explore two hypotheses for explaining it.},
	Annote = {measured pairwise, looked at composing existing paths to construct alternatives

5 pairwise datasets
- construct graph where nodes are hosts, edges are paths
- in most of them, weight edges by long-term average (RTT, loss rate, bandwidth)
- remove the actual path, then do shortest path calculation

2 datasets are paxsons
others are traceroute servers, i think},
	Author = {Stefan Savage and Andy Collins and Eric Hoffman and John Snell and Thomas Anderson},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-09 11:15:50 -0700},
	Date-Modified = {2009-04-12 17:50:32 -0700},
	Keywords = {policy inference,tr-delay},
	Title = {The end-to-end effects of {I}nternet path selection},
	Year = {1999},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/316188.316233}}

@inproceedings{lakshmi-ucb,
	Author = {Lakshminarayanan Subrmanian and Sharad Agarwal and Jennifer Rexford and Randy H.Katz},
	Booktitle = {INFOCOM},
	Date-Added = {2009-04-09 03:28:33 -0700},
	Date-Modified = {2009-04-09 03:28:42 -0700},
	Title = {Characterizing the {I}nternet Hierarchy from Multiple Vantage Points},
	Year = {2002}}

@article{gao,
	Author = {Lixin Gao},
	Date-Added = {2009-04-09 03:27:31 -0700},
	Date-Modified = {2009-04-09 03:28:09 -0700},
	Journal = {IEEE/ACM TON},
	Title = {On inferring autonomous system relationships in the {I}nternet},
	Year = {2001},
         volume = {9},
          number = {6},
            year = {2001},
             issn = {1063-6692},
              pages = {733--745},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/90.974527}}

@article{multihoming-optimizing,
	Annote = {designing algos for effective smart routing:
Based on real traffic demands, but the multihoming is based on an abstract model.},
	Author = {Goldenberg,, David K. and Qiuy,, Lili and Xie,, Haiyong and Yang,, Yang Richard and Zhang,, Yin},
	Date-Added = {2009-04-09 03:05:21 -0700},
	Date-Modified = {2009-04-09 03:07:05 -0700},
	Journal = {SIGCOMM CCR},
	Keywords = {multihoming},
	Title = {Optimizing cost and performance for multihoming},
	Year = {2004}}

@inproceedings{multihoming-experiences,
	Annote = {We useda trace-driven 
emulation approach to evaluate the performance of these 
schemes whenever possible. We collected packet traces in 
a randomweek fromthe access router of an engineering 
companythat hasanInternet accesslinkrunningat 500Kbps. },
	Author = {Fanglu Guo and Jiawu Chen and Wei Li and Tzi-cker Chiueh},
	Booktitle = {INFOCOM},
	Date-Added = {2009-04-09 03:02:47 -0700},
	Date-Modified = {2009-04-09 03:04:29 -0700},
	Keywords = {multihoming},
	Title = {Experiences in Building a Multihoming Load Balancing System},
	Year = {2004}}

@article{stub-engineering,
	Abstract = {Today, most multi-connected autonomous systems (AS) need to control the flow of their interdomain traffic for both performance and economical reasons. This is usually done by manually tweaking the BGP configurations of the routers on an error-prone trial-and-error basis. In this paper, we demonstrate that designing systematic BGP-based traffic engineering techniques for stub ASes are possible. Our approach to solve this traffic engineering problem is to allow the network operator to define objective functions on the interdomain traffic. Those objective functions are used by an optimization box placed inside the AS that controls the interdomain traffic by tuning the iBGP messages distributed inside the AS. We show that the utilization of an efficient evolutionary algorithm allows to both optimize the objective function and limit the number of iBGP messages. By keeping a lifetime on the tweaked routes, we also show that providing stability to the interdomain path followed by the traffic is possible. We evaluate the performance of solution based on traffic traces from two stub ASes of different sizes. Our simulations show that the interdomain traffic can be efficiently engineered by using not more than a few iBGP advertisements per minute.Our contribution in this paper is to demonstrate that by carefully thinking the design of the interdomain traffic engineering technique, stub ASes can engineer their outbound traffic over relatively short timescales, by exclusively tweaking their BGP routes, and with a minimal burden on BGP. Systematic BGP-based traffic engineering for stub ASes is thus possible at a very limited cost in terms of iBGP messages.},
	Annote = {- most stub ASes are multihomed
- based on traces from 2 stub ASes
- looks like the multi-homing aspects are based on simulations from looking at routeviews},
	Author = {Uhlig,, Steve and Bonaventure,, Olivier},
	Date-Added = {2009-04-09 02:50:05 -0700},
	Date-Modified = {2009-04-09 02:54:50 -0700},
	Journal = {SIGCOMM CCR},
	Keywords = {multihoming},
	Title = {Designing {BGP}-based outbound traffic engineering techniques for stub {AS}es},
	Year = {2004}}

@inproceedings{multihomed-heirarchy,
	Annote = {- based its results on measurements for a single stub network with 2 providers
- found that bc of AS hierarchy the different paths tended to merge, so RTT difference is due to path up to merge point (return path???)},
	Author = {Sanghwan Lee and Zhi-Li Zhang and Srihari Nelakuditi},
	Booktitle = {IMC},
	Date-Added = {2009-04-09 02:46:50 -0700},
	Date-Modified = {2009-04-09 02:48:44 -0700},
	Keywords = {multihoming},
	Title = {Exploiting {AS} hierarchy for scalable route selection in multi-homed stub networks},
	Year = {2004}}

@inproceedings{atmen,
	Annote = {ATMEN is a triggered measurement infrastructure for communicating/coordinating across various adminstrative entities
ATMEN nodes can trigger measurements at remote sites, or query ongoing passive or historical data
measurements can be turned on/off due to events
avoid wasted measurements by reusing: spatial, temporal, application reuse},
	Author = {Balachander Krishnamurthy and Harsha V. Madhyastha and Oliver Spatscheck},
	Booktitle = {WWW},
	Date-Added = {2009-04-09 00:45:19 -0700},
	Date-Modified = {2009-04-10 14:46:51 -0700},
	Keywords = {coordination},
	Title = {ATMEN: A Triggered Network Measurement Infrastructure},
	Year = {2005}}

@inproceedings{kompella-blackholes,
	Annote = {within an ISP

pairwise probes to detect loss
15 minute intervals

max coverage algo (based on known paths, since you are the ISP) to explain the pattern of failures seen},
	Author = {Ramana Kompella and Jennifer Yates and Albert Greenberg and Alex Snoeren},
	Booktitle = {INFOCOM},
	Date-Added = {2009-04-09 00:17:56 -0700},
	Date-Modified = {2009-04-09 00:18:08 -0700},
	Title = {Detection and Localization of Network Black Holes},
	Year = 2007}

@techreport{wang-feamster,
	Author = {Feng Wang and Nick Feamster and Lixin Gao},
	Date-Added = {2009-04-09 00:04:06 -0700},
	Date-Modified = {2009-04-09 00:04:06 -0700},
	Institution = {{Univ. of Massachusetts, Amherst}},
	Title = {Quantifying the effects of routing dynamics on end-to-end {I}nternet Path Failures},
	Year = 2005}

@inproceedings{ipmp3,
	Annote = {ability to identify point of performance fault on fwd/rev paths from a single point would be useful (such as loss, reordering, queueing)

},
	Author = {Matthew Luckie and Tony McGregor},
	Booktitle = {ACM SIGCOMM Workshop on Network Troubleshooting},
	Date-Added = {2009-04-08 23:30:24 -0700},
	Date-Modified = {2009-04-08 23:35:08 -0700},
	Keywords = {active},
	Title = {Path Diagnosis with {IPMP}},
	Year = {2004}}

@inproceedings{IPMP2,
	Annote = {path and delay in a single packet exchange, as well as clock info

used in NLANR AMP, mainly on paths in I2

81% of paths showed no bias, ICMP vs IPMP
the others were split in terms of which was higher, though the IPMP ones are only rarely much larger},
	Author = {Matthew Luckie and Tony McGregor},
	Booktitle = {PAM},
	Date-Added = {2009-04-08 23:21:54 -0700},
	Date-Modified = {2009-04-08 23:29:41 -0700},
	Keywords = {active, one-way delay},
	Title = {{IPMP}: {IP} Measurement Protocol},
	Year = {2002}}

@inproceedings{IPMP,
	Abstract = {Packet probing is an important Internet measurement technique, supporting the investigation of packet delay, path, and loss. Current packet probing techniques use Internet Protocols such as the Internet Control Message Protocol (ICMP), the User Datagram Protocol (UDP), and the Transmission Control Protocol (TCP). These protocols were not originally designed for measurement purposes. Current packet probing techniques have several limitations that can be avoided. The IP Measurement Protocol (IPMP) is presented as a protocol that addresses several of the limitations discussed.},
	Annote = {this paper focuses on delay
current probing not suitable for delay at router level
clock sync hard/expensive

problems w existing approaches:
A. Separation of Path and Delay Measurements (in load balancing and under heavy load)
B. Limited Ability to Measure to a Router 
C. Limited Consideration of Protocol Encapsulation (protocal-based filtering)
D. Limited Clock Support 

IPMP
- routers insert path records1},
	Author = {Matthew Luckie and Tony McGregor and Hans-Werner Braun},
	Booktitle = {IMW},
	Date-Added = {2009-04-08 23:13:15 -0700},
	Date-Modified = {2009-04-08 23:21:50 -0700},
	Keywords = {active,one-way delay},
	Title = {Towards Improving Packet Probing Techniques},
	Year = {2001}}

@inproceedings{bgp-multiple-perspectives,
	Abstract = {There have been many studies on measuring and interpreting inter-domain routing dynamics. Most of them, however, are based on the approach of off-line and passive post-processing BGP routing updates. We propose a new methodology that uses real-time and active monitoring to troubleshoot various BGP routing anomalies. This paper focuses on a specific BGP routing problem -- missing routes that occur when some ASes can reach a prefix while others can't. The idea is to periodically monitor the BGP routing status at multiple vantage points, like Route Views, and when a possible missing route event is detected issue traceroute queries from various looking glasses to learn of the packet-forwarding path status. By comparing previous and current packet-forwarding paths, we can have an idea of where the missing route event takes place. This paper examines the plausibility of this methodology and discusses preliminary experimental results.},
	Annote = {they try to locate events in the AS peering topology
methodology mirrors the manual investigation that operators do

using looking glasses, they could not scale to the "ideal" of having a routing map from every looking glass to every prefix (w/o overloading looking glasses)

at 1 per minute, they instead TR from each LG to each AS (not prefix), so they can check for which PEERINGS it can reach, but this only helps localization in case of peering failures, update every 10 days

supplement this with a division of prefixes across LG, so each prefix is assigned to 3-4, updated every 3-4 days

each LG only sees ~12% of AS peerings (out of routeviews?  not clear, but probably), and the marginal is usually less than 1% for additional LGs

they choose one prefix per 15 min RV update
- withdrawn from at least 2 
- all ASes along those routes are reachable from some LG

in 11 of 378 events, they found some peering along the (old?) path was unreachable.  not clear what they do if the TR path changed but works

then choose one per st
- withdrawn at least 2
- >3 LG TRs to prefix

10% of events they can find a suspect peering this way},
	Author = {Chang,, Di-Fa and Govindan,, Ramesh and Heidemann,, John},
	Booktitle = {ACM SIGCOMM Workshop on Network Troubleshooting},
	Date-Added = {2009-04-08 21:57:02 -0700},
	Date-Modified = {2009-04-10 13:33:25 -0700},
	Keywords = {bgp,active,failures,monitoring,passive, coordination,tr-reach},
	Title = {Locating {BGP} Missing Routes Using Multiple Perspectives},
	Year = {2004}}

@inproceedings{revtr,
	Author = {Ethan Katz-Bassett and Harsha V. Madhyastha and Vijay Kumar Adhikari and Colin Scott and Justine Sherry and Peter van Wesep and Arvind Krishnamurthy and Thomas Anderson},
	Booktitle = {NSDI},
	Date-Added = {2009-04-08 15:07:35 -0700},
	Date-Modified = {2010-05-01 02:14:40 -0700},
	Title = {Reverse Traceroute},
	Year = {2010}}

@inproceedings{etomic2,
	Author = {E. Magana and D. Morato and M. Izal and J. Aracil and F. Naranjo and F. Astiz and U. Alonso and I. Csabai and P. Haga and G. Simon and J. Steger and G. Vattay},
	Booktitle = {IEEE IPOM},
	Date-Added = {2009-04-08 15:03:37 -0700},
	Date-Modified = {2009-04-08 15:06:33 -0700},
	Keywords = {testbed},
	Title = {{The European Traffic Observatory Measurement Infraestructure (ETOMIC)}},
	Year = {2004}}

@inproceedings{etomic,
	Author = {D. Morato and E. Magana and M. Izal and J. Aracil and F. Naranjo and F. Astiz and U. Alonso and I. Csabai and P. Haga and G. Simon and J. Steger and G. Vattay},
	Booktitle = {TRIDENTCOM},
	Date-Added = {2009-04-08 15:00:23 -0700},
	Date-Modified = {2009-04-08 15:03:31 -0700},
	Keywords = {testbed},
	Title = {{The European Traffic Observatory Measurement Infraestructure (ETOMIC)}: A testbed for universal active and passive measurements},
	Year = {2005}}

@phdthesis{harsha-thesis,
	Annote = {Availability of 10 paths from the source to 
random destinations increases the fraction of paths for which the optimal policy could get 
the AS path exactly right from just over 60% to over 80%},
	Author = {Harsha V. Madhyastha},
	Date-Added = {2009-04-08 14:57:36 -0700},
	Date-Modified = {2009-06-08 13:19:23 -0700},
	School = {Univ. of Washington},
	Title = {An Information Plane for {Internet} Applications},
	Year = {2008}}

@misc{octant-website,
	Date-Modified = {2008-02-13 21:51:01 -0700},
	Key = {octant},
	Note = {\url{http://www.cs.cornell.edu/~bwong/octant/}},
	Title = {Octant: A Framework for the Geolocation of {I}nternet Hosts}}

@inproceedings{zheng-hijack,
	Annote = {did not read much of it
monitor from select PL sites, look for hop count changes or changes in last AS comparing destination to last router before it},
	Author = {Changxi Zheng and Lusheng Ji and Dan Pei and Jia Wang and Paul Francis},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-07 19:06:06 -0700},
	Date-Modified = {2009-04-07 19:09:16 -0700},
	Keywords = {hijack,active},
	Title = {A Light-Weight Distributed Scheme for Detecting {IP} Prefix Hijacks in Realtime},
	Year = {2007}}

@inproceedings{hu-hijack,
	Annote = {from ispy related work (havent read):
- shows that BGP-only systems may false pos on legitimate but anomalous BGP updates
- uses control and data plane
- real-time
-  require privileged access to live BGP feeds},
	Author = {X. Hu and Z. Morley Mao},
	Booktitle = {IEEE Security and Privacy},
	Date-Added = {2009-04-07 18:50:38 -0700},
	Date-Modified = {2009-04-07 18:52:49 -0700},
	Keywords = {hijack,active,passive,bgp},
	Title = {Accurate Real-time Identification of IP Prefix Hijacking},
	Year = {2007}}

@article{maggs-multihoming,
	Annote = {journal version of:
A measurement-based analysis of multihoming maggs-multihoming-measurement
and maybe
 Multihoming performance benefits: an experiment evaluation of practical enterprise strategies

emulated multihoming by choosing cities in which multiple akamai measurement nodes were single-homed to different providers, to look at performance benefits of k-multihoming

and then looks at practical solutions for route control

multihoming provides potentially large performance benefits},
	Author = {Akella,, Aditya and Maggs,, Bruce and Seshan,, Srinivasan and Shaikh,, Anees and Sitaraman,, Ramesh},
	Date-Added = {2009-04-07 16:01:07 -0700},
	Date-Modified = {2009-04-07 16:02:51 -0700},
	Journal = {IEEE/ACM TON},
	Keywords = {multihoming,policy inference},
	Title = {On the Performance Benefits of Multihoming Route Control},
	Year = {2008}}

@techreport{as-completeness-bkp,
	Annote = {Our findings call for new ways of inferring AS-level connectivity that do not rely solely on the use of active/passive measurements from vantage points, and our preliminary results towards this direction look promising.

they have access to the peerings of C some large content provider who says they peer with 80-90% of ASes at each IXP
so their technique is to just assume it peers with everyone at the IXPs (and take the hit when they are wrong).  pretty stupid},


	Author = {Ricardo Oliveira and Dan Pei and Walter Willinger and Beichuan Zhang and Lixia Zhang},
	Date-Added = {2009-04-05 00:47:24 -0700},
	Date-Modified = {2009-04-05 00:55:05 -0700},
	Institution = {UCLA},
	Keywords = {topology,tr-topo,representativeness},
	Title = {Quantifying the Completeness of the Observed {I}nternet {AS}-level Structure},
	Year = {2008}}


@article{as-completeness,
 author = {Oliveira, Ricardo and Pei, Dan and Willinger, Walter and Zhang, Beichuan and Zhang, Lixia},
 title = {The (in)completeness of the observed internet AS-level structure},
 journal = {IEEE/ACM Trans. Netw.},
 issue_date = {February 2010},
 volume = {18},
 number = {1},
 year = {2010},
 issn = {1063-6692},
 pages = {109--122},
 numpages = {14},
 url = {http://dx.doi.org/10.1109/TNET.2009.2020798},
 doi = {10.1109/TNET.2009.2020798},
 acmid = {1816297},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {border gateway protocol (BGP), interdomain routing, internet topology},
} 

@inproceedings{sidecar,
	Author = {Rob Sherwood and Neil Spring},
	Booktitle = {IMC},
	Date-Added = {2009-04-05 00:24:55 -0700},
	Date-Modified = {2010-03-07 10:58:27 -0800},
	Title = {Touring the {I}nternet in a {TCP} sidecar},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1177080.1177093}}

@inproceedings{ark-aims,
	Author = {Young Hyun},
	Booktitle = {ISMA AIMS},
	Date-Added = {2009-04-05 00:15:17 -0700},
	Date-Modified = {2009-04-05 00:19:13 -0700},
	Title = {Archipelago update and analyses},
	Year = {2009}}

@inproceedings{paxsonspoof,
	Annote = { ``what proportion of routers in today's Internet are slow at generating TE replies?''
the answer to this question is ``few'' which implies that tools such as pathchar and treno practice suffer greatly from slow-path/fast-path differences

generation times are generally in the sub-millisecond},
	Author = {R. Govindan and V. Paxson},
	Booktitle = {PAM},
	Date-Added = {2009-04-04 23:48:56 -0700},
	Date-Modified = {2010-01-13 18:10:53 -0800},
	Title = {Estimating router {ICMP} generation delays},
	Year = {2002}}

@article{cbg,
	Author = {B. Gueye and A. Ziviani and M. Crovella and S. Fdida},
	Date-Added = {2009-04-04 18:53:15 -0700},
	Date-Modified = {2009-04-04 20:47:35 -0700},
	Journal = {IEEE/ACM TON},
	Keywords = {geolocation,tr-geo,tr-delay},
	Title = {Constraint-Based Geolocation of {I}nternet Hosts},
	Year = {2006}}

@misc{ripe-ris,
	Date-Added = {2009-04-04 18:30:44 -0700},
	Date-Modified = {2009-04-09 17:34:09 -0700},
	Key = {riperis},
	Note = {\url{http://www.ripe.net/ris/}},
	Title = {{RIPE RIS}}}

@misc{routeviews,
	Author = {David Meyer},
	Date-Added = {2009-04-04 18:29:56 -0700},
	Date-Modified = {2009-04-04 18:29:56 -0700},
	Howpublished = {\url{http://www.routeviews.org}},
	Title = {Route{V}iews}}

@inproceedings{radargun,
	Author = {Adam Bender and Rob Sherwood and Neil Spring},
	Booktitle = {IMC},
	Date-Added = {2009-04-04 18:29:18 -0700},
	Date-Modified = {2009-04-04 18:29:18 -0700},
	Title = {Fixing {A}lly's Growing Pains with Velocity Modeling},
	Year = {2008}}

@article{dimes,
	Author = {Yuval Shavitt and Eran Shir},
	Date-Added = {2009-04-04 18:22:58 -0700},
	Date-Modified = {2009-04-04 18:23:03 -0700},
	Journal = {SIGCOMM CCR},
	Title = {{DIMES}: Let the {I}nternet Measure Itself},
	Year = 2005}

@misc{ark,
	Date-Added = {2009-04-04 18:21:03 -0700},
	Date-Modified = {2009-04-04 18:21:03 -0700},
	Key = {ark},
	Note = {\url{http://www.caida.org/projects/ark/}},
	Title = {Archipelago Measurement Infrastructure}}

@article{apar,
	Author = {Mehmet H. Gunes and Kamil Sarac},
	Date-Added = {2009-04-04 17:04:22 -0700},
	Date-Modified = {2009-04-04 17:08:19 -0700},
	Journal = {IEEE/ACM TON},
	Title = {Resolving {IP} Aliases in Building Traceroute-Based {Internet} Maps},
	Year = {2008}}

@article{tomo-survey,
	Author = {Mark Coates and Alfred Hero and Robert Nowak and Bin Yu},
	Date-Added = {2009-04-04 16:24:12 -0700},
	Date-Modified = {2009-04-04 16:24:55 -0700},
	Journal = {{IEEE Signal Processing Magazine}},
	Keywords = {tomography},
	Title = {{Internet} Tomography},
	Year = {2002}}

@inproceedings{network-radar,
	Annote = {delay tomography without requiring control of both ends

if you send back-to-back packets to 2 different destinations, they should experience same delay on shared links, so any differences are causes by the unshared portion
repeat this to many pairs to reconstruct logical link delay distributions on all branches

assumes "that the delays experienced on all links beyong the branching point are uncorrelated," but isn't that false for the shared portion of return paths? ok they try to address this with one sentence
they use TCP syn/akk for their RTT

they focus on esimating delay variance of the shared network segment

they evaluate on a network IN THEIR LAB, 4 routers 9 PCs },
	Author = {Yolanda Tsang and Mehmet Yildiz and Paul Barford and Robert Nowak},
	Booktitle = {IMC},
	Date-Added = {2009-04-04 16:10:29 -0700},
	Date-Modified = {2009-04-04 16:28:32 -0700},
	Keywords = {tomography,one-way delay,tr-delay,tr-paths},
	Title = {Network Radar: Tomography from Round Trip Time Measurements},
	Year = {2004}}

@inproceedings{iplane,
	Author = {Harsha V. Madhyastha and Tomas Isdal and Michael Piatek and Colin Dixon and Thomas Anderson and Arvind Krishnamurthy and Arun Venkataramani},
	Booktitle = {OSDI},
	Date-Added = {2009-04-04 15:51:23 -0700},
	Date-Modified = {2009-04-04 15:51:37 -0700},
	Keywords = {tr-delay,tr-geo,tr-paths,tr-topo},
	Title = {{iPlane}: An Information Plane for Distributed Services},
	Year = {2006}}

@inproceedings{tbg,
	Author = {Ethan Katz-Bassett and John P. John and Arvind Krishnamurthy and David Wetherall and Thomas Anderson and Yatin Chawathe},
	Booktitle = {IMC},
	Date-Added = {2009-04-04 15:49:50 -0700},
	Date-Modified = {2009-04-04 15:50:09 -0700},
	Keywords = {tr-delay,tr-geo,tr-paths,tr-topo,geolocation},
	Title = {Towards {IP} geolocation using delay and topology measurements},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1177080.1177090}}

@inproceedings{octant,
	Author = {Bernard Wong and Ivan Stoyanov and Emin Gun Sirer},
	Booktitle = {NSDI},
	Date-Added = {2009-04-04 15:49:46 -0700},
	Date-Modified = {2009-04-04 15:50:29 -0700},
	Keywords = {geolocation,tr-delay,tr-geo,tr-paths,tr-topo},
	Title = {{Octant}: A Comprehensive Framework for the Geolocalization of {Internet} Hosts},
	Year = {2007}}

@inproceedings{mahajan-link-weights,
	Author = {Ratul Mahajan and Neil Spring and David Wetherall and Tom Anderson},
	Booktitle = {IMW},
	Date-Added = {2009-04-04 15:48:04 -0700},
	Date-Modified = {2011-07-06 21:02:10 -0700},
	Isbn = {1-58113-603-X},
	Keywords = {policy inference,tr-paths,tr-topo,tr-delay},
	Location = {Marseille, France},
	Title = {Inferring link weights using end-to-end measurements},
	Year = {2002},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/637201.637237}}

@inproceedings{maggs-multihoming-measurement,
	Abstract = {Multihoming has traditionally been employed by stub networks to enhance the reliability of their network connectivity. With the advent of commercial "intelligent route control" products, stubs now leverage multihoming to improve performance. Although multihoming is widely used for reliability and, increasingly for performance, not much is known about the tangible benefits that multihoming can offer, or how these benefits can be fully exploited. In this paper, we aim to quantify the extent to which multihomed networks can leverage performance and reliability benefits from connections to multiple providers. We use data collected from servers belonging to the Akamai content distribution network to evaluate performance benefits from two distinct perspectives of multihoming: high-volume content-providers which transmit large volumes of data to many distributed clients, and enterprises which primarily receive data from the network. In both cases, we find that multihoming can improve performance significantly and that not choosing the right set of providers could result in a performance penalty as high as 40%. We also find evidence of diminishing returns in performance when more than four providers are considered for multihoming. In addition, using a large collection of measurements, we provide an analysis of the reliability benefits of multihoming. Finally, we provide guidelines on how multihomed networks can choose ISPs, and discuss practical strategies of using multiple upstream connections to achieve optimal performance benefits.},
	Annote = {

 Venugopalan Ramasubramanian, Fabian Kuhn, Dahlia Malkhi, Mahesh Balakrishnan and Aditya Akella. 
``On the Treeness of Internet Latency and Bandwidth'', ACM SIGMETRICS, Seattle, WA, June 2009. 
Acceptance rate: 15% (27/180).  


21. Aditya Akella, Jeffrey Pang, Anees Shaikh, Bruce Maggs and Srinivasan Seshan. ``A Comparison of 
Overlay Routing and Multihoming Route Control'', ACM SIGCOMM, Portland, OR, August 2004. 
Conference acceptance rate: 9% (31/340). 
22. Aditya Akella, Anees Shaikh and Srinivasan Seshan. ``Multihoming Performance Benefits: An 
Experimental Evaluation of Practical Enterprise Strategies'', USENIX Annual Technical Conference, Boston, 
MA, June 2004. Conference acceptance rate: 13% (21/164).  

25. Aditya Akella, Srinivasan Seshan and Anees Shaikh. ``Toward Representative Internet Measurements'', 
3rd New York Metro Area Networking Workshop, New York, NY, September 2003.  





},
	Author = {Akella,, Aditya and Maggs,, Bruce and Seshan,, Srinivasan and Shaikh,, Anees and Sitaraman,, Ramesh},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-04 15:13:56 -0700},
	Date-Modified = {2009-04-09 03:06:48 -0700},
	Keywords = {multihoming,policy inference},
	Title = {A measurement-based analysis of multihoming},
	Year = {2003}}

@article{unmeasured,
	Abstract = {Distance estimation is important to many Internet applications. It can aid a WWW client when selecting among several potential candidate servers, or among candidate peer-to-peer servers. It can also aid in building efficient overlay or peer-to-peer networks that dynamically react to change in the underlying Internet. One of the approaches to distance (i.e., time delay) estimation in the Internet is based on placing Tracer stations in key locations and conducting measurements between them. The Tracers construct an approximated map of the Internet after processing the information obtained from these measurements. This work presents a novel algorithm, based on Algebraic tools, that computes additional distances, which are not explicitly measured. As such, the algorithm extracts more information from the same amount of measurement data. Our algorithm has several practical impacts. First, it can reduce the number of Tracers and measurements without sacrificing information. Second, our algorithm is able to compute distance estimates between locations where Tracers cannot be placed. To evaluate the algorithm's performance, we tested it both on randomly generated topologies and on real Internet measurements. Our results show that the algorithm computes up to 50-200 % additional distances beyond the basic Tracer-to-Tracer measurements.},
	Annote = {builds on IDMaps to extract as much info as possible
 e2e delay measurements, then solve a set of linear equations, assuming either routing is symmetric or clocks are synchronized},
	Author = {Yuval Shavitt and Xiaodong Sun and Avishai Wool and Bulent Yener},
	Date-Added = {2009-04-04 12:16:16 -0700},
	Date-Modified = {2009-04-04 12:27:15 -0700},
	Journal = {IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS},
	Keywords = {one-way delay,tr-paths,tr-delay},
	Number = {1},
	Title = {Computing the Unmeasured: An Algebraic Approach to {I}nternet Mapping},
	Volume = {22},
	Year = {2004}}

@misc{owamp,
	Annote = {owping is an implementations of this that was used for the IMC delay asymmetry paper},
	Author = {Shalunov, S. and Teitelbaum, B. and Karp, A. and Boote, J. and Zekauskas, M.},
	Date-Added = {2009-04-04 12:05:42 -0700},
	Date-Modified = {2009-04-04 12:09:21 -0700},
	Howpublished = {RFC 4656 (Proposed Standard)},
	Keywords = {one-way delay},
	Title = {A One-way Active Measurement Protocol {(OWAMP)}},
	Year = {2006}}

@misc{brice,
	Annote = {Anyway regarding the source-routing experiments, there are still a few
IXPs that we are not able to detect in our traces, so we wanted to
know if source-routed probes can help us.
It seems that lots of PL nodes block such packets at the very
beginning of the path. Nevertheless I could find some nodes which do
not block them, but I receive ICMP "Source routing failed" (!S in
traceroute) very often, which means the packets are blocked somewhere
in the network.
Hopefully they will be blocked far enough to allow us to get some
interesting results. I'm just starting so I don't know yet..},
	Date-Added = {2009-04-04 10:54:13 -0700},
	Date-Modified = {2009-04-04 11:05:36 -0700},
	Key = {personal},
	Keywords = {source routing},
	Title = {{Personal communication with Brice Augustin of Laboratoire d'informatique de Paris 6}}}

@inproceedings{path-diversity,
	Abstract = {Internet Service Providers (ISPs) can exploit path diversity to balance load and improve robustness. Unfortunately, it is difficult to evaluate the potential impact of these approaches without routing and topological data, which are confidential. In this paper, we characterize path diversity in the real Sprint network. We then characterize path diversity in ISP topologies inferred using the Rocketfuel tool. Comparing the real Sprint topology to the one inferred by Rocketfuel, we find that the Rocketfuel topology has significantly higher apparent path diversity. We evaluate heuristics that improve the accuracy of the inferred Rocketfuel topologies. Finally, we discuss limitations of active measurements techniques to capture topological properties such as path diversity.},
	Annote = {looks at path diversity between PoPs in an ISP

possible inaccuracies during probing:
- lack of VPs-- need to enter/exit at all PoPs (and inside a PoP, which is hardest)
- incomplete traceroutes
- changes in the path during a probe (they don't mention load-balancing, but presumably that too)
- incorrect DNS-> PoP mapping

possible inaccuracies from processing
- alias resolution
- adding reverse links

37% (of total number of real sprint links) extra links between PoPs that do connect (so i guess this is between IPs that don't?  i'm confused)},
	Author = {Renata Teixeira and Keith Marzullo and Stefan Savage and Geoffrey M. Voelker},
	Booktitle = {IMC},
	Date-Added = {2009-04-03 21:40:32 -0700},
	Date-Modified = {2009-04-10 14:28:44 -0700},
	Keywords = {topology,tr-topo},
	Title = {In search of path diversity in {ISP} networks},
	Year = {2003}}

@inproceedings{predictive-power,
	Annote = {looks at the predictive power of Rocketfuel-style link weight inference
mainly looks at how accurate Rocketfuel's prior is-- assuming latency=weight, unless other evidence, so minimize that given the other constraints

uses Geant, plus 2 Rocketfuel topologies and assesses predictive power for:
- when you are missing measurements (it says it in terms of missing links?)
- single link failures

studies against a few sets of "real" weights
does well, except against "backbone" network where traffic traverses the backbone regardless of distance
},
	Author = {Andrew Coyle and Miro Kraetzl and Olaf Maennel and Matthew Roughan},
	Booktitle = {IMC},
	Date-Added = {2009-04-03 21:18:29 -0700},
	Date-Modified = {2009-04-03 21:40:29 -0700},
	Keywords = {policy inference, imc 2008},
	Title = {On the Predictive Power of Shortest-Path Weight Inference},
	Year = {2008}}

@inproceedings{revisiting-as-topology,
	Abstract = {The development of veracious models of the Internet topology has received a lot of attention in the last few years. Many proposed models are based on topologies derived from RouteViews [1] BGP table dumps (BTDs). However, BTDs do not capture all AS--links of the Internet topology and most importantly the number of the hidden AS--links is unknown, resulting in AS--graphs of questionable quality. As a first step to address this problem, we introduce a new AS--topology discovery methodology that results in more complete and accurate graphs. Moreover, we use data available from existing measurement facilities, circumventing the burden of additional measurement infrastructure. We deploy our methodology and construct an AS--topology that has at least 61.5% more AS--links than BTD--derived AS--topologies we examined. Finally, we analyze the temporal and topological properties of the augmented graph and pinpoint the differences from BTD--derived AS--topologies.},
	Annote = {bc there are missing links, esp peering, in routeviews, we need something else

Our methodology is based on exploiting BGP dynamics to discover additional 
topological information. In particular we accumulate the AS--path information 
from BGP updates seen from RV to create a comprehensive AS--level topol- 
ogy. The strength of our approach relies on a beneficial side--effect of the prob- 
lematic nature of BGP convergence process.

sired aspect of the interdomain architecture can be used constructively. We find 
that our substantially larger AS--graph retains the power--law property of the 
degree distribution. Finally, we show that our method discovers links of small 
communication importance connecting low and medium--degree ASs, suggesting 
AS--links used for backup purposes and local communication in the periphery of 
the Internet. 
},
	Author = {Xenofontas A. Dimitropoulos and Dmitri V. Krioukov and George F. Riley},
	Booktitle = {PAM},
	Date-Added = {2009-04-03 19:52:49 -0700},
	Date-Modified = {2009-04-03 19:58:24 -0700},
	Keywords = {topology},
	Title = {Revisiting Internet AS-level Topology Discovery},
	Year = {2005}}

@inproceedings{doubletree,
	Author = {Benoit Donnet and Philippe Raoult and Timur Friedman and Mark Crovella},
	Booktitle = {SIGMETRICS},
	Date-Added = {2009-04-03 19:50:49 -0700},
	Date-Modified = {2009-04-03 19:51:29 -0700},
	Title = {Efficient Algorithms for Large-Scale Topology Discovery},
	Year = {2005}}

@inproceedings{improved-doubletree,
	Annote = {this added bloom filters and a few other things on top of doubletree},
	Author = {Benoit Donnet and Timur Friedman and Mark Crovella},
	Booktitle = {PAM},
	Date-Added = {2009-04-03 19:38:09 -0700},
	Date-Modified = {2009-04-03 19:50:47 -0700},
	Title = {Improved Algorithms for Network Topology Discovery},
	Year = {2005}}

@inproceedings{route-similarity,
	Abstract = {Route similarity refers to the similarity of two routes between two nodes and an arbitrary third node. This intuitive concept plays an important role in distributed system deployment and path-edge inference. However, route similarity has not been quantitatively studied from an end-node perspective, and its properties are poorly understood. In this paper, we make an initial effort in quantifying route similarity by investigating a simple metric---RSIM. Using two large-scale traceroute data sets, we show that RSIM can be measured using only a small number of random traceroutes, and that it captures the similarity of both upstream and downstream routes. As a case study, we also describe how to use RSIM to infer shared path edges. We show that if a pair of end nodes have an RSIM value larger than 0.8, they have over 80 % probability of sharing path edges.},
	Annote = {from CMU
We define route similarity as the overlap of two end-to-end routes between two 
nodes and an arbitrary third node. In this definition, we regard routes as a prop- 
erty of end nodes, and route similarity captures the similarity of this property 
for different end nodes.

useful for
- clustering
- path edge inference

RSIM is defined as the ratio between the total 
number of shared links and the total number of links on two routes

twodatasets: theRocketfuel dataset - 30 PL to 120K prefixes
and 
the Matrixdataset. 
matrix - 160 PL nodes, pairwise

for PL, varying the destinations, using the 5K reachable destinations
the larger the benchmark RSIM value is, the less 
sensitive the RSIM values are to the chosen destination.

but even if forward paths are same, reverse might be different},
	Author = {Ningning Hu and Peter Steenkiste},
	Booktitle = {PAM},
	Date-Added = {2009-04-03 19:26:52 -0700},
	Date-Modified = {2009-04-03 19:33:03 -0700},
	Keywords = {tr-paths},
	Title = {Quantifying Internet End-to-End Route Similarity},
	Year = {2006}}

@inproceedings{openmeas,
	Annote = {internet measurement:
High barrier of entry into the field
Requires deep expertise 
Needs professional contacts
Involves significant effort
A frequent result: 
General inferences from small-scale studies

them:
OpenMeas
-Remove dedicated infrastructure
	No dedicated infrastructure!
	All functionality at the end-hosts
	An existing DHT as the glue (OpenDHT)
- Benefits
	Nothing to maintain
	Community orientation
	Lowering the ``barrier of entry'' to the measurements studies
- But limited functionality
	No find-grained time coordination
	Best effort

Measurement requesters
- Deposit requests
- Poll for results
Measurement providers
- Poll for requests
- Deposit results
Watchers (in particular long-term data repositories)
- Poll for results},
	Author = {Mark Allman and Lann Martin and Michael Rabinovich and Kenneth Atchinson},
	Booktitle = {PAM},
	Date-Added = {2009-04-03 17:07:16 -0700},
	Date-Modified = {2009-04-03 17:12:01 -0700},
	Keywords = {pam 2008},
	Title = {On Community-Oriented Internet Measurement},
	Year = {2008}}

@inproceedings{flexmon,
	Abstract = {Researchers need current and historical measurements of In- 
ternet paths. We built and deployed a complete system designed to fill 
these needs: a safe, shareable, multi-user active network measurement 
system probes network paths and reliably records measurements in a 
storage facility with multiple levels of caching, providing users with fast, 
flexible querying. Our system, deployed on PlanetLab for over 20 months, 
has accumulated 940 million measurements and made them publicly 
available in a separate, federated data repository. Our experience shows 
that building and running such a valuable research tool poses significant 
engineering and practical challenges. 
},
	Annote = {Flexmon: a shareable, multi-user active measurement system that 
collects pairwise path data between sites in a network at tunable frequencies, yet 
protects the network from excess traffic

A different design point on the NMS spectrum:
Obtain highly accurate measurements
{\ldots} from a resource-constrained, unreliable network
{\ldots} for multiple simultaneous users
{\ldots} sometimes at high frequency
... and return results fast and reliably

motivating use case is flexlab (nsdi 2007)
- network conditions from PL, emulated in emulab

Frequent simultaneous probing can cause self-interference, and increase cost
Amortize cost of measurements by removing probe duplication across users
Need best possible measurements for models
Measurement accuracy vs resource limits
- they are not all the way there yet (says their slides)

Flexmon
- A measurement service providing shared, accurate, safe, reliable wide area path-oriented measurements
- 2 yrs on PL, data available via web or query interfaces
- can request measurements
- also automatically does all-pairs
Currently use two tools
- fping measures latency. Attempts to distinguish loss/restoration of connectivity from heavy packet loss by increasing probing frequency
- Modified iperf estimates ABW

uses the fping utility to measure latency and detect path outages. 
When a loss occurs, a state machine drives a frequency-adaptive probing process 
to distinguish packet loss from true connectivity failure (in four seconds), and 
to subsequently detect connectivity restoration (within ten seconds). },
	Author = {David Johnson and Daniel Gebhardt and Jay Lepreau},
	Booktitle = {PAM},
	Date-Added = {2009-04-03 16:35:23 -0700},
	Date-Modified = {2009-04-03 17:07:11 -0700},
	Keywords = {pam 2008,tr-delay},
	Title = {Towards a High Quality Path-oriented Network Measurement and Storage System},
	Year = {2008}}

@inproceedings{pam-geoloc-dbs,
	Annote = {looks at:
* Database-driven IP geolocation 
* Measurement-based IP geolocation 
to find
* Geographic resolution of databases

uses 2 commercial databases: MaxMind and Hexasoft

A recent comparison between two such
databases found that their location estimates differed by at least 1000~km for
more than 30\% of all IP addresses tested~\cite{pam-geoloc-dbs}

Werely 
onafreedatabase,HostIP[3], thatcontains1,356,506IPblocks,toperformlookups 
inthetwootherdatabases.ForeachIPblockofHostIP, wetakeanIPaddressanduse 
it tolookupthetwodatabases.

dismiss TBG and Octant by using their own stupid bandwidth-estimating technique:
To illustrate the marginal improvement of complex measurement-based geolocation 
techniques, we do not only consider CBG, but also add to it estimation of the bottle- 
neck bandwidth on the path.

Drawbacks of databases 
* Staleness of the location information 
* Incompleteness of the records within databases 
* Uncertainty on the used sources and methodology 
* Coarse granularity of the region 
* Discrete solution space 

Advantages of databases 
* Easy deployment 
* Fast lookups 
* Resource inexpensive 
* Suited for typical applications 
* Reasonably priced 

30% of their CBG results have areas almost the size of the US!
80-90% the size of portugal!

i think it says that 90% of DB results were outside the cbg region},
	Author = {S.S. Siwpersad and Bamba Gueye and Steve Uhlig},
	Booktitle = {PAM},
	Date-Added = {2009-04-03 14:25:44 -0700},
	Date-Modified = {2009-04-04 19:46:37 -0700},
	Keywords = {pam 2008,tr-delay,tr-geo,geolocation},
	Title = {Assessing the Geographic Resolution of Exhaustive Tabulation},
	Year = {2008}}

@inproceedings{private-wans,
	Abstract = {topology, 
content 
providers, 
private WAN, 
measurement              
 
In this paper we collect and analyze traceroute measurements to show 
that large content providers (e.g., Google, Microsoft, Yahoo!) are 
deploying their own wide-area networks, bringing their networks closer to 
users, and bypassing Tier-1 ISPs on many paths. This trend, should it 
continue and be adopted by more content providers, could flatten the 
Internet topology, and may result in numerous other consequences to 
users, Internet Service Providers (ISPs), content providers, and network 
researchers. 
},
	Annote = {Investigates the degree to which large contect providers are deploying private wide-area networks

*Selected one server from each of the 20 most 
popular content providers (identified by Alexa.com) 
*Queried these servers from 50 public, globally 
distributed tracerouteservers 
*For each discovered path, we: 
*Determined the organization ID for each discovered IP 
address 
*mapped the distinct router IP addresses to Autonomous 
System (AS) numbers to identify hops on Tier-1 ISPs 
*FQDNs and traceroute latency estimates used to 
determine geographic location of routers

compared the paths using four different metrics: 
* Average number of hops on Tier-1 networks 
* Number of paths that involved no Tier-1 ISPs 
* Degree: number of different ISPs a content provider 
connects to 
* Number of geographic locations a content provider's routers 
were found

A dichotomy appears to be forming: 
* Paths to the ``leaders''(such as the ``Big 3''-Google, Yahoo!, 
Microsoft) averaged 1-3 hops on a Tier-1 ISP network 
* Paths to the ``laggards''averaged ~5 hops on a Tier-1 ISP 

only interested in identifying the end points of content provider networks

google is most aggressive

},
	Author = {Phillipa Gill and Martin Arlitt and Zongpeng Li and Anirban Mahanti},
	Booktitle = {PAM},
	Date-Added = {2009-04-03 13:57:30 -0700},
	Date-Modified = {2009-04-03 14:24:22 -0700},
	Keywords = {pam 2008,topology,tr-paths,tr-geo,tr-topo},
	Title = {The Flattening Internet Topology: Natural Evolution, Unsightly Barnacles or Contrived Collapse?},
	Year = {2008}}

@inproceedings{topology-from-bgp,
	Abstract = {This paper describes a method of inferring logical relationships between network prefixes within an Autonomous System (AS) using only passive monitoring of BGP messages. By clustering these prefixes based upon similarities between their update times, we create a hierarchy linking the prefixes within the larger AS. We can frequently identify groups of prefixes routed to the same ISP Point of Presence (POP), despite the lack of identifying information in the BGP messages. Similarly, we observe disparate prefixes under common organizational control, or with long shared network paths. In addition to discovering interesting network characteristics, our passive method facilitates topology discovery by potentially reducing the number of active probes required in traditional traceroute-based Internet mapping mechanisms.},
	Annote = {- clustering methods to derive logical topology
- more detail than topologies constructed only from routing data, no active probing
- cluster based on seeing updates within the same window
- can guide which paths to TR

also took a TR snapshot by tracing to one address in each prefix

evaluate their clustering based on:
- IP address similarity
- Ratio of shared to unshared traceroute path length
- DNS-based PoP comparison},
	Author = {Andersen,, David G. and Feamster,, Nick and Bauer,, Steve and Balakrishnan,, Hari},
	Booktitle = {IMW},
	Date-Added = {2009-04-03 00:18:18 -0700},
	Date-Modified = {2009-04-03 02:24:31 -0700},
	Keywords = {topology,bgp,passive,tr-topo,tr-paths,tr-geo},
	Title = {Topology inference from {BGP} routing dynamics},
	Year = {2002}}

@inproceedings{whereintheworld,
	Abstract = {When your packets travel through the Internet, where exactly do they go? How many users of your web site live in Europe? How will your Internet service be affected by a new trans-pacific cable? To answer these questions you need geographic information. Internet researchers frequently need to map their observed data to specific places. But IP addresses, Autonomous System numbers, and hostnames are values in a logical hierarchy; they contain no geographic information. There is no authoritative database for mapping these identifiers to locations, so several sources of network information must be used, and these sources may be conflicting or incomplete. The large size of the typical data set used in Internet research makes manually mapping many thousands of IP addresses to locations impractical and imprecise; an automated solution is required. In this paper we describe NetGeo, a tool that overcomes these obstacles.

NetGeo is a tool that maps IP addresses, domain names, and Autonomous System (AS) numbers to geographic locations. NetGeo has significant potential to support a variety of tasks: automatic selection of geographically nearby mirror sites; ISP decisions on where to deploy new infrastructure, traffic flow analysis for tariff policy research; regionally-based advertising design, etc. NetGeo is currently being used both in a graphical traceroute tool and for studies of connectivity and traffic flow between countries.

NetGeo can be accessed interactively via the web and through Java and Perl APIs. The NetGeo back-end consists of a database and a collection of Perl scripts for address parsing and heuristic analysis of whois records. To reduce the load on whois servers and to improve performance, NetGeo caches geographic information parsed from previous queries.

Prior to the development of NetGeo, Internet geographic information was not easily available. We look forward to many creative uses of this tool as researchers become aware of its availability.},
	Annote = {uses variety of techniques:
whois
Hostname parsing
DNS LOC},
	Author = {D. Moore and R. Periakaruppan and J. Donohoe and K. Claffy},
	Booktitle = {INET},
	Date-Added = {2009-04-02 19:41:30 -0700},
	Date-Modified = {2009-04-04 19:45:27 -0700},
	Keywords = {tr-geo,geolocation},
	Title = {Where in the World is netgeo.caida.org?},
	Year = {2000}}

@misc{outages,
	Date-Modified = {2008-02-13 21:34:01 -0700},
	Key = {outages},
	Note = {\url{http://isotf.org/mailman/listinfo/outages}},
	Title = {Outages Mailing List}}

@misc{netgeo,
	Abstract = {To find the latitude/longitude values for a target IP address or AS, NetGeo first searches for a record containing the target in its own database. The NetGeo database caches the location information parsed from the results of previous whois lookups, to minimize the load on whois servers. If a record for the target is found in the database, NetGeo returns the requested information, e.g., latitude and longitude. If no matching record is found in the NetGeo database, NetGeo performs one or more whois lookups using the ARIN/APNIC/RIPE whois servers, until a whois record for the target is found.

After obtaining a record from a whois server, the NetGeo Perl scripts parse the whois record and extract location information and the date of last update. The NetGeo parser attempts to extract the city, state (or province, district, etc.), and country from the text of the whois record. For US addresses the parser also extracts the zip code, if possible. If the parser is unable to parse an address it attempts to find an area code or international phone code in the contact section; the phone code is mapped to a country and then the parser attempts to parse the address again, using the hint provided by the phone code. The parser also guesses the country from email addresses with 2-letter TLDs found in the contact section.},
	Annote = {NetGeo technology has been licensed to Ixia, who markets a geographic location product called IxMapping (Discontinued). Ixia's IxMapping services is designed to assist Internet content providers, e-commerce firms, ISPs, and others to track the geographic location of Internet users, destination servers, and provider hardware.

},
	Date-Modified = {2009-04-04 19:47:12 -0700},
	Key = {netgeo},
	Keywords = {geolocation},
	Note = {\url{http://www.caida.org/tools/utilities/netgeo/}},
	Title = {{NetGeo - The Internet Geographic Database}}}

@inproceedings{chang01inferringas-level,
	Abstract = {A number of recent studies characterize AS-level topology of the Internet by exploiting connectivity information 
contained in BGP routing tables. In this paper, we present an alternative method for discovering AS connectivity 
by inferring individual AS connections from the Internet's router-level topology. This methodology has several 
advantages over using BGP routing tables. First, it allows us to obtain AS-level connectivity information at a 
finer granularity -e.g., multiple connections between a pair of ASs. second, we can discover ASs aggregated in 
BGP routing tables and third, we can identify AS border routers, which may allow us to further characterize 
inter-AS connections. Border routers have multiple interfaces, each with an address in a potentially different AS. 
A ma jor challenge of our approach is then to properly map border routers to their corresponding ASs. To this 
end, we present in this paper several mapping rules and heuristic for inferring the ASs of border routers. We 
report on results showing the effectiveness and validity of these rules and heuristic. },
	Annote = {claims to be essentially the first to do IP->AS topology, along with some followup from mercator folks:
H Tangmunarunkit R Govindan S Shenker and D Estrin The impact of routing policy on Internet paths
In Proceedings of IEEE Infocom April

used TRs from B Cheswick Internet mapping project http://www.cs.bell-labs.com/who/ches.map 

router-level graph is from a single source
steps:
- do default BGP-based mapping
- identify border routers by looking for aliases in different ASes.  uses mercator alias technique, but sends the UDP packets source routed (to bypass some sort of filters or something?) (generated lots of complaints).  did not help at all
- then assign routers at borders based on rules: if i have an interface from X, either I am X or one of X's peers.  if i connect to a router in AS X, either i am in X or one of X's peers.  intersect these two, if singleton i am that.  otherwise use harsha's majority algo
- together, these mapped 2000 of 10000 border routers
- use heuristics to fill remaining holes

"Duenotonlytothe 
sheer number of probes that must reachall existingnetworks inthetopologydiscoveryprocess but alsotothe 
heightenedsecurityawarenessof networkadministratorswhotendtoviewlegitimatenetworkdiscoveryeortsas 
maliciousintrusionattempts wefoundthattopologydiscoveryeortsconsistingof simplepathtracingtogreedily 
mapnetworklinkstobenotpractical"},
	Author = {Hyunseok Chang and Sugih Jamin and Walter Willinger},
	Booktitle = {SPIE ITCom},
	Date-Added = {2009-04-02 17:58:36 -0700},
	Date-Modified = {2009-04-02 18:48:20 -0700},
	Keywords = {tr-paths,tr-topo,source routing},
	Title = {Inferring {AS}-level {I}nternet topology from router-level path traces},
	Year = {2001}}

@inproceedings{zhang01-constancy,
	Annote = {uses measurements from NIMI
does not use traceroutes},
	Author = {Yin Zhang and Nick Duffield and Vern Paxson and Scott Shenker},
	Booktitle = {IMW},
	Date-Added = {2009-04-02 17:50:12 -0700},
	Date-Modified = {2009-04-02 17:52:53 -0700},
	Keywords = {nimi},
	Title = {On the Constancy of {I}nternet Path Properties},
	Year = {2001}}

@conference{paris-traceroute,
	Author = {Augustin, B. and Cuvellier, X. and Orgogozo, B. and Viger, F. and Friedman, T. and Latapy, M. and Magnien, C. and Teixeira, R.},
	Booktitle = {IMC},
	Date-Added = {2009-04-02 17:14:22 -0700},
	Date-Modified = {2009-04-02 17:14:22 -0700},
	Title = {Avoiding traceroute anomalies with {Paris} {traceroute}},
	Year = {2006}}

@misc{sarangworld,
	Date-Added = {2009-04-02 17:13:35 -0700},
	Date-Modified = {2009-04-02 17:13:35 -0700},
	Howpublished = {\url{http://www.sarangworld.com/TRACEROUTE/}},
	Key = {Sarangworld},
	Title = {Sarangworld Project}}

@inproceedings{as-level-traceroute,
	Abstract = {Traceroute is widely used to detect routing problems, characterize end-to-end paths, and discover the Internet topology. Providing an accurate list of the Autonomous Systems (ASes) along the forward- ing path would make traceroute even more valuable to researchers and network operators. However, conventional approaches to mapping traceroute hops to AS numbers are not accurate enough. Address registries are often incomplete and out-of-date. BGP routing tables provide a better IP-to-AS mapping, though this approach has significant limitations as well. Based on our extensive measure- ments, about 10% of the traceroute paths have one or more hops that do not map to a unique AS number, and around 15% of the traceroute AS paths have an AS loop. In addition, some traceroute AS paths have extra or missing AS hops due to Internet eXchange Points, sibling ASes managed by the same institution, and ASes that do not advertise routes to their infrastructure. Using the BGP tables as a starting point, we propose techniques for improving the IP-to-AS mapping as an important step toward an AS-level traceroute tool. Our algorithms draw on analysis of traceroute probes, reverse DNS lookups, BGP routing tables, and BGP update messages collected from multiple locations. We also discuss how the improved IP-to-AS mapping allows us to home in on cases where the BGP and traceroute AS paths differ for legitimate reasons.},
	Author = {Zhuoqing Morley Mao and Jennifer Rexford and Jia Wang and Randy H. Katz},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-02 17:11:50 -0700},
	Date-Modified = {2011-07-06 21:02:10 -0700},
	Isbn = {1-58113-735-4},
	Location = {Karlsruhe, Germany},
	Title = {Towards an accurate {AS}-level traceroute tool},
	Year = {2003},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/863955.863996}}

@inproceedings{mercator,
	Annote = { Generals: external knowledge
                 (traceroutes, alias probes, source
                 routing), wide area (whole {I}nternet),
                 active, provides connectivity graph of the
                 whole {I}nternet, primarily complete within
                 transit providers and not stubs 

single source
 informed random address probing
source routing- only 8% of routers supported it
- discovered 1 in 6 of the links they saw
- Many tens of system administrators complained
mercator technique for aliases (UDP respond source address)},
	Author = {Ramesh Govindan and Hongsuda Tangmunarunkit},
	Booktitle = {INFOCOM},
	Date-Added = {2009-04-02 17:10:53 -0700},
	Date-Modified = {2009-04-02 18:50:24 -0700},
	Keywords = {tr-topo, source routing},
	Title = {Heuristics for {I}nternet Map Discovery},
	Year = {2000}}

@inproceedings{padmanabhan02passive,
	Annote = {identifying lossy links in core by passive observation of existing client/server traffic},
	Author = {Venkata N. Padmanabhan and Lili Qiu and Helen J. Wang},
	Booktitle = {IMW},
	Date-Added = {2009-04-02 15:37:27 -0700},
	Date-Modified = {2009-04-02 15:50:52 -0700},
	Keywords = {tomography},
	Title = {Passive network tomography using Bayesian inference},
	Year = {2002}}

@inproceedings{dnsmisname,
	Author = {Ming Zhang and Yaoping Ruan and Vivek Pai and Jennifer Rexford},
	Booktitle = {USENIX Technical Conference},
	Date-Added = {2009-04-02 11:45:55 -0700},
	Date-Modified = {2009-04-04 20:47:18 -0700},
	Keywords = {tr-geo,geolocation},
	Title = {How {DNS} misnaming distorts {I}nternet topology mapping},
	Year = {2006}}

@article{paxson-e2e-dynamics,
	Annote = {using same testbed as paxson-e2e, but looks at tcp transfers rather than traceroutes},
	Author = {Paxson,, Vern},
	Date-Added = {2009-04-02 10:59:14 -0700},
	Date-Modified = {2009-04-02 11:03:25 -0700},
	Journal = {SIGCOMM CCR},
	Number = {4},
	Title = {End-to-end {I}nternet packet dynamics},
	Volume = {27},
	Year = {1997}}

@article{nimi,
	Abstract = {Historically, the Internet has been woefully under-measured and under-instrumented. The problem is only getting worse with the network's ever-increasing size. We discuss the goals and requirements for building a &quot;measurement infrastructure &quot; for the Internet, in which a collection of measurement &quot;platforms &quot; cooperatively measure the properties of Internet paths and clouds by exchanging test traffic among themselves. The key emphasis of the architecture, which forms the underpinnings of the National Internet Measurement Infrastructure (NIMI) project, is on tackling problems related to scale. Consequently, the architecture emphasizes decentralized control of measurements; strong authentication and security; mechanisms for both maintaining tight administrative control over who can perform what measurements using which platforms, and delegation of some forms of measurement as a site's measurement policy permits; and simple configuration and maintenance of platforms},
	Annote = {goal is an architecture that scales, rather than particular analysis},
	Author = {Vern Paxson and Jamshid Mahdavi and Andrew Adams and Matt Mathis},
	Date-Added = {2009-04-02 10:29:05 -0700},
	Date-Modified = {2009-04-02 10:44:19 -0700},
	Journal = {IEEE Communications},
	Keywords = {measurement infrastructure},
	Title = {An architecture for large-scale {I}nternet measurement},
	Volume = {36},
	Year = {1998}}

@inproceedings{bottlenecks,
	Abstract = {Conventional wisdom has been that the performance limitations in the current Internet lie at the edges of the network -- i.e last mile connectivity to users, or access links of stub ASes. As these links are upgraded, however, it is important to consider where new bottlenecks and hot-spots are likely to arise. In this paper, we address this question through an investigation of non-access bottlenecks. These are links within carrier ISPs or between neighboring carriers that could potentially constrain the bandwidth available to long-lived TCP flows. Through an extensive measurement study, we discover, classify, and characterize bottleneck links (primarily in the U.S.) in terms of their location, latency, and available capacity.We find that about 50% of the Internet paths explored have a non-access bottleneck with available capacity less than 50 Mbps, many of which limit the performance of well-connected nodes on the Internet today. Surprisingly, the bottlenecks identified are roughly equally split between intra-ISP links and peering links between ISPs. Also, we find that low-latency links, both intra-ISP and peering, have a significant likelihood of constraining available bandwidth. Finally, we discuss the implications of our findings on related issues such as choosing an access provider and optimizing routes through the network. We believe that these results could be valuable in guiding the design of future network services, such as overlay routing, in terms of which links or paths to avoid (and how to avoid them) in order to improve performance.},
	Annote = {uses TR to identify paths that share IXPs as potential bottlenecks
calculates delay of each hop by difference of RTT
- uses these to estimate prop delay, then to find queueing delays as they increase},
	Author = {Akella,, Aditya and Seshan,, Srinivasan and Shaikh,, Anees},
	Booktitle = {IMC},
	Date-Added = {2009-04-01 18:07:37 -0700},
	Date-Modified = {2009-04-01 18:12:14 -0700},
	Keywords = {tr-paths,tr-delay},
	Title = {An empirical evaluation of wide-area {I}nternet bottlenecks},
	Year = {2003}}

@misc{traceroute,
	Author = {Van Jacobson},
	Date-Added = {2009-04-01 18:03:13 -0700},
	Date-Modified = {2009-04-01 18:04:00 -0700},
	Howpublished = {{\url{ftp://ftp.ee.lbl.gov/traceroute.tar.Z}}},
	Title = {{Traceroute}}}

@inproceedings{geo-resources,
	Annote = {locations of routers, links
look at router location vs population density, link density vs geographic distance

week of skitter traceroutes (last week of 2001), 500K interfaces and 800K links, from 20 sources
mercator data from august 1999, single source, 200k interfaces, 300k links

get locations from Ixia's IxMapper [6] and Akamai's EdgeScape [1]. 
IxMapper uses DNS names
edgescape uses DNS names plus Akamai's access to ISP databases},
	Author = {Lakhina,, Anukool and Byers,, John W. and Crovella,, Mark and Matta,, Ibrahi},
	Booktitle = {IMW},
	Date-Added = {2009-04-01 17:10:44 -0700},
	Date-Modified = {2009-04-04 20:46:55 -0700},
	Keywords = {tr-geo},
	Title = {On the geographic location of {I}nternet resources},
	Year = {2002}}

@inproceedings{geographic-properties,
	Annote = {looks at Circuitousness, impact of multiple ISPs, hot potato/cold potato, geographic fault tolerance etc

uses geotrack (from geoping paper), which uses DNS names
- of .net DNS names, gets locations of 70%
- unclear how many have .net or how it does on others

uses traceroutes from 20 hosts, plus paxsons 1995 data
destinations were:
- 256 univ hosts
- 1205 public library web servers
- 3100 users that connected to online TV guide
- EuroWeb 1092 european webservers
},
	Author = {L. Subramanian and V.N. Padmanabhan and R. Katz},
	Booktitle = {USENIX Technical Conference},
	Date-Added = {2009-04-01 16:56:39 -0700},
	Date-Modified = {2009-04-09 11:18:03 -0700},
	Keywords = {tr-geo},
	Title = {Geographic properties of {I}nternet routing},
	Year = {2002}}

@inproceedings{geoprefix,
	Abstract = {Information about the geographic locality of IP prefixes can be useful for understanding the issues related to IP address allocation, aggregation, and BGP routing table growth. In this paper, we use traceroute data and geographic mappings of IP addresses to study the geographic properties of IP prefixes and their implications on Internet routing. We find that (1) IP prefixes may be too coarse-grained for expressing routing policies, (2) address allocation policies and the granularity of routing contribute significantly to routing table size, and (3) not considering the geographic diversity of contiguous prefixes may result in overestimating the opportunities for aggregation in the BGP routing table.},
	Annote = {3 traceroute datasets
to (1)clients/(2)servers using CoralCDN
(3) breadth from 25 PL sites to 4 addresses per routeviews prefix

undns for locations
20% of clients had locations
63% of servers
27% of breadth

about 1/3 overall, they claim

only 50-60% of reachable IPs have DNS names
},
	Author = {Freedman,, Michael J. and Vutukuru,, Mythili and Feamster,, Nick and Balakrishnan,, Hari},
	Booktitle = {IMC},
	Date-Added = {2009-04-01 16:42:03 -0700},
	Date-Modified = {2009-04-04 20:46:00 -0700},
	Keywords = {geolocation,tr-geo},
	Title = {Geographic locality of {IP} prefixes},
	Year = {2005}}

@inproceedings{geoping,
	Annote = {IP2Geo set of techniques:
-geotrack uses DNS
-geoping
- geocluster uses various DB data (incomplete, inaccurate) and clusters by prefix

they find geocluster most promising},
	Author = {V. Padmanabhan and L. Subramanian},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-04-01 16:40:09 -0700},
	Date-Modified = {2009-04-04 20:47:44 -0700},
	Keywords = {geolocation,tr-geo,tr-delay},
	Title = {An Investigation of Geographic Mapping Techniques for {I}nternet Hosts},
	Year = {2001}}

@article{idmaps,
	Abstract = {from project webpage, not actual abstract:
It is increasingly the case that a given internet interaction can be satisfied by one of a number of internet hosts. In any such interaction a major factor in choosing which host to access is the distance between the interacting hosts. Distance here refers to some internet performance metrics such as latency or bandwidth. The benefit of factoring in distance in the choice of which replicated web server or web cache to access is apparent. Of broader impact would be the use of distance information in the self-configuration of long-term peering relationships between servers providing network services, such as netnews servers, domain name servers, multicast routers, or web caches.

While hosts can measure characteristics of paths using various tools such as ping, traceroute, pathchar, mtrace, etc., having each host conduct performance measurements prior to each internet interaction inevitably leads to high overhead both to the host and to the internet. Hence a useful service for the internet would be one whereby a host could quickly and efficiently learn the distance between two other hosts. To be widely useful, such a service should provide an answer with a delay and overhead less than those of the gains achieved by using the service.

The objective of this research is to explore scalable design alternatives for an architecture to provide Internet Distance Maps Service (IDMaps).},
	Annote = {early latency estimation system by performing measurements between landmarks},
	Author = {Paul Francis and Sugih Jamin and Cheng Jin and Yixin Jin and Danny Raz and Yuval Shavitt and Lixia Zhang},
	Date-Added = {2009-04-01 16:35:33 -0700},
	Date-Modified = {2009-04-04 17:06:28 -0700},
	Journal = {IEEE/ACM TON},
	Month = {October},
	Number = {5},
	Title = {{IDMaps}: A Global {I}nternet Host Distance Estimation Service},
	Volume = {9},
	Year = {2001}}

@unpublished{sosp09-failures,
	Annote = {Consensus was similar to my review: great dataset, but didn't do much with it, esp in terms of implications

This paper analyzes crash reports from 2 large Windows data sets (of users who have opted to provide such data to Microsoft).  The authors look for 3 types of errors in the data that they can safely/easily classify as hardware failures: CPU MCE, one-bit failures in kernel code pages, and failed disk reads.  Analyzing the data, the paper finds that the fault rates are higher than perhaps had been thought, that once a machine has a failure it is more likely to have the same type of failure again, and that many faults are intermittent (as opposed to transient) and cause most of the failures.

Strengths: The paper gives failure rates for consumer PCs "in the wild," along with some results on the nature of these failures.  The authors have great data sets, and they seem to do a good job extracting interesting conclusions from them and explaining the reasoning behind their analysis.  The authors do a good job dealing with some limitations of the data and combining the sets to overcome some of these limitations.  This is not my area, but I still found most of the paper quite readable. 

Weaknesses: While the paper seems to provide a nice measurement study, I wanted a bit more context: how do the types of faults/failures they were able to analyze fit into the larger space of all faults/failures?  do they have hopes of extending their analysis to other faults?  what are the implications of the results, what should people do now that they know about them?

The paper does not seem to make an argument for the implications of its findings, and without that it comes off as "just" a measurement study.

Comments to the authors:
Questions:
Can you give any feeling for the frequency of other events in the dumps, to give some context for the ones you focus on?  Is dealing with these particular issues important, or is it just a byproduct of them being the ones you can pin down?

One thing I was curious about is what you would put in the Windows dumps to help this type of analysis.

I was curious if the reports tell you what the common MCEs are.  Figure 7 was nice.

The absolute number of, for instance, machines that had bit flips and were up for 60 days are extremely low (15, I think?).  Did you see any hardware differences for when those occurred?

Minor points:
Figures 3-5 seem to be numbered out of order compared to when you address them in the text.

Figure 6: Would be nice if you labeled the points (the tops of the bars), to make the log scale more readable.

I liked the footnote about the author's crashing home machine.  The phrasing makes it sound like the computer was replaced, though the previous sentence sounds like the plan was to replace the disk.  Clarify?

Figure 8 is hard to read.  A more descriptive caption might help, and you refer to the rows by number in the text, though they aren't numbered in the table.

Given the hash issue, be a little clearer about what you mean by "8525 machines."

typos:
Intro, last para: "analyzes HE probability" -> the
Section 2, next to last para: "and shown" -> "and show"
Figure 6 caption: "probability crashing" -> "...of crashing"
Section 5: "755,539 from the..." -> "755,539 machines"
Section 6 2nd para: "our our"
6.1 2nd para: "that fall are" -> "that fail are"
Section 7: "analysis in then location" -> "in the" Also unsure if analysis is the correct word?
7.1, para 2: "not not"
Gray's [7,8] classic papers -> Gray's classic papers [7,8] or at the end of the sentence
8: "3 internet services" -> "3 Internet services"  There are also many cap letters that need to be protected in the bib, Windows, NT, LAN, Internet, etc
8, para 5. "While Xu et al..." is not a sentence.  I think it is meant to be combined with "each of these studies..."?  Also, "et al." should not have a period after the "et"},
	Author = {121},
	Date-Added = {2009-04-01 15:46:20 -0700},
	Date-Modified = {2009-05-27 15:42:22 -0700},
	Keywords = {590L spring 2009 SOSP shadow PC},
	Note = {SOSP submission},
	Title = {Cycles, cells and platters: An empirical analysis of hardware failures on a million commodity PCs},
	Year = {2009}}

@inproceedings{rem,
	Abstract = {Often when assessing complex network behavior a single measure- 
ment is not enough to gain a solid understanding of the root causes of the behav- 
ior. In this initial paper we argue for thinking about ``measurement'' as a process 
rather than an event. We introduce reactive measurement (REM), which is a tech- 
nique in which one measurement's results are used to automatically decide what 
(if any) additional measurements are required to further understand some ob- 
served phenomenon. While reactive measurement has been used on occasion in 
measurement studies, what has been lacking is (i) an examination of its general 
power, and (ii) a generic framework for facilitating fluid use of this approach. 
We discuss REM's power and sketch an architecture for a system that provides 
general REM functionality to network researchers. We argue that by enabling the 
coupling of disparate measurement tools, REM holds great promise for assisting 
researchers and operators in determining the root causes of network problems and 
enabling measurement targeted for specific conditions. 
},
	Annote = {We introduce reactive measurement (REM), which is a tech- 
nique in which one measurement's results are used to automatically decide what 
(if any) additional measurements are required to further understand some ob- 
served phenomenon},
	Author = {Mark Allman and Vern Paxson},
	Booktitle = {PAM},
	Date-Added = {2009-03-23 19:19:08 -0700},
	Date-Modified = {2009-04-03 19:58:40 -0700},
	Keywords = {pam 2008},
	Title = {A Reactive Measurement Framework},
	Year = {2008}}

@inproceedings{spectral-probing,
	Annote = {previous techniques to find shared bottleneck require congested link

this just requires ability to momentarily boost queueing delay

uses ideas of signals, interference, crosstalk

they claim traceroute insufficient to find sharing bc:
- only detects layer 3 devices
- disabled behind NATs/ firewalls

use traceroute to check if path is stable (no multipath
for validation (in the case of no sharing if traceroute is through different ASes)},
	Author = {Partha Kanuparthy and Constantine Dovrolis and Mostafa Ammar},
	Booktitle = {IMC},
	Date-Added = {2009-03-23 13:36:09 -0700},
	Date-Modified = {2009-03-23 13:42:01 -0700},
	Keywords = {imc 2008},
	Title = {Spectral Probing, Crosstalk and Frequency Multiplexing in Internet Paths},
	Year = {2008}}

@inproceedings{traceroute-method,
	Annote = {compares ICMP, TCP, UDP traceroutes (and paris variants of ICMP/UDP, plus UDP-Paris DNS that sends a paris DNS request) to list of routable IPs, list of routers, list of major websites

ICMP reaches more destinations and uncovers more AS links
UDP reaches fewest destinations but most IP links (load balanced more often)

gives techniques to infer spoofed traceroute responses and firewall locations

i think they only count AS links that agree w BGP

UDP-paris DNS did not reach many more than UDP-paris

of UDP-paris, ICMP-paris, and TCP, only 2.3% were reachable only w UDP

inferred very few spoofed responses to ICMP

observe different load balancing for different probe types

NANOG traceroute captures info about MPLS

ICMP does not have ports, use ICMP ID/sequence to match up

relationship to my work: they conclude that using more than one method will increase coverage of both IP and AS links.  revtr would probably have an even bigger effect},
	Author = {Matthew Luckie and Young Hyun and Bradley Huffaker},
	Booktitle = {IMC},
	Date-Added = {2009-03-23 11:55:17 -0700},
	Date-Modified = {2009-04-10 14:36:09 -0700},
	Keywords = {imc 2008,active,measurement tools,topology,tr-topo},
	Title = {Traceroute Probe Method and Forward IP Path Inference},
	Year = {2008}}

@inproceedings{as-bigfoot,
	Annote = {aims at answering how we know when we have measured enough, how much is missing

estimage that 700 monitors would see 99.9% of AS links

measurements of Internet: tomography, traceroute, route monitors
they focus on route monitors
- claim most up to date info
- can see dynamics

uses capture-recapture model to estimate},
	Author = {Matthew Roughan and Jonathan Tuke and Olaf Maennel},
	Booktitle = {IMC},
	Date-Added = {2009-03-23 01:06:05 -0700},
	Date-Modified = {2009-04-05 00:45:29 -0700},
	Keywords = {imc 2008,representativeness},
	Title = {Bigfoot, Sasquatch, the Yeti and Other Missing Links: What We Don't Know About the AS Graph.},
	Year = {2008}}

@inproceedings{internet-ecosystem,
	Annote = {classify ASes into "species" based on function and business type
RouteViews and RIPE not sufficient to infer evolution of peering links, so focus on c2p
- bc the number of p2p observed increases w # of monitors, and they lack enough monitors

looks at trends over time in connectivity, etc},
	Author = {Amogh Dhamdhere and Constantine Dovrolis},
	Booktitle = {IMC},
	Date-Added = {2009-03-23 00:48:23 -0700},
	Date-Modified = {2009-03-23 00:53:22 -0700},
	Keywords = {imc 2008,bgp,passive,topology},
	Title = {Ten Years in the Evolution of the Internet Ecosystem},
	Year = {2008}}

@inproceedings{nearest-peer-imc08,
	Annote = {existing solutions, including (1) distance-based sampling, (2) coordinates, and (3) identifier-based sampling use measured inter-peer latencies to drive finding closest peer.  all require: when p1 is handling search for peer of peer p2, p1 should be able to efficiently find closer peer to p2 if one exists.

they argue this works when peers are far apart, not when very close to each other (same campus/ same extended LAN)

this occurs bc local PoP usually has a star topology and assumptions of the existing solutions (which rely on looking at a subset of latencies) do not hold in this setting

datasets:
- 150K azureus peers (to show PoP clusters in real world)
- 22K recursive DNS servers (to show latency conditions)

traceroutes to DNS servers to find ones with same PoP
estimate latency between servers in same domain as sum of latencies between each of them and closest common upstream router (so presumably using hop-by-hop RTT)
use King to measure latencies between hosts in different domains

one of their heuristics to fix this is that peers that share the last, say, 5 hops, are likely in the same network.

how (well) does king work?
how exactly do they get the latencies from servers/peers to the common upstream routers?  (rockettrace) the sum of latencies from each of them to their closest common upstream router
> Yes -- we used the difference between RTTs.
> There isn't an easy way to get one-way latencies, and we did not have
> control over the peers either.

would their heuristic work better w reverse traceroute than forward?

In the DNS dataset/Figure 2, how do you define what is a shared PoP, vs. the shared routers that occur further along the path?  Similarly, when clustering the Azureus data set, how do you define "closest upstream router?"  Is it literally just the last hop on the path before the peer?  Say my path to p1, p2, and p3 end as follows:
... r1 r2 p1
... r1 r2 p2
... r1 r3 p3
Do p1 and p2 end up clustered by r2, and p3 is in a different cluster (based on r3)?  Or can they all end up clustered together bc of r1?
> For the latency predictions in our DNS measurements, we use the closer
> (to the DNS servers being measured) of the last shared PoP and the
> last shared router as the "transit point" between the given DNS
> servers.

> In the Azureus measurements, we use the closest "measurable" common
> router -- by measurable, I mean a common router that gave meaningful
> values for latencies. So in the example you mention, we cluster p1 and
> p2 under r2, and p3 under a different cluster (exactly as you note),
> assuming we were able to get latency measurements to r2. The reason we
> did this, and not cluster all under r3, is that in the latter case, it
> becomes trickier to estimate the distribution of inter-peer latencies
> among all peer-pairs within the cluster. With the former, we end up
> with smaller clusters, so should result in a conservative estimate of
> the actual clustering extent.



},
	Author = {Vivek Vishnumurthy and Paul Francis},
	Booktitle = {IMC},
	Date-Added = {2009-03-21 16:11:58 -0700},
	Date-Modified = {2009-06-08 14:09:57 -0700},
	Keywords = {imc 2008,coordinates},
	Title = {On the Difficulty of Finding the Nearest Peer in P2P Systems},
	Year = {2008}}

@inproceedings{densification,
	Author = {Pedarsani,, Pedram and Figueiredo,, Daniel R. and Grossglauser,, Matthias},
	Booktitle = {SIGMETRICS},
	Date-Added = {2009-03-20 22:16:51 -0700},
	Date-Modified = {2009-03-20 22:17:44 -0700},
	Keywords = {sigmetrics 2008},
	Title = {Densification arising from sampling fixed graphs},
	Year = {2008}}

@inproceedings{goldberg-sigmetrics08,
	Author = {Goldberg,, Sharon and Xiao,, David and Tromer,, Eran and Barak,, Boaz and Rexford,, Jennifer},
	Booktitle = {SIGMETRICS},
	Date-Added = {2009-03-20 21:58:29 -0700},
	Date-Modified = {2009-03-20 22:16:33 -0700},
	Keywords = {sigmetrics 2008},
	Title = {Path-quality monitoring in the presence of adversaries},
	Year = {2008}}

@inproceedings{ispy,
	Author = {Zheng Zhang and Ying Zhang and Y. Charlie Hu and Z. Morley Mao and Randy Bush},
	Booktitle = {SIGCOMM},
	Date-Added = {2009-03-20 21:27:16 -0700},
	Date-Modified = {2009-04-03 02:26:44 -0700},
	Keywords = {SIGCOMM 2008,active,asymmetry,failures,monitoring,planetlab,reverse,hijack,topology,tr-paths,tr-reach},
	Title = {{iSpy}: detecting {IP} prefix hijacking on my own},
	Year = {2008}}

@inproceedings{ballani:hijack,
	Author = {	H. Ballani and P. Francis and and X. Zhang},
	Booktitle = {SIGCOMM},
	Title = {A study of prefix hijacking and interception in the Internet},
	Year = {2007}}

@inproceedings{delay-asymmetry,
	Abstract = {RTT has been widely used as a metric for peer/server selection. How- 
ever, many applications involving closest peer/server selection like streaming, 
tree-based multicast services and other UDP and TCP based services would ben- 
efit more from knowing one-way delay (OWD) rather than RTT. In fact, RTT is 
a compromise solution in most cases and is used to infer forward and reverse de- 
lays by many protocols and applications. They assume forward and reverse delay 
to be equal to half of RTT. 
In this paper we compare and contrast one way delays and corresponding RTTs 
using a wide selection of routes in the Internet. We first measure the extent and 
severeness of asymmetry in forward and reverse OWD in Internet. We then at- 
tempt to isolate the causes of OWD asymmetry by correlating OWD asymmetry 
with the route asymmetry. Finally, we investigate the dynamics of delay asymme- 
try: There exists a weak correlation between the fluctuation of RTT and OWD and 
a strong correlation between OWD change and the corresponding route change.},
	Annote = {argues that OWD is often more relavent than RTT
CV - delay is symmetric
180 GREN nodes and 25 commercial nodes.  82 GREN nodes and 12 commercial nodes after cutting those w bad clock drift
partition into g2g and (c2c, g2c, c2g)
 We found 
that commercial networks exhibit higher levels of asymmetry than education and re- 
search networks. We found a weak correlation between router-level path asymmetry 
and delay asymmetry.

Our findings suggest that proximity-based applications that need information about 
OWD can benefit from accurate OWD measurement as opposed to using half of RTT as 
an approximation. However, OWD measurement requires the cooperation of both end 
hosts. One possible solution to this is to incorporate OWD measurement software as a 
daemon in commodity OSes similarly as the ICMP echo daemon for normal ping. 

router level asymmetry does not imply delay asymmetry whereas delay asymmetry 
implies router level asymmetry. OBVIOUS

NTP drift- 40% have error estimate > 20 ms
Remove trace if
- NTP error estimate > 10ms
	Leaves 82 GREN nodes and 12 commercial nodes
- Sum of NTP error estimate > 3% of RTT for a node pair
	Leaves primarily long distant routes },
	Author = {Abhinav Pathak and Himabindu Pucha and Ying Zhang and Z. Morley Mao and Y. Charlie Hu},
	Booktitle = {PAM},
	Date-Added = {2009-03-09 00:51:15 -0600},
	Date-Modified = {2009-04-03 17:27:01 -0700},
	Keywords = {active,asymmetry,one-way delay,planetlab,representativeness,reverse,pam 2008,tr-delay,tr-paths},
	Title = {{A Measurement Study of Internet Delay Asymmetry}},
	Year = {2008}}

@inproceedings{planetseer,
	Annote = {seems to only use multiple vantage points to identify cases of partial reachability, does not even look at the non-local traceroutes that i can tell},
	Author = {Zhang,, Ming and Zhang,, Chi and Pai,, Vivek and Peterson,, Larry and Wang,, Randy},
	Booktitle = {OSDI},
	Date-Added = {2009-03-01 23:49:16 -0700},
	Date-Modified = {2009-05-26 21:06:50 -0700},
	Keywords = {asymmetry,active,failures,monitoring,planetlab,reverse,rootcause,service,tr-reach},
	Title = {{P}lanet{S}eer: {I}nternet path failure monitoring and characterization in wide-area services},
	Year = {2004}}

@inproceedings{google-whyhigh,
	Annote = {previosly titled:
Troubleshooting Latency-based Server Selection: Why Bringing the Server Near does not Improve Performance
WhyHigh-- Harsha's paper w Google
IMC 2009 submission (notes below on earlier NSDI 2009 submission)
- queueing delays often override the benefits of interacting w a nearby server- "connections to most clients are affected"
- prioritizes which to investigate by common AS path or by common CDN node
- google gathers a latency map by occassionally redirecting to a random CDN node and monitoring TCP
- redirection is actually based on prefix of DNS nameserver resolving for the client
- 40% of connections more than 500ms!
- since measuring RTT from small SYN/ACK packets, transmission delay should be small, so propogation + queueing
- clients in 80% of prefixes are served by the nearest (geographically) node, and 92% to one that is within 10ms of nearest (though may not be true for new nodes in CDN)
- in assessing prop delay, they assume the min delay has no queueing bc they have enough samples to factor it out
- capture queueing by comparing MEDIAN for prefix to min for region, instead of MIN for prefix
-- 40% of prefixes have latency 50ms more than region min
- although 60% of paths change on back to back days (of the 10K prefixes that have median RTT 50ms > min RTT), these ones have identical RTT diff distribution to those that don't change
-- as they point out, doesnt account for rev path changes or for finer granularity changes
- inflation usually affects all prefixes served by a particular AS path, or none, so can group by common path
- how does it look if you don't look across prefix but rather across client?  do some clients account for all the low values?  
-- compare median to client to min to prefix
-- 1/2 prefixes have 1/2 clients with 50ms median inflation
-- 25% prefixes have 80% clients inflated
-- queueing latency inflation seems widespread
-- they do not address trying to isolate the queueing problem

Questions/Suggestions sent to harsha
----------
- the definition of non-identical in the last full para on pg 6 is unclear.  first you say you do it based on IP-level, then you mention PoPs.  which does the 6K number correspond to?  if IP, why mention PoPs?  if PoP, why mention the IP level comparison?
- why not look at rev TTL for min vs median comparison (to see if path is changing)?  do you have it?
- a bit weird to spend time showing how queueing is important, then abandon it.  i didn't go back to see if you did, but make sure to set up the expectation for this.  also might want to speculate a bit about what google could do about the problem
- 4.2 quibble: BGP doesn't necessarily tell you all the alternative paths, does it?  also it is not at all clear what you use the BGP data for.  I guess eventually in 4.5 you use it to identify "Lack of peering," but it is pretty unclear in 4.2 what is coming.
- if you're not tracerouting all the way to the destination, how do you know that a jump in latency to an intermediate node has anything to do with the e2e latency (vs taking a different reverse path back)?
- in 4.3, do you require them to share the entire path to group, or just a segment of the path?  i would think that looking at a common intermediate shared path serving multiple edge ASes would be useful
- 4.4 "unlike previously seen in Figure 3."  The phrase makes it sound like Fig3 showed that it was not the case that new nodes had many prefixes redirected elsewhere, whereas I think what you mean is that Fig 3 showed that overall nodes do not have prefixes redirected elsewhere (and Fig 9 shows that new nodes are the ones that do).
- in 4.5, I don't get how you can differentiate between limited bandwidth, misconfiguration, and traffic engineering cases.  I understand you assume each of them in different cases, but I don't understand how the observations lead to the conclusions/ how they rule out the other possibilities.  Are these just guesses based on the resolution of the cases studies in 5.1?
- Table 1 could use some bolding or indentation to indicate which rows are subrows of others.  As is, I think tables often suggest that the rows are non-overlapping.  Also, are Circuitous Fwd/Rev mutually exclusive?  
- Fig 15 captures fraction inflated paths via transit vs peering, but don't we need to know what overall fraction of paths are transit/peering to judge this graph?
- section 6.  want to throw in a reference to rev tr, say the RIPE or NANOG talk?  or the report we have up on the web.
-------------

NSDI 2009 submission, rejected.  
- replicating content across geographically distributed servers and redirecting clients to closest in terms of latency has emerged as common (CDN)
- most comment redirection is based on latency
- main result: does not guarantee improvements in client performance
- inflation of latencies caused by inefficient Internet routing causes cases of being redirected to father away server
- must identify and troubleshoot sub-optimal paths
- want a way to pinpoint cause of inflation to an AS and identify root cause/ techniques to solve
- major challenge was LACK OF VISIBILITY into reverse path and lack of existing tools to give this view
-- "One of the challenges we faced in identifying network paths with inflated latencies was lack of visibility into the reverse path from the client.  This is specially significant because of the adundance of asymmetric paths in the Internet and the surprising lack of existing tools that can give us this view into the network."
- Netflow records identify entry point, but otherwise you need a node there
- 22% of prefixes experience more than 50ms latency over min for region
- 55% for prefixes served by new CDN nodes (IMC paper claims 45% instead)
- believe path inflation is one of the main causes
- even being redirected to nearest node is not enough
- heuristics to guess when it is reverse path, but only get some cases
- peer w japanese ISP in japan, but inflated reverse path suggested by RTT jump across hops, change in rev TTL, flow records in US.  a legacy of the contect provider's earlier presence in the US only

- once you identify, can influence issues by either advertising more specifics or by influencing the other ISP

LIMITATIONS
- RTT > 500ms from a node in Asia to a bunch of prefixes in Taiwan
- flow records don't explain inflation
- lack of evidence means suspicion of inflation along reverse path is just a theory
- they believe the key limitation is a lack of information about reverse paths from clients back to CDN nodes
- "It is not perfect.  This is a consequence of WhyHigh's partial view of Internet routing and incomplete knowledge of AS boundaries.  In order to more precisely troubleshoot problems and overcome limitations of the current system, we believe WhHigh needs the ability to gather information about the reverse path back from clients to Google's nodes."},
	Author = {Rupa Krishnan and Harsha V. Madhyastha and Sridhar Srinivasan and Sushant Jain and Arvind Krishnamurthy and Thomas Anderson and Jie Gao},
	Booktitle = {IMC},
	Date-Added = {2009-01-27 19:47:57 -0800},
	Date-Modified = {2009-09-09 13:05:51 -0700},
	Keywords = {active,asymmetry,bgp,measurement tools,monitoring,one-way delay,reverse},
	Title = {Moving Beyond End-to-End Path Information to Optimize {CDN} Performance},
	Year = {2009}}

@misc{nanog-conf,
	Date-Added = {2009-01-27 14:40:34 -0800},
	Date-Modified = {2009-04-10 07:33:37 -0700},
	Key = {nanog},
	Title = {{NANOG} 45},
	Year = {2009}}

@misc{ripe-conf,
	Date-Added = {2009-01-27 14:40:34 -0800},
	Date-Modified = {2009-04-10 07:33:37 -0700},
	Key = {ripe},
	Title = {{RIPE} 58},
	Year = {2009}}

@inproceedings{revtr-ripe,
	Author = {Ethan Katz-Bassett},
	Booktitle = {RIPE 58},
	Date-Added = {2009-01-27 14:40:34 -0800},
	Date-Modified = {2009-04-10 07:33:37 -0700},
	Title = {Reverse Traceroute},
	Year = {2009}}

@article{CaesarR05,
	Author = {Matthew Caesar and Jennifer Rexford},
	Citedby = {0},
	Cites = {0},
	Doi = {http://dx.doi.org/10.1109/MNET.2005.1541715},
	Journal = {IEEE Network},
	Number = {6},
	Pages = {5-11},
	Researchr = {http://researchr.org/publication/CaesarR05},
	Tags = {routing},
	Title = {BGP routing policies in ISP networks},
	Volume = {19},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/MNET.2005.1541715}}

@inproceedings{hubble-ripe,
	Author = {Ethan Katz-Bassett},
	Booktitle = {RIPE 56},
	Date-Added = {2009-01-27 14:40:34 -0800},
	Date-Modified = {2009-03-20 19:15:11 -0700},
	Note = {\url{www.ripe.net/ripe/meetings/ripe-56/presentations/Katz-Bassett-Studying_ Black_Holes_with_Hubble.pdf}},
	Title = {Studying Black Holes on the {I}nternet with {H}ubble},
	Year = {2008}}

@inproceedings{revtr-nanog,
	Author = {Ethan Katz-Bassett},
	Booktitle = {NANOG 45},
	Date-Added = {2009-01-27 14:40:34 -0800},
	Date-Modified = {2009-03-20 19:15:11 -0700},
	Note = {\url{http://www.nanog.org/meetings/nanog45/presentations/Tuesday/Katz_reversetraceroute_N45.pdf}},
	Title = {Practical Reverse Traceroute},
	Year = {2009}}

@inproceedings{hubble-nanog,
	Author = {Ethan Katz-Bassett},
	Booktitle = {NANOG 40},
	Date-Added = {2009-01-27 14:40:34 -0800},
	Date-Modified = {2009-03-20 19:15:11 -0700},
	Note = {\url{http://www.nanog.org/meetings/nanog40/presentations/EthanKatzBassett-RealTimeBlackholeAnalysis.pdf}},
	Title = {Real-time Blackhole Analysis with {H}ubble},
	Year = {2007}}

@inproceedings{bgpmon-pub,
	Author = {He Yan and Dave Matthews and Ricardo Oliveira and Lixia Zhang and Kevin Burnett and Dan Massey},
	Booktitle = {In Cybersecurity Applications and Technologies Conference for Homeland Security(CATCH},
	Title = {Bgpmon: A real-time, scalable, extensible monitoring system},
	Year = {2009}}

@inproceedings{bgpmon,
	Author = {Andree Toonk},
	Booktitle = {NANOG 45},
	Date-Added = {2009-01-27 14:40:34 -0800},
	Date-Modified = {2009-03-20 19:15:11 -0700},
	Note = {\url{http://www.nanog.org/meetings/nanog45/presentations/Sunday/Toonk_bgpmon_N45.pdf}},
	Title = {{BGP}mon},
	Year = {2009}}

@inproceedings{nanog-traceroute,
	Annote = { ``the number one
go-to tool is `traceroute',''  but ``[asymmetric paths are] number one plague
of traceroute'' because ``traceroute shows you the forward path only'' and 
``the reverse path itself is completely invisible''~\cite{nanog-traceroute}.

"Most modern networks are actually well run
So simple issues like congestion or routing loops are becoming 
asmallerpercentageofthetotal networkissuesencountered. 
a smaller percentage of the total network issues encountered. 
* And more commonly, the encountered issues are complex 
enough that a na{\"\i}ve traceroute interpretation is utterly useless. 

* How traceroute works 
* Interpreting DNS in traceroute 
 Location Identifiers, Interface Types and Capacities, Router Type and Roles (core, peering, customer), Network Boundaries and Relationships
- Knowing the geographical location of the routers is 
an important first step to understanding an issue.
-- lets you identify incorrect/suboptimal routing, understand interconnections, and identify when high latency is actually expected
- want to identify boundaries bc that is where policy changes (ex: different return paths based on local pref)
- idenifying the relationship (p2p, c2p) can also be helpful (can sometimes tell from DNS)

* Understanding network latency 
how to tell if latency is normal?
- use geoloc
- affected by prioritization/rate-limiting: probing "to it" vs "through it"
- ICMP generation rate limiting:
Juniper 
* Hard limit of 50pps per interface, 250pps on FPC3s 
* Hard limit of 500pps per PFE as of JUNOS 8.3+ 
* Foundry 
* Hard limit of 400pps per interface 
* Force10 
* Hard limit of 200pps or 600pps per interface 

Traceroute is showing you the hops on the forward path. 
* But showing you latency based on the forward PLUS reverse 
paths. Any delays on the reverse path will affect your results!

* Asymmetric paths 
- control your SRC address to affect which reverse path you see
* Multiple paths 
* MPLS and traceroute },
	Author = {Richard A Steenbergen},
	Booktitle = {NANOG 45},
	Date-Added = {2009-01-27 14:40:34 -0800},
	Date-Modified = {2009-03-20 19:15:11 -0700},
	Keywords = {asymmetry,measurement tools,one-way delay,active,reverse},
	Note = {\url{http://www.nanog.org/meetings/nanog45/presentations/Sunday/RAS_traceroute_N45.pdf}},
	Title = {A Practical Guide to (Correctly) Troubleshooting with Traceroute},
	Year = {2009}}

@inproceedings{paris-load-balance,
	Annote = {
NOTES FROM THEIR IMC SLIDES
network operators now widely use the load balancing capabilities of their routers, for traffic engineering, to increase capacity or improve resilience. 

3 types supported: destination, per-flow (Routers use a hash of the IP addresses, protocol, port numbers, to associate packets to a flow.), per-packet (rarest due to reordering). 

15 RON sources, 68K destinations (aiming for one per prefix).  % of src,dst pairs affected by per-dst, per-flow, per-packet: 72/39/2.  Found in 10% of ASes, esp tier 1 (7 of 9).  a few load balancers at key locations in core networks affect many paths.  AT&T widely uses per-dst.  L3 widely uses per-flow.  Per-packet seems to be used mainly at peering between client/provider.   

We call the set of paths between a divergence point and a convergence point, a diamond. 
Then we describe diamonds in terms of length (number of hops, here 3), width (number of paths, here 2), and asymmetry, which is the difference, in hop count, between the longest and shortest path.  More than 50% of per-flow/dst are length 2-3, but 1% are 8 hops or longer.  Length 2 generally means parallel links between same 2 routers in actual topology.  Half of diamonds use only 2 disjoint paths, but a small number are 16 wide (max allowed by routers).  Wide ones may be a bundle of small-capacity links.  Diamonds are either long and narrow or short and wide (no long and wide).  80% are symmetric (all paths same length), otherwise vary from 1-3 difference usually (small number are worse).  Asymmetry could be either different length/same cost or new mechanisms called ``unequal cost multipath'' that allows routers to select paths having slightly different costs.   Max per-flow asymmetry was 8, found in NTT network, where the short one was a tunnel (so maybe the same).

almost all are intra-AS

 Also compare RTTs.  Response is ICMP, which are likely to be balanced, so predict response (which depends on probe) and tweak probe data to fix flow of the response too.  Very little RTT difference-- only 12% have greater than 1 ms.  Only a few cases have a significant delay difference, up to 20 ms.

NOTES FROM  Workshop on End-to-End Monitoring Techniques and Services (E2EMON), May 2007 PRELIMINARY TALK SLIDES
Now we can trace a clean path, but we can only trace one path at a time. Multiple traceroutes towards different destinations, but all traversing the same load balancer, will eventually discover all the paths. This would be the case for Internet cartography applications, which trace towards thousands, or hundreds of thousands destinations. So why would be need a tool to enumerate the paths? Simply because Internet cartography is NOT the most common way people use traceroute. Usually people use it to trace to a single destination. If you allow to trace a single path one at a time, you may diagnose the wrong path, for instance. 

That's why we place our work in the context of tracing from a single source to a single destination. We suggest a new goal for route tracing in this context and propose an adaptive probing strategy. Instead of sending a fixed number of probes per hop as does classic traceroute, we adapt this number according what has been discovered just before. Instead of expecting a single path, we explore the set of possible flow identifiers to enumerate the nexthops of load balancers with a high degree of confidence. Finally, we enrich the output with valuable information on the type of load balancing encountered. 

We tested it by running measurements from a single source located in Paris, towards 5000 randomly selected destinations. 1 round takes 100 minutes.  Detected load balancing to 1700 of them, 30% per flow and 2% per packet.

Observed up to 16 distinct nexthops.  Something surprising: ICMP probing also reveals multiple interfaces per hop, but usually fewer than UDP probing. We found that most of per-flow load balancers also use some fields in the ICMP header to define a flow. 

Instead of varying the port numbers, we vary the destination address in a small prefix block. Our experiments show that per-destination load balancers are even more frequent than per-flow.

Finally, we also propose a method to control the flow on the return path.

can i identify diamonds like they do?
},
	Author = {Brice Augustin and Timur Friedman and Renata Teixeira},
	Booktitle = {IMC},
	Date-Added = {2009-01-03 16:12:29 -0800},
	Date-Modified = {2009-01-03 17:55:41 -0800},
	Keywords = {active,asymmetry,measurement tools,topology},
	Title = {Measuring load-balanced paths in the internet},
	Year = {2007}}

@phdthesis{burch-thesis,
	Annote = {Network Mapping
- single source, lots of destination
- Internet Mapping Project (IMP)
- create visual maps
When IMP began, it was run from Bell Laboratories in Lucent Technology. Daily scans were run 
of Lucent's network. The maps helped debug routing tables, which contained route announcements for 
networks like lsu.edu and the U.S. Postal Service. Although it is not clear if either Louisiana State 
University or the U.S. Postal Service were actually connected to the network, their CIDR blocks should not 
have appeared in the corporate routing tables. 
The somewhat-surprising usefulness of the mapping and related technology resulted in Lucent forming 
a start-up venture to commercialize the technology. This venture, called Lumeta[57], spun-off of Lucent in 
October, 2000, taking the Internet Mapping Project with it. The commercialized version of the software, 
with many features added, is offered as IPsonar by Lumeta. 
One of the features added is the ability to display data using the graph layout. By coloring the edges 
and nodes, the map can show insecure regions, new acquisitions, rare domains (domains with few mapped 
hosts), unexpected networks, and many other forms of data. The data, and the visualization there of, enables 
networks administrators to debug, optimize, and secure their corporate networks.


Alias Resolution
- evaluates existing techniques-- IP ID, UDP, and rate limiting

Estimating the Reverse Route Map
- a novel method to estimate the reverse routing map for a measurement host using the TTL field
- two previously-known ways to determine a set of paths towards a location: traceroutes from remote locations and loose source routing
- his technique: look at possibilities from topology.  eliminate possiblities for which TTL drops are wrong
- uses many more possible initial TTL values than we use
-  algorithm realizing the TTL method consists of two phases
- first phase creates the BestTTL array, which specifies the likely initial TTL value for a host from the final TTL value for a packet from that host and the length of the path from the measurement host to the host. (assumes symmetric/same length)
-  second phase considers all edges in the topology to create the reverse routing map
The traceroute servers yielded 136 paths representing a total of 833 arcs. The input topology contained 
only 396 of these arcs. Of these, 19 (4.8%) were dropped by the TTL method. Thus, the TTL method is 
approximately 95% accurate in maintaining correct arcs. In contrast, only 35.5% of all arcs in the input 
topology were maintained. The bulk of the inaccuracy results from inaccuracies within the measured topol- 
ogy: 437 of the arcs from the traceroute server data (52.5%) were missing from the measured topology. 
Because the topology is considered an input to the TTL method, arcs missing in the input that should have 
been in the output are not counted against the TTL method. Such a large fraction of arcs missing from the 
input topology is, at first, alarming. However, these numbers overstate the incompleteness of the topology.
- does not usually find a single path
- does not really evaluate how correct the paths are

Tracing Anonymous Packets

Monitoring Link Delays with One Measurement Host 
- includes "Monitoring Link Delays with One Measurement Host"
- includes both a general system to determine link delays from end-to-end measurements and a specific system to perform end-to-end measurements from a single measurement host.
- similar to "Computing the unmeasured" but attaches a centralized measurement host and border routers with dedicated asyncrhonous transfer mode (ATM) or MPLS low-delay tunnels
- requirement is similar to full synchronization of endpoints
- a special case of the cyclic path measurement of ``Estimating one-way delays from cyclic-path delay measurements"
- virtual measurements hosts are created by attaching a single measurement host to the border routers via tunnels
-  measurement host contains an ATM card configured with a virtual circuit to each border router in the network
- linear program:
First, the sum of the propagation and the average queue 
delay along each path should be close to the average measured delay for that path. Second, the sum of 
the propagation delay of the links along each path should be near the minimum measured delay for that 
path. Third, in the absence of data to the contrary, propagation delays and average queue delays should be 
approximately symmetric.
- compared to previous work, the assumption that links must be symmetric is replaced with a goal of maximizing symmetry. 
-  Bidirectional 
links are almost universally allocated as a single bidirectional circuit. Because the lengths of the light (or 
electronic) path in each direction along such a link are equal, the propagation delays will be symmetric. It 
is less clear that maximizing the symmetry of queue delays is proper. 
- uses slack variables

Firewall Configuration and Anonymous DNS


takeaways
- 3/5 of IPs rate limit UDP responses},
	Author = {Hal Burch},
	Date-Added = {2008-12-04 19:15:27 -0800},
	Date-Modified = {2009-04-02 17:10:53 -0700},
	Keywords = {active,asymmetry,measurement tools,monitoring,one-way delay,reverse,service,tomography,topology,tr-paths,tr-topo,tr-delay},
	School = {CMU},
	Title = {Measuring an IP network in situ},
	Year = {2005}}

@article{gurewitz-onewaydelay,
	Annote = {in contrast to "Monitoring Link Delays with One Measurement Host" (burch) and  ``Estimating one-way delays from cyclic-path delay measurements," (their earlier work) uses standard measurement packets and does nto rely on any clock synchronization
relies on one-way measurements, without clock sync
one-way measurements between neighboring nodes, pose measurements as contraints to optimization problem
one-way measurements (which include clock offsets) and their combinations impose constraints on one-way delays
they evalutes both least square error (LSE) and maximum entropy (ME)
ME is based on the probability of finding a randomly-hopping packet on any particular link
ME work better in their evaluations
the nodes are in an overlay, not necessarily directly connected
sum along various cyclic paths over which the clock offsets will cancel
the cyclic path is constructed, not directly measured, as the sum of one-way measurements

validated on simulated topologies-- tiny overlay of 5 nodes, 16 links, and 8 node 17 link, 20 node 102 link

``Computing the unmeasured: An algebraic approach to internet mapping" 
- e2e delay measurements, then solve a set of linear equations, assuming either routing is symmetric or clocks are synchronized

},
	Author = {Omer Gurewitz and Israel Cidon and Moshe Sidi},
	Date-Added = {2008-12-03 13:44:19 -0800},
	Date-Modified = {2009-04-04 17:07:00 -0700},
	Journal = {IEEE/ACM TON},
	Keywords = {one-way delay, asymmetry,active,tomography,reverse},
	Title = {One-way delay estimation using network-wide measurements},
	Year = {2006}}

@inproceedings{cyclic-path,
	Author = {Omer Gurewitz and Moshe Sidi},
	Date-Added = {2008-12-03 13:13:49 -0800},
	Date-Modified = {2008-12-03 13:44:16 -0800}}

@inproceedings{path-inflation,
	Annote = {trace driven study of 65 ISPs
novel techniques to infer intra-domain and peering policies from E2E measurements
observe significant degree of helpful non-early-exit and load-balancing
widespread traffic engineering, both intra and inter
intra has minimal impact on path inflation vs (peering/inter)
argue that underlying cause is lack of BGP policy controls to provide convenient engineering

42 vantage points to all prefixes




},
	Author = {Neil Spring and Ratul Mahajan and Thomas Anderson},
	Booktitle = {SIGCOMM},
	Date-Added = {2008-10-29 19:18:02 -0700},
	Date-Modified = {2009-04-03 21:21:09 -0700},
	Keywords = {tr-paths,tr-topo,tr-geo,tr-delay,policy inference},
	Title = {Quantifying the Causes of Path Inflation},
	Year = {2003}}

@inproceedings{as-power-law,
	Annote = {3 snapshots between nov 1997 and dec 1998, with 45% growth, BGP data from NLANR
also uses routers data from~\cite{multicast-trees}
power-law fit of 96% or higher on properties such as node outdegree, frequency of outdegree, and pairs within h hops of each other
benefits of understanding the topology: protocols that take advantage of topological properties, more accurate models for simulations, protocol analysis, and growth projections},
	Author = {Michalis Faloutsos and Petros Faloutsos and Christos Faloutsos},
	Booktitle = {SIGCOMM},
	Date-Added = {2008-10-29 18:06:12 -0700},
	Date-Modified = {2008-10-30 02:26:14 -0700},
	Title = {On Power-law Relationships of the {I}nternet Topology},
	Year = {1999}}

@inproceedings{netdiff,
	Annote = {infer ISP topology
- uses DNS for ISP pops
- maxmind for destination networks
infer ISP performance from entry pop into it to destination network

bc infer path latency using single-ended measurements, discard traceroutes in which forward and reverse paths differ by more than 3 hops
(uses RTT to estimate one-way latency)

misses paths in eg AT&T's hub&spoke topology bc it lacks probers in most of the small cities

uses new undns rules to infer locations, w 2 checks:
- path should not leave a city then return (middle hop likely wrong)
- speed of light-- RTT to back to back hops must increase by at least SOL between cities.  breaks down with asymmetry

},
	Author = {Ratul Mahajan and Ming Zhang and Lindsey Poole and Vivek Pai},
	Booktitle = {NSDI},
	Date-Added = {2008-10-06 23:32:22 -0700},
	Date-Modified = {2009-05-25 19:37:58 -0700},
	Keywords = {active,asymmetry,monitoring,tomography,nsdi 2008,tr-delay,tr-geo,tr-paths},
	Title = {Uncovering performance differences among backbone {ISP}s with {N}etdiff},
	Year = {2008}}

@inproceedings{dimes-vantagepoints,
	Annote = {http://www.eng.tau.ac.il/~udiw/papers/vp.pdf},
	Author = {Yuval Shavitt and Udi Weinsberg},
	Booktitle = {INFOCOM},
	Date-Added = {2008-09-26 22:05:44 -0700},
	Date-Modified = {2009-04-10 07:32:35 -0700},
	Keywords = {active,representativeness,to read,topology,tr-topo},
	Title = {Quantifying the Importance of Vantage Points Distribution in Internet Topology Measurements},
	Year = {2009}}

@inproceedings{oliveira-completeness,
	Annote = {looked at slides, not paper
- "the completeness problem" of AS-level connectivity
- uses ground truth to evaluate (in)completeness of the "public view" (PV) of AS topology
- need observation over time to capture hidden links that are used if primary paths fail
- peer links not advertised upstream
- PV covers almost all links of the Tier-1, in fact covered by a single customer view
- Tier-2 links are covered by a direct customer, but a provider misses the peer links
- PV of stud captures all customer-provider links (if you accumulate over a long enough time)
- content provider that peers heavily in 30 IXPs-- missing most peering links in PV
"In the absence of having a BGP feed 
in each stub AS, there will inevitably 
be gaps in the inferred AS topology 
map ..."
"New inference techniques are needed to 
capture or estimate peer links that do not rely 
solely on measurements from small set of 
vantage points"},
	Author = {Ricardo Oliveira and Dan Pei and Walter Willinger and Beichuan Zhang and Lixia Zhang},
	Booktitle = {SIGMETRICS},
	Date-Added = {2008-09-02 17:43:31 -0700},
	Date-Modified = {2009-03-20 22:16:47 -0700},
	Keywords = {bgp,passive,representativeness,topology,sigmetrics 2008},
	Title = {In Search of the Elusive Ground Truth: The {I}nternet's {AS}-level Connectivity Structure},
	Year = {2008}}

@inproceedings{as-asymmetry,
	Annote = {did not read

only looks at AS-level asymmetry
14% of paths display AS-level asymmetry
a few end-points are consistently members of asymmetric pairs

router-level looked at by same authors in \cite{how-asymmetric-paper}},
	Author = {Yihua He; Faloutsos, M.; Krishnamurthy, S},
	Booktitle = {IEEE GLOBECOM},
	Date-Added = {2008-07-09 20:25:38 -0700},
	Date-Modified = {2008-12-05 17:53:42 -0800},
	Keywords = {asymmetry},
	Title = {Quantifying Routing Asymmetry in the Internet at the AS Level},
	Year = {2004}}

@inproceedings{caida-trends,
	Abstract = {We report results from a longitudinal analysis of the IP traffic workload seen at a single measurement site inside a major Internet traffic exchange point. Using data collected by the NLANR/MOAT Network Analysis Infrastructure (NAI) project [NAI] and analysis software from CAIDA's CoralReef project [CoralReef], we present trends in application usage seen at the NASA Ames Internet Exchange over 10 months, from May 1999 through March 2000. We show changes in the fraction of traffic from streaming media and online gaming, as well as an increase in traffic from new applications such as Napster and IPSEC tunneling. We also show that our data does not indicate any overall change in the TCP/UDP traffic ratio at the Ames Internet Exchange during this period, or significant differences from the analyses by MCI Worldcom and CAIDA in 1998. },
	Annote = {very few packets with options observed in practice},
	Author = {Sean McCreary and kc claffy},
	Booktitle = {ITC Specialist Seminar},
	Date-Added = {2008-07-09 20:06:01 -0700},
	Date-Modified = {2008-07-09 20:07:36 -0700},
	Keywords = {timestamp},
	Title = {Trends in wide area IP traffic patterns - A view from Ames Internet Exchange},
	Year = {2000}}

@inproceedings{rocketfuel,
	Annote = {7 times more links than skitter in selected networks of some ISPs
750 traceroute servers
PROBLEM
router-level ISP topologies
goal: more accurate maps for research

APPROACH
focus on an ISP to get better precision
ISPs publish enough info to reconstruct map

KEY IDEAS
focus per ISP

bgp to direct probes

assumptions to reduce probes

ally
DETAILS
BGP-> which prefixes are server
TR -> what paths are
DNS -> where routers are/ roles
maps-> backbone, PoPs, peering links
balance accuracy vs speed, dont want to overload TR servers
try not to duplicate measurements

BGP to direct probes: if a path includes target AS
- from servers in the beginning of a path to prefixes at end of path
- if all paths to a prefix traverse target, probes from anywhere to the prefix, and from the prefix to anywhere

assume simple case: each TR server has one ingress point, each prefix has one egress point, BGP peers have one early-exit per ingress

3 ISPs validated

brute force all servers to all prefixes, 1 TR per 1.5 min, would take 125 days to complete

use DNS names to assign ASes, not prefix matching
- non-BGP speaking neighbors numbered from provider address space
- edge links between neighbors
- helps prune out DSL etc

RESULTS
validated w 3/10 ISPs
- found every pop
- did not miss any pop-level links, but had some extras
- router accuracy varied
- G, VG, VG->E

validated by probing 60 /24s to see if they missed anything
- they find 64-96% of backbone routers
- access coverage lower

compare the neighbors they see to routeviews.  70%+

if they consider skitter data, they would have trimmed 1-7% of TRs that would have been useful

6% of their TRs did not transit the ISP

ingress filtering throws out a lot of directed probes (in a good way)
same w egress filtering.  however, they miss a lot of egresses (0-20%)
PROS

CONS
mpls map of level 3 is a mess
validation
one-off
scaling to whole internet 

QUESTIONS FOR THEM
- how much do they miss b/c of their probe reduction strategies?
- why did 6% miss the ISP?

QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK
how would we do this now?
how to choose what traceroutes to issue from TR servers/ VPs for iplane?  hubble?  revtr?
what does revtr buy us?
validation?
could set up a system where you request a map of a particular ISP},
	Author = {Neil Spring and Ratul Mahajan and David Wetherall},
	Booktitle = {SIGCOMM},
	Date-Added = {2008-07-07 11:15:02 -0700},
	Date-Modified = {2009-10-28 12:39:48 -0700},
	Keywords = {topology,representativeness,to read,tr-delay,tr-geo,tr-topo},
	Title = {Measuring ISP Topologies with Rocketfuel},
	Year = {2002}}

@webpage{lumeta,
	Abstract = {The project consists of frequent path probes, one to each registered Internet entity. From this, trees are built mapping the paths to most of the networks on the Internet. The specific endpoints or network services on those endpoints are not the goal of this map but rather the subject being mapped here is the topology of the "center" of the Internet.},
	Annote = {maps available on request
also have an IPv6 map

from~\cite{caida-incongruities}, "Construction of IP-level Internet maps was 
also done by Cheswick and Burch [11] who made their traceroutes publicly available in 1999-2001."  that was a bell labs link that now forwards to this},
	Date-Added = {2008-07-07 10:56:06 -0700},
	Date-Modified = {2011-07-06 21:02:10 -0700},
	Keywords = {topology,representativeness},
	Title = {Lumeta - Internet Mapping Project},
	Bdsk-Url-1 = {http://www.lumeta.com/internetmapping/}}

@url{caida-skitter-map,
	Annote = {B. Huffaker, A. Broido, k. claffy, M. Fomenkov, K. Keys, Y.Hyun, and D. Moore, ``Skitter AS Internet 
Graph,'' Apr 2002, http://www.caida.org/analysis/topology/as_core_network/

derived from skitter traceroutes and published periodically as an AS core poster},
	Author = {Bradley Huffaker and Andre Broido and kc claffy and Marina Fomenkov and K. Keys and Young Hyun and D. Moore},
	Date-Added = {2008-07-07 10:48:20 -0700},
	Date-Modified = {2011-07-06 21:02:10 -0700},
	Keywords = {topology,representativeness},
	Title = {Skitter AS Internet Graph},
	Bdsk-Url-1 = {http://www.caida.org/analysis/topology/as_core_network/}}

@url{keynote,
	Date-Added = {2008-07-07 10:27:51 -0700},
	Date-Modified = {2011-07-06 21:02:10 -0700},
	Keywords = {failures,monitoring,service},
	Title = {Keynote Systems},
	Bdsk-Url-1 = {http://www.keynote.com/}}

@url{pingdom,
	Annote = {"focus lies on covering the uptime monitoring needs of 90% of the companies in the world"
$9.95/month basic service, 39.95/month business service
http, tcp, ping, udp checks
sms and email notifications
multiple locations
checks every 1-60 minutes
no installation on your side},
	Date-Added = {2008-07-07 10:22:17 -0700},
	Date-Modified = {2011-07-06 21:02:10 -0700},
	Keywords = {failures,service,monitoring},
	Title = {pingdom},
	Bdsk-Url-1 = {http://www.pingdom.com/}}

@url{downforeveryoneorjustme,
	Annote = {presumably checks the page from multiple locations, but unclear exactly what it does or how.  no description, just gives you an answer},
	Date-Added = {2008-07-07 10:14:13 -0700},
	Date-Modified = {2011-07-06 21:02:10 -0700},
	Keywords = {failures,service,monitoring},
	Title = {downforeveryoneorjustme.com},
	Bdsk-Url-1 = {downforeveryoneorjustme.com}}

@inproceedings{caida-incongruities,
	Abstract = {Researchers investigating topics such as performance, stability, and growth of the Internet often turn 
to BGP routing tables to obtain Internet topology. BGP routing tables provide a mapping from address 
prefixes to autonomous system (AS) paths. Our study, based on hundreds of thousands of traceroutes from 
three locations worldwide, categorizes differences between AS paths obtained from BGP routing tables and 
AS paths derived from traceroute paths. We find much of the disparity results from exchange points ASes 
(which rarely appear in BGP paths) and by groups of ASes under the same ownership . We introduce a 
new AS relationship, common ownership, that reflects the complexities of real-world business relationships 
and practices. We conjecture that the observed difference in size between the cores of an AS graph derived 
from BGP and an AS graph derived from traceroute is due to the visibility of peering at exchange points 
in traceroute paths. 
},
	Annote = {PROBLEM
researchers often use BGP tables to derive topology; how does this differ from what you get from traceroutes converted to AS paths?
\cite{caidi-topology} found that skitter graph had larger core (bidirectional connectivity) than RouteViews graph, even though number of ASes and links is similar.  this paper beings to address why

APPROACH

KEY IDEAS
introduce idea of "common ownership" as an AS relationship

DETAILS
data collected at three locations worldwide 
- At each location we obtained traceroute IP paths and BGP AS paths from two topologically nearby hosts
- skitter monitors in San Jose AboveNet, Amsterdam RIPE, tokyo DNS root server
- BGP routing table of a backbone router located within the same AS and within a few IP hops from each skitter monitor (from routeviews)

one cycle of traceroutes for 12 hours in April 2002
BGP snapshot from middle of that period
each probed at least 140K destinations
throw out any traceroutes that did not reach or have missing hops
discard unmappable addresses (no prefix, reversed space), but not the paths containing them
choose one target per prefix
http://www.pch.net/resources/data/exchange-points

-Since no ready-made list of IX ASes could be found, we compiled our own by querying the ma jor Internet 
registries (ARIN, RIPE, APNIC) and a routing registry (RADB)
- We had available a copy of a 
subset of the ARIN WHOIS database that provides the name and the database ID of the registered owner of 
each AS allocated by ARIN. We grouped records by database ID and by name. Because the name field is free- 
form text entered by the registrant, there is often slight variation in the text supplied by a single organization 
We sorted the records by the name field to put similar 
names near each other despite slight variations and then manually grouped the records. We also applied the 
same method to a file used by the CIDR Report [5] for mapping ASes to the names of organizations

RESULTS
most of differences due to exchange points (dont appear in BGP tables) and multiple ASes under same control
% of mismatches where it is just addition of IXes (by source): 33%, 82%, and 54%.  the 2 high ones are located near exchange points
although most of the paths through IXes are just using them as the peering point, some seem to "shortcut" through in comparison with BGP paths.  
- unclear why
- some ASes at IXes announce the exchange prefix, which can distort the AS path mapping.  they do not investigate how often this happens
36/25/5% due to multiple ASes under same ownership
unexplained by these 2 categories: 43%, 14%, and 44% of the initial incongruent AS paths and 8%, 14%, and 19% of the non-redundant AS paths
- speculate that some may be due to customer ASes at tail of TR AS paths (so provider might do the announcement/aggregate prefixes)
- just over half of the TR AS paths can be derived by inserting into BGP path
- most of the others are substitutions
PROS

CONS 

QUESTIONS FOR THEM

QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK},
	Author = {Young Hyun and Andre Broido and kc claffy},
	Booktitle = {SIGMETRICS},
	Date-Added = {2008-07-04 16:26:38 -0700},
	Date-Modified = {2009-04-10 14:28:24 -0700},
	Keywords = {topology, representativeness, bgp,tr-topo},
	Title = {Traceroute and BGP AS Path Incongruities},
	Year = {2003}}

@misc{skitter,
	Annote = {describes topology measurement infrastructure and tools
advantages and disadvantages of BGP vs IP granularities
visualization techniques
only 18 sources at that point},
	Author = {CAIDA},
	Date-Added = {2008-07-04 15:42:26 -0700},
	Date-Modified = {2009-04-04 23:01:52 -0700},
	Howpublished = {\url{http://www.caida.org/tools/measurement/skitter/}},
	Keywords = {to read,topology,active, measurement tools, bgp, representativeness},
	Title = {{S}kitter project}}

@inproceedings{caida-internet-expansion,
	Annote = {uses RouteBiews data from 97-2001
introduces idea of semiglobal prefixes, looks at standalone prefixes (no super/subset), root prefixes (no superset), subset
1/2 of all prefix reannouncements come from 1% of ASes (backbone, developing countries, govt)
small ASes do not contribute more than their share of routing entries or churn},
	Author = {Andre Broido and Evi Nemeth and kc claffy},
	Date-Added = {2008-07-04 15:19:54 -0700},
	Date-Modified = {2008-07-04 15:42:13 -0700},
	Keywords = {topology,to read,stability,bgp},
	Title = {Internet Expansion, Refinement and Churn}}

@inproceedings{caida-topology,
	Annote = {http://www.caida.org/publications/papers/2001/OSD/topologylocal.pdf
uses milliions of skitter probes to construct DIRECTED IP graph
compares to graphs you get from BGP feeds
looks at things like stub sections of the graph, strongly connected core
core of skitter graph much larger than routeviews graphs, even though links/nodes count is similar (10x i think)

properties of IP-level graph},
	Author = {Andre Broido and kc claffy},
	Booktitle = {SPIE ITCom},
	Date-Added = {2008-07-04 15:17:08 -0700},
	Date-Modified = {2009-04-10 13:48:37 -0700},
	Keywords = {topology,to read,representativeness,tr-topo},
	Title = {Internet topology: connectivity of IP graphs},
	Year = {2001}}

@inproceedings{measurement-framework,
	Author = {R. Teixeira and J. Rexford},
	Booktitle = {ACM SIGCOMM Workshop on Network Troubleshooting},
	Date-Added = {2008-07-04 14:58:03 -0700},
	Date-Modified = {2008-07-04 15:00:18 -0700},
	Keywords = {to read,rootcause},
	Title = {A measurement framework for pinpointing routing changes},
	Year = {2004}}

@inproceedings{anonymous-routers,
	Author = {Bin Yao and Ramesh Viswanathan and Fangzhe Chang and Daniel Waddington},
	Booktitle = {INFOCOM},
	Date-Added = {2008-07-04 13:53:59 -0700},
	Date-Modified = {2009-04-10 14:28:07 -0700},
	Keywords = {to read, topology, measurement tools, active,tomography,tr-topo},
	Title = {Topology inference in the presence of anonymous routers},
	Year = {2003}}

@article{multicast-trees,
	Abstract = {Multicasting has an increasing importance for network applications such as groupware or videoconferencing. Several multicast routing protocols have been defined. However they cannot be used directly in the Internet since most inter-domain routers do no implement multicasting. Thus these protocols are mainly tested either on a small scale inside a domain, or through the Mbon&eacute;, whose topology is not really the same as Internet topology. The purpose of this paper is to construct a graph using actual routes of the Internet, and then to use this graph to compare some parameters - delays, scaling in term of state or traffic concentration - of multicast routing trees constructed by different algorithms - source shortest path trees and shared trees.},
	Annote = {got the takeaway from \cite{barford-marginal-utility}
only skimmed the setup of the paper
PROBLEM

APPROACH
use Loose Source Routing to measure routes from different vantage points
see how many edges/nodes a source adds

KEY IDEAS

DETAILS
12 sources (their network plus 11 of the 5000), 5000 hosts (who had contacted their network and responded to Loose Source Routing and Recording)
summer 1995

RESULTS
the routes from any subset of 6 sources contained nearly 90 % of the nodes and edges ultimately discovered
on average, a source adds only 0.7% ($\pm$ 0.5%) edges and 0.4% ($\pm$ 0.2%) nodes

PROS

CONS 

QUESTIONS FOR THEM

QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK},
	Author = {Jean-Jacques Pansiot and Dominique Grad},
	Date-Added = {2008-06-30 17:32:51 -0700},
	Date-Modified = {2010-03-07 10:58:08 -0800},
	Journal = {SIGCOMM CCR},
	Keywords = {representativeness,tr-topo,tr-paths,source routing},
	Title = {On routes and multicast trees in the {I}nternet},
	Year = {1998}}

@inproceedings{template,
	Annote = {PROBLEM

APPROACH

KEY IDEAS

DETAILS

RESULTS

PROS

CONS 

QUESTIONS FOR THEM

QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK},
	Date-Added = {2008-06-30 17:12:34 -0700},
	Date-Modified = {2008-06-30 17:12:51 -0700},
	Keywords = {template}}

@inproceedings{barford-marginal-utility,
	Abstract = {The cost and complexity of deploying measurement infrastructure in the Internet for the purpose of analyzing its structure and behavior is considerable. Basic questions about the utility of increasing the number of measurements and measurement sites have not yet been addressed which has led to a "more is better" approach to wide-area ,measurement studies. In this paper, we step toward a more quantifiable understanding of the marginal utility of performing wide-area ,measurements in the context of Internet topology discovery. We characterize the observable topology in terms of nodes, links, node degree distribution, and distribution of end-to-end flows using statistical and information-theoretic techniques. We classify nodes discovered on the routes between a set of 8 sources and 1277 destinations to differentiate nodes which make up the so called "backbone" from those which border the backbone and those on links between the border nodes and destination nodes. This process includes reducing nodes that advertise multiple interfaces to single IP addresses. We show that the utility of adding sources beyond the second source quickly diminishes from the perspective of interface, node, link and node degree discovery. We also show that the utility of adding destinations is constant for interfaces, nodes, links and node degree indicating that it is more important to add destinations than sources.},
	Annote = {PROBLEM
[when your goal is to map the topology of the Internet core], how many measurement sources/destinations do you need?  
since we don't have ground truth, instead look at the marginal utility of adding one more source/destination

APPROACH
take the aggregated information from all collected traces as the baseline graph, and we measure how well small subsets of the measurements manage to cover this baseline graph.  

KEY IDEAS
"the fact that additional measurements may provide low marginal coverage does not necessarily imply that the overall coverage obtained is high"

DETAILS
skitter measurements from may 2000
main data set is 8 srcs, 1277 dsts; suplement with 12 srcs, 300K dsts
first dataset is srcsXdsts, 2nd is sparse 
related to harsha's study of how atlas grows as we add measurements from end hosts
they are concerned with nodes/links in the BACKBONE
define node coverage, edge coverage ( |seen|/|total|)
define v_G(k,m) denote expected node coverage of G by k random srcs, m random dsts.  similarly e_G(k,m) for edges
define marginal utility is eg e_G(k,i+1)-e_G(k,i)
"since we are primarily interested in charachterizing the Internet backbone, and since we have no expectation of completely mapping stub domains, we would ideally like to measure the coverage of the Internet backbone"
they do some simple alias resolution (source address-based technique), but results do not look different at interface vs node levvel
they look at information theoretic measurement of marginal utility

RESULTS
utility of adding srcs beyond the 2nd quickly diminishes for interface, node, link, and node degree discovery
- but still increasing.  and we would likely expect a continous small increase until you have srcs in all edge networks
utility of adding dsts remains constant (always helpful at the numbers they work with)

PROS
important to classify this
gives a simple framework for looking at this sort of problem
gives a clear answer over their datasets

CONS 
unclear how this applies over the larger datasets that we care about
and unclear how it applies when you care about the edge, not just the core

QUESTIONS FOR THEM

QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK
are the results true at the numbers we deal with?  what would this study look like with our data?
is this a framework for investigating PL coverage compared to skitter, dimes, TTM, BGP?
how does having a dst in an AS compare to having a src compare to having a BGP feed?
what regions ar hard to discover using traceroute?
their goal is the core, whereas we also care about the edge.  how do the results look different if you consider the edge?  in particular, seems like srcs matter a lot more in our setting.  in theis, with things dst routed, links to core from new srcs don't count once they hit an old link as soon as they enter the core, but new dst routing exposes new chunks of the core},
	Author = {Paul Barford and Azer Bestavros and John Byers and Mark Crovella},
	Booktitle = {IMW},
	Date-Added = {2008-06-30 17:02:11 -0700},
	Date-Modified = {2009-04-10 14:27:47 -0700},
	Keywords = {representativeness,topology,tomography,tr-topo},
	Title = {On the marginal utility of network topology measurements},
	Year = {2001}}

@inproceedings{discarte,
	Annote = {followup to Passenger

PROBLEM
how to align record route (RR) and traceroute probes to get better topologies?

APPROACH
- uses disjunctive logic programming (logical inference and constraint solving technique) to assign interfaces to their RR implementation type, then merge RR and traceroute data

KEY IDEAS
- there are a finite number of RR implementations (in terms of how they are visible to probes, esp how they deal with TTL and TTL expiring probes), often corresponding to major router vendors/models
- we can leverage that fact and observed engineering practices to merge RR and traceroute much better than they were able to with Passenger
- leads to better topologies

DETAILS
- TR topologies suffer from errors due to routers that do not repond to alias resolution probes, anonymous routers, mid-measurement path instabilities, MPLS, and insufficient vantage points
- RR discovers aliases for unresponsive routers, exposes MPLS tunnels, anonymous routers (*'s), hidden routers (do not decrement TTL, sometimes this happens within MPLS), multi-path load balancing, and mid-measurement path instabilities
- w Passenger paper, 40% of data could not be aligned and was unusable, and 11% of inferred aliases were wrong
- TR discovers incoming interface, RR outgoing or internal
- types of router implementations
-- Departing (61.9%) - cisco-- does not update the RR for TTL expiring packets
-- MPLS (13.3%) - also implement the ICMP unreachable MPLS trailers protocol that returns MPLS tunnel identifiers
-- NotImpl (9.1%)
-- Arriving (7.1%) - update on TTL expiring bc RR set when packet arrives.  Juniper
-- Lazy (5.8%) - do not decrement TTL for packets w RR option set.  Cisco's Carrier line
-- Mixed (2.7%) - if packet expires, uses incoming.  else, uses outgoing.  Linux-based IP stacks.

- DLP "has the ability to describe a low-level set of inter-dependent interactions while simultaneously shaping the solution to match high-level constraints"
- any model that violates a strong constraint, and the remaining are assigned costs based on number of weak constraints they violate
- only strong constraint is that a router's RR implementation must be consistent across all its interfaces
- weak constraints in order of weight:
1) no self-loops
2) ends of links tend to be from same /31 or /30
3) aliases inferred with ally are often correct
4) hidden routers are rare, so prefer fewer
5) more routers support RR than are NotImpl

RESULTS
- DisCarte correctly aligns 96% of addresses and reduces false alias rate to 3%
- of 602,136 IPs within 9 hops of vantages, only 8,441 (1%) dropped RR packets (though they see more IPs w RR, so % of routers that drop likely higher)
- enabling IP options breaks load-balancing, spreading a single flow across multiple equal-cost paths
- 374,337 aliases
-- 11.2% of aliases identified were not found with ally
-- 88.3% confirmed with ally, 3.8% denied by IP-identifier, 7.8% were from unresponsive routers
-- 91.2% of the aliases involved IP addresses discovered only by adding the RR option
- more complete alias resolution still required for correct topologies
- no false links in 4 topologies
- abilene, NLR, CANET do not respond to alias resolution probes


PROS
- seems to make the passenger/RR stuff more usable

CONS 

QUESTIONS FOR THEM
- how do they get false alias rate?  looks like by trying to confirm them with ally
- can we get their list of aliases? (sounds like it is available)
- are they going to run it as a service?
- see note in RESULTS above: what % of routers (not IPs they see) drop RR packets?
- look at how they differentiate types of routers, e.g. Abilene=Juniper.  can we get their list of IPs->types?
- why is it useful to identify aliases for things only visibile with RR?
- get their ground truth and alias info to see if we can identify the missing aliases

QUESTIONS FOR US/ IMPLICATIONS FOR OUR WORK
- do we have a RR traceroute tool (meaning one that does both TTL limiting and RR), or just a RR ping tool?
- can we add it to iplane?
- what's the MPLS tunnel identifier stuff?  can we use that?
- dealing w firewall policies.  forged TTL-exceeded messages for packets with RR set
- they believe options (at least RR) are more likely to generate complaints, so use stop lists per-destination.  generate a stoplist of last k IP addresses to each destination from a local machine, by running a reverse traceroute to each dest and record the last 3 hops
- can timestamping add in the missing aliases, esp where >9 hops from everywhere or can't infer correcrly
- they say the only way to improe topologies is to increase the number of vantage points
- inspired by paxson's strategies for sound internet measurement
"meaure the same path and topology using two different methods so that their consistency can ensure an accurate result. ... study small components first (PL before internet), invest in visualization (they use neato and dot), build test suites (they have 77 regression tests including difficult-to-interpret traces and groups of traces)"},
	Author = {Rob Sherwood and Adam Bender and Neil Spring},
	Booktitle = {SIGCOMM},
	Date-Added = {2008-06-29 00:28:13 -0700},
	Date-Modified = {2010-03-24 12:04:24 -0700},
	Keywords = {measurement tools, timestamp, SIGCOMM 2008,tr-topo},
	Title = {DisCarte: A Disjunctive {I}nternet Cartographer},
	Year = {2008}}

@inproceedings{end-system-monitoring,
	Abstract = {Internet routing events are known to introduce severe disruption to applications. So far effective diagnosis of routing events has relied on proprietary ISP data feeds, resulting in limited ISP-centric views not easily accessible by customers or other ISPs. In this work, we propose a novel approach to diagnosing significant routing events associated with any large networks from the perspective of end systems. Our approach is based on scalable, collaborative probing launched from end systems and does not require proprietary data from ISPs. Using a greedy scheme for event correlation and cause inference, we can diagnose both interdomain and intradomain routing events. Unlike existing methods based on passive route monitoring, our approach can also measure the impact of routing events on end-to-end network performance. We demonstrate the effectiveness of our approach by studying five large ISPs over four months. We validate its accuracy by comparing with the existing ISP-centric method and also with events reported on NANOG mailing lists. Our work is the first to scalably and accurately diagnose routing events associated with large networks entirely from end systems.},
	Annote = {- have a paper copy with more notes, but here are highlights
- presented in Hubble session at NSDI 2008
- monitor one ISP at a time from end systems, looking to correlate route changes to probable causes (things that could have changed path selection either internal or BGP)
- greedy scheme for event correlation and cause inference
- "from the perspective of end users, the ability ot diagnose routing disruptions also provides insight into the reliability of ISP networks and ways to improve the network infrastructure as a whole"
- "focus on explaining routing events that the ISP should be held accountable for and can directly address, e.g., internal routing changes and peering session failures"
- uses latency measurements in the probes to quantify the impact of these routing events
- "for internal or intra-domain routing events it is obvious whcih ISP should take responsibility for them.  therefore, we do not focus on constructin detailed intra-domain routing tables."
- each end system acquires its own routing view by daily conducting traceroute to one IP in each prefix
- then try to select a minumum set of traceroute probes that cover all the visible PoP-prefix pairs with a greedy algo (for all PoPs in the target ISP, prefixes in which probes traverse that ISP)
- refreshing this pop-prefix map tends to take 20 minutes per ISP
- "topology discovery could be affected by ISPs' ICMP filtering policy.  fortunately, we find this is performed mostly by ISPs on their edge routeres connecting to customers, which has little impact on our inference"
- for traceroute hops in ISP, map to PoP (using undns)
- for traceroute hops not in ISP, map to AS
- * used as wildcard to map to any ISP or PoP (conservatively)
- discard if two or more consecutive * hops
- discard traceoutes w transient loops
TYPES OF CHANGES (between 2 consecutive measurements)
1) different ingress PoP change
2) same ingress PoP but different egress PoP changes
3) same ingress PoP and same egress PoP changes
- assume that each routing event can be explained by only one cause, choose greedily based on difference between # changes it explains and number of conflicting measurements (evidence graph and conflict graph)
causes based on BGP decision process
type 2) could be
- old-peering-down/ new-peering-up
- old-localpref-decrease/ new-localpref-increase
- old-external-worsen/ new-external-improve (includes withdrawl/announcements, AS path change, MED change, etc)
- old-internal-increase/ new-internal-decrease
type 3) could be
- internal pop change: old-internalincrease/ new-internal-decrease
- next hop AS change: old-peering-down/ new-peering-up, old-external-worsen/new-external-improve
- AS path change, but not next hop - external-as-change

STUDY
- 132 days for 5 backbone ISPs
- probe between 87-371 destinations on average per PL node to get coverage
- for each AS they monitor, they only see 6-18% of the prefixes exported by that AS, so they will miss changes that only affect other prefixes
- (i think considering only prefixes for which they have a traceroute to that prefix through the PoP that originates a BGP feed)  they detect 6-23% of BGP visible changes (next hop AS, AS path change)
-- miss events due to being too short (most of the misses), traceroute filtering (4-15%), small fraction (up to 5%) due to other causes (inaccurate AS mapping, forward path doesnt match BGP data)
- compare to wu's technique which relies on all BGP feeds in an AS, they match ~75%
- for hot-potato changes, false positive rate of 45%, false negative rate of 32%.  for session reset, 60/34%

- how do you know which ISP to monitor?
- seems like a copout to not care about events inside the ISP-- how do you know if it is bad without doing this?
- do they discard all loops or just those that resolve during the traceroute?
- what causes the mistakes vs Wu?
- with false positive and false negative so high, is there really much benefit?
- does this assume routing events are inherently interesting?  why do i care if they don't affect performance?
- who uses this?  it requires significant infrastructure per-ISP, and how do you know which ISP you want to monitor?
-- the types of inferences you can make with this are cool, in terms of tracing it back to likely BGP causes.  how do you see this in use?  if it's PL service, you'd like to monitor all ISPs, but probably can't do that in practice.  how do i know which ISP to monitor, and how does it scale?
-- what's causing high false pos/ false neg?
no dynamic coordination, each monitor just probes the same things over and over},
	Author = {Ying Zhang and Z. Morley Mao and Ming Zhang},
	Booktitle = {NSDI},
	Date-Added = {2008-06-26 15:59:59 -0700},
	Date-Modified = {2009-08-12 12:25:12 -0700},
	Keywords = {monitoring,active,rootcause, nsdi 2008,tr-delay,tr-paths,tr-geo},
	Title = {Effective Diagnosis of Routing Disruptions from End Systems},
	Year = {2008}}

@inproceedings{bgpath,
	Annote = {- examine one particular update [operator looking at own prefix] through route collector data
define:
- local rank of e - # of prefixes whose path at time t as observed by collector c contains e
- global rank of e - # of unique prefixes whose path at time t as observed by any collector contains e
- origin rank of AS v - number of prefixes that at time t are known by c to originate by AS v

first try Macro-Event Detection.  if this fails, go to Fine-Grained Analysis
- among all reliable collectors without any reboots during the time in question, select those that belong to ASes on old or new paths
MACRO-EVENT
- for each edge on old and new, consider the evolution in global rank
- check if it has a "relevant" rank and one near zero, both during the event
- if this fails, do it for local rank for each selected colector separately
- if this fails:
FINE-GRAINED 
- look only at the flows of of prefixes that share at least the first 2 prefixes with either the old or new path

Q:
ARVIND1 - [this class of approaches] too abstract a model of topology 
ARVIND2 - [this class of approaches] doesn't give satisfying answer "we used the system on this problem and fixed it"
- it doesn't help idenfity important problems-- seems like a missing piece is what will make an operator start investigating.  Do you have evidence that operators track updates to their prefixes and want to investigate them?  It seems like that could be an overwhelming amount of data without something to tell them which are interesting.  I would guess that they care about things like unreachability, bad performance, maybe oscillating paths, maybe huge spikes in traffic over certain links.  
- It seems like in the examples that you talk about, simpler techniques like the union-intersection algorithm [Feldmann 2004] would point you in the right direction.  How often does your technique work and this wouldn't, and what is an example?  If the simpler technqiue usually gives you at least a superset of what your technique returns, can you simplify things by starting there?  Naively, I don't understand why you'd need to look at edges that were in both the old and new path; what's an example?  What does your technique add to union/intersection if you only care about your prefix?  It seems like (naively) it adds a sense of how widespread the problem is, but "misses" things if the problem only affects a small number of prefixes (say, load balancing).
- We have different settings-- we are after systems that monitor everything at once, whereas you are after a system to investigate a particular problem.  The stated setting is operators investigating their own prefixes, but the technqiue doesn't seem to leverage this fact, that you have access to your own BGP tables and can issue traceroutes from 
your own network.  Have you thought much about what this can add?
- In the illustrated examples, it seems that the analysis is done after the problem repairs.  I can see how this would be useful if the problem recurs/to prevent it from recuring, but the analysis as presented does not check when that is the case.  When else would it help to do the analysis after things repair?  If the problem anyway corrects itself within a few minutes and the analysis takes this long, why do I need to investigate/ how do I know which of the many events to investigate?
- It seems like historical trends might be a way to differentiate repairs from failures.  Have you looked at this at all?
- Section 4c talking about lrank says "[If the collector is not incident to the edge] any inference supported only by local rank analysis requires further investigation."  What does this investigation entail?
- How do you find appropriate cutoffs for determining if global rank is appropriate? 
- The "compatible" restriction for fine-grained analysis means choosing only those prefixes that share a common origin/provider, right?  So essentially I check how my prefixes are being treated, but ignore everyone elses'.  What's the intuition behind this, as it seems I would care how I was being treated compared to others?
- The end of Section 4 metnions iterative deepening of the analysis.  Do you have an example of how this helps, especially given the use case of an operator who cares about updates to her/his prefixes?
- Is your simulation 1 node per AS?  If so, it seems like this biases towards having events that effect all prefixes on a given link.  Do you know how things change with more realistic topologies?
- It seems from Table II that the grank technique will apply to very few edges (mostly tier 1 edges I would guess).  How often did grank or lrank work over real data?   
- After reading the paper, I was left wondering:
-- how often the technique works for updates when people would actually want to apply it?
-- ... and when something simpler wouldn't?
-- in cases when it doesn't work, what is missing to keep it from working?
POSSIBLE COLLABORATIONS:
- When some prefixes stay on a link and others leave:
-- we might be able to differentiate between multiple peering points for a given AS link.  It seems like a big current limitation of the work is that [if I understand correctly] it only produces a result if the number of prefixes hits 0 in one of the analysis techniques.
-- we can check whether the prefixes that don't leave the link are actually reachable
- We might be able to suggest which prefixes are having problems and hence which you should analyze, and this might lead to your system suggesting other prefixes that experienced similar changes
- We're interested in what operators currently do in terms of interdomain traffic engineering.  It seems like they have tools to manipulate OSPF link weights to get the intradomain traffic balancing they want, but it is less clear they know what to do interdomain.  Have you guys thought about this problem at all?  Do you know what the state of the art is?  It seems like this is a place where these aggregate BGP views might help.

},
	Author = {Alessio Campisano and Luca Cittadini and Giuseppe Di Battista and Tiziana Refice and Claudio Sasso},
	Booktitle = {NOMS},
	Date-Added = {2008-06-24 22:01:59 -0700},
	Date-Modified = {2008-06-26 15:58:32 -0700},
	Keywords = {monitoring, bgp, rootcause,passive},
	Title = {Tracking Back the Root Cause of a Path Change in Interdomain Routing},
	Year = {2008}}

@inproceedings{how-asymmetric-paper,
	Abstract = {Routing asymmetry in the Internet can significantly affect the manner in which we model and simulate its behavior. In 
this paper, we study routing asymmetry in the Internet and present quantitative evaluations on the extent of such asymmetry 
today. Our quantitative evaluations provide a measure of the difference between the forward and reverse paths between two end 
points. Routing asymmetry has not been studied extensively before; this is primarily due to the lack of a systematic approach for 
quantifying asymmetry except for simply computing the difference between the forward and reverse path lengths. By applying 
our framework for representing asymmetry, we quantify routing asymmetry for both US higher education academic networks 
and general commercial networks at two different levels: the Autonomous System (AS) level and the router (or link) level. We 
take into consideration, not only the difference in the forward and reverse path lengths, but also the AS and link identities and 
the sequence in which these entities appear on the paths. We measure the AS level routing asymmetry, and provide upper lower 
bounds on link level routing asymmetry. Our studies show that academic networks appear to be more symmetric than general 
commercially deployed networks. Furthermore, our studies demonstrate that routing asymmetry exhibits a skewed distribution i.e., 
a few end-points seem to display a higher extent of participation on asymmetric routes. 
},
	Annote = {- 6 page version of how-asymmetric-poster SEE NOTES THERE
135 AMP from NLANR           
traceroute servers
- for any 2 entities (link or AS) x and y in a pair of paths, define non-negative base dissimilarity value w[x,y] which represents how different they are
- form a matrix of these values, then calculate minimal composite dissimilarity for each pair of routes
- look at absolute asymmetry (this value) and length-based normalized value
- pick one tracerotue server per AS
- b/c they are dealing w traceroutes (not something like timestamp which will stamp given ANY valid interface), they have to apply heuristics to guess whether 2 interfaces are on the same link
- "traditionally, ... Internet ... do not use subnet masks longer than 30 bits; this requires 4 addresses per link: 2 host addresses, one network address, and one broadcast address." host addresses are 10 and 01 network is 00 and broadcast is 11
- RFC 3021 proposed 31-bit subnet masks in point-to-point links
-- heuristic: 2 IP addresses, one from forward and one from reverse, belong to same p-to-p link if either:
1) differ only in last bit
2) differ in only last 2 bits, which are 01 and 10, and neither 00 nor 11 appear in any traceroutes
-- does not capture non p-to-p links, such as Ethernet or IXPs (often /24)
- compare US GREN vs commercial internet


- poster, i believe that there is a longer version i'll read next
-- On Routing Asymmetry in the Internet ("intended for" Autonomic Networks Symposium in Globecom 2005) [1]
-- Quantifying Routing Asymmetry in the Internet at the AS Level (IEEE GLOBECOM 2004) [2]
- cites previous studies that look at difference in lengths of paths between pairs of nodes
- goal here is to measure the magnitude of routing asymmetry, not just existence
- both AS and router level
- compare US GREN vs commercial internet
- new heuristic to determine if 2 IPs are interfaces of "same link"
-- point-to-point link, the link forms a network (normally a /30 or /31) by itself
-- heuristic: 2 IP addresses, one from forward one from reverse path belong to the same point-to-point link if they belong to the same /31 or the same /30 w their last 2 bits at 01 and 00
-- not all links are p-to-p (some are multiple-access, such as ethernet, esp near the edge), perhaps overestimating amount of asymmetry
--- relax to 1) same /24, 2) same /16, 3) same AS
- commercial has higher % of asymmetry and higher magnitude of it
- skewed-- a few end-points consistently participate in asymmetric paths
- propose Minimal Composite Dissimilarity (MCD)
-- see [2] for details
-- proportional to miminal edit distance

going from same AS heuristic to /30-/31 heuristic,
- 38%-85% of AMP display assymetry (14% at AS level)
- 88-98% of RETRO "" (65% at AS level)
- gren much more symmetric
DATASETS
- AMP NLANR, 135 N.A. GREN
- REverse TraceROute tool (RETRO) 300 ASes in 55 countries
-- i think this is just scripting public traceroute servers
- full mesh measurements

},
	Author = {Yihua He and Michalis Faloutsos and Srikanth Krishnamurthy and Bradley Huffaker},
	Booktitle = {Autonomic Networks Symposium in Globecom},
	Date-Added = {2008-06-16 19:11:31 -0700},
	Date-Modified = {2009-05-25 19:36:02 -0700},
	Keywords = {asymmetry,representativeness},
	Title = {On Routing Asymmetry in the {I}nternet},
	Year = {2005}}

@inproceedings{how-asymmetric-poster,
	Annote = {- poster, i believe that there is a longer version i'll read next
-- On Routing Asymmetry in the Internet ("intended for" Autonomic Networks Symposium in Globecom 2005) [1]
-- Quantifying Routing Asymmetry in the Internet at the AS Level (IEEE GLOBECOM 2004) [2]
- cites previous studies that look at difference in lengths of paths between pairs of nodes
- goal here is to measure the magnitude of routing asymmetry, not just existence
- both AS and router level
- compare US GREN vs commercial internet
- new heuristic to determine if 2 IPs are interfaces of "same link"
-- point-to-point link, the link forms a network (normally a /30 or /31) by itself
-- heuristic: 2 IP addresses, one from forward one from reverse path belong to the same point-to-point link if they belong to the same /31 or the same /30 w their last 2 bits at 01 and 00
-- not all links are p-to-p (some are multiple-access, such as ethernet, esp near the edge), perhaps overestimating amount of asymmetry
--- relax to 1) same /24, 2) same /16, 3) same AS
- commercial has higher % of asymmetry and higher magnitude of it
- skewed-- a few end-points consistently participate in asymmetric paths
- propose Minimal Composite Dissimilarity (MCD)
-- see [2] for details
-- proportional to miminal edit distance

going from same AS heuristic to /30-/31 heuristic,
- 38%-85% of AMP display assymetry
- 88-98% of RETRO ""
- gren much more symmetric
DATASETS
- AMP NLANR, 135 N.A. GREN
- REverse TraceROute tool (RETRO) 300 ASes in 55 countries
-- i think this is just scripting public traceroute servers
- full mesh measurements
},
	Author = {Yihua He},
	Booktitle = {SIGCOMM},
	Date-Added = {2008-06-16 18:46:43 -0700},
	Date-Modified = {2008-06-16 19:11:43 -0700},
	Keywords = {asymmetry, poster, representativeness},
	Title = {How Asymmetric is Internet Routing? A Systematic Approach},
	Year = {2005}}

@inproceedings{tulip,
	Annote = {tulip tool for end-user diagnosis/localization of problems
- uses ICMP timestamps and IP identifier counters to diagnose reordering, loss, and queuing
- usually narrows location of reordering and loss to within 3 hops and queuing to within 4
-- this is based on number of routers that give all the properties they need, for instance respond to ICMP timestamps or give consecutive IP-IDs
- this is ICMP timestamps, not IP
- can differentiate between forward, reverse, or forward + reverse reordering based on IP id of response from router (compared to order in which they were sent to router), plus arrival time at source
- can differentiate forward path loss by sending 3 packets to router.  if only responses to 1st and 3rd, and the response id are consecutive, then forward.  
- if router uses per-flow counter (instead of single counter), then ids off by 2 indicate the middle response was lost on the return path
- can evoke consecutive IP-IDs at least 80% of time from over 90% of routers
- some routers have weird IP-ID implementations
- 3 packet technique useful for differentiating between data losses and rate-limiting
},
	Author = {Ratul Mahajan and Neil Spring and David Wetherall and Thomas Anderson},
	Booktitle = {SOSP},
	Date-Added = {2008-06-16 16:53:21 -0700},
	Date-Modified = {2010-03-07 10:56:31 -0800},
	Keywords = {monitoring,active,rootcause, measurement tools, timestamp, asymmetry},
	Title = {User-level {I}nternet Path Diagnosis},
	Year = {2003}}

@inproceedings{passive-topology,
	Annote = {-methodology to infer network structure from passive measurements of IP traffic
1) cluster traffic sources that share paths w/o ip or AS info
2) infer topology from small number of active measurements
3) recover missing info
-tradeoffs between active probes and accuracy
-problems w active:
1) must esablish a set of sources and targets
2) significant traffic and complex management
3) ICMP filtering etc
- passive can be widely collected w/o significant management overhead and offer an opportunity to greatly expand perspective of Internet structure
- treat source IPs as anonymous identifiers (so can't see IP, but can group by it)
- cluster sources by TTL-vectors to monitor points
- make O(1) traceroutes from each cluster to each passive monitor site (actually, sounds like they measure from monitor sties to clusters)

datasets:
1) topologies generated by Orbit
2) Skitter (24 monitors to 1M target hosts) april 21-may 8, 2003? 192K routers, 609K links
3) 24 hrs of 15 honeypots (Dec 22 2006), managed by 10 organizations. 22K IPs
- 93.5% of IPs were seen at only one honeypot, 22K seen at at least 2

- use source IP as identifier (and TR target) and TTL from packet 
-- TTLs inferred for Skitter and Orbit data
- monitors at edge
- use "unique hop count contrast vectors" (subtract mean of vector from all values) to account for offset to border router)
- use gaussian mixture models to account for a cluster having multiple egress points and/or varying paths to those egress points 
- their random toplogy has 1000 nodes, of which they select 800 leaves.  NOT MUCH STRUCTURE
-- in fact, just doing random clusters, the estimated # of shared hops in the paths from 2 nodes to a measurement node is off by an ave of 2.25, vs 1.25 in their technique.  does not seem like much of a gain
-- on more realistic topology (skitter), using more clusters does not lead to much better estimates of shared path length
LOGIC of SHARED HOPS
- for 2 sources and their paths to a measurement node, they can share all, none, or some of path
- if we know # of shared hops for all such triples, then we can form logical topology (bc of dst routing)
- so focus on esatimating P(i,j,k) the length of shared paths
- this is only STRICTLY TRUE for paths FROM the sources to passive measurement nodes, not necessarily for measurements from M to Si and Sj, which are what we'd generally actually have

Q:
- how many clusters do they expect/have?  how many TRs does this lead to?
- aren't they seeing partial TTLs to destinations (ie, they are sampling at the middle), so they might hit that point on the way to different destinations and have taken different paths?  no, bc honeypots are destinations.  however, other monitors this might be a problem.
- does the traffic to honeypots distort things?
- they claim that their IMC paper [8] shows that TTL vectors close in Euclidean sense may not be close in network topology.  what does this imply for iplane?  but maybe they mainly mean things like offsets to border router (takes me 2 hops to get to same border it takes you 3 hops)
- how does the a) "weight" and b) info provided by this compare to everyone using iplane?
- how much do the clusterings change over time?  how often do you have to recluster?  how often do you have to probe each cluster?
- how do the clusters compare to prefixes?  why is this more useful than probing every prefix?  or why is this clustering better than using BGP data to cluster per atom?
- they don't model internet routing in their simulation (just shortest path).  how does this affect things?
- they arbitrarely switch from assuming measurements from sources (5.2.2) to paths to clusters (first para of 5).  and they don't deal with assymmetric paths.  how does this affect things?  you only have paths to the srcs, but without issuing probes to everywhere you only have hop counts from the srcs.

notation:
h_{i,k} hop count from source i to measurement node k
U_{i,j,k}=| T_{i,j,k} | (1)
- T_{i,j,k}={k':| |h_{i,k'}-h_{j,k'}| - |h_{i,k}-h{j,k}| < \epsilon}
- set of measurement nodes for which i and j have more similar hop counts than they do for k
- as this approaches |{k}|, the 2 sources are more likely in the same cluster, so more potential overlap of paths
I^c_k= {[x,y]:x, y \in I_k (we have active measurements to k) and U_{x,y,k}=c}  
RMSE(h^hat)=ave over all i,j of squared diff between estimate and actual number of shared hops (and over all measurement nodes?)},
	Author = {Brian Eriksson and Paul Barford and Robert Nowak},
	Booktitle = {SIGCOMM},
	Date-Added = {2008-06-15 10:50:41 -0700},
	Date-Modified = {2009-04-03 02:26:29 -0700},
	Keywords = {topology,passive,SIGCOMM 2008,tr-paths},
	Title = {Network Discovery from Passive Measurements},
	Year = {2008}}

@inproceedings{spam-botnets,
	Annote = {- developed spam signature generation framework
- use Hotmail data
- focused on URLs in emails
- 74% contain at least one URL, most of rest are penny stock
- does not require labeled data or whitelists
- detecting botnets individually based on the content of their emails is hard, easier in aggregate
- operates by attempting to find traffic patterns that are bursty and distributed
- signatures detect between16%to18%of spam per month
can this actually run in real time?
how does it avoid marking things like JetBlue promotions?  i guess because they look for diverse senders
they discard all forwarded mail... seems easy to spoof that
they require 20 source ASes-- how hard would it be for a botnet to only use a few big ASes?  esp bc the botnets they identify use only 10s to hundreds of source IPs (though they are only using sampled IPs)
so many magic constants-- require URL to be active < 5 days},
	Author = {Yinglian Xie and Fang Yu and Kannan Achan and Rina Panigrahy and Geoff Hulten and Ivan Osipkov},
	Booktitle = {SIGCOMM},
	Date-Added = {2008-06-11 11:50:54 -0700},
	Date-Modified = {2008-06-11 11:52:42 -0700},
	Keywords = {botnets,590L, 590L summer 2008},
	Title = {Spamming Botnets: Signatures and Characteristics},
	Year = {2008}}

@inproceedings{ono,
	Annote = {- piatek presented
- system called Ono
- design, deployment, and evaluation of an approach to reducing costly cross-ISP p2p traffic w/o sacrificing performance
- recycles network views from CDNs to drive biased neighbor selection w/o probes
- they have 120,000 BitTorrent users in 3000 networks
- 33% of time able to select peers within single AS
- median # of AS hops to all recommended peers is 1
- higher quality paths too-- two orders lower latency, 30% lower loss vs random
- by recycling CDN views (through looking for peers with similar redirection ratios), does not need new infrastructure, measurements, or cooperation between ISPs and P2P
- ratios exchanged directly or through distributed storage (not through tracker)
- requires your peers to be running the plugin too
- attempts to perform recursive DNS lookups to determine the ratio maps for peers not running the plugin
- to maintain robustness, only biases a fraction of traffic for each torrent
- CDN server equivalence by /24
- additive increase, multiplicitive decrease for DNS lookups based on whether value returned stays same or changes
- pings the servers to see if they are close

- paper doesnt show how many peers are Ono recommended, but reverse-engineer it to seem like they are only getting 5000 Ono peers for 100K people running Ono with direct exchange, and only 180K Ono-peers using even recursive lookups
- need someone (like a tracker) with more global view to actually exploit the locality in the system

GOAL IS NO PATH MONITORING/PROBING

from April 2007-Jan 2008
- 300K IPs, 108 countries, 15K prefixes, 2800 ASes

Q:
- how much do you get by doing a reverse DNS lookup on the client IPs and doing undns?  
- how many DNS lookups (esp recursive ones) is it performing?  why don't these count as measurements?
- why cosine similarity for distance, vs euclidean distance, say?
- they use 0.15 as their similarity threshold-- why is this the right value?
- does the /24 CDN server equivalence work?
- 1ms RTT?},
	Author = {David Choffnes and Fabian E. Bustamante},
	Booktitle = {SIGCOMM},
	Date-Added = {2008-05-19 12:19:36 -0700},
	Date-Modified = {2009-03-20 21:36:24 -0700},
	Keywords = {p2p, 590L, 590L spring 2008,active,SIGCOMM 2008},
	Title = {Taming the Torrent: A practical approach to reducing cross-{ISP} traffic in peer-to-peer systems},
	Year = {2008}}

@article{zhang00stationarity,
	Annote = {- look at the question of stationarity "to what extent are past measurements a good predictor of the future?"
- mathimatically stationary: can be described with a single time invariant mathematical model
- 31 NIMI hosts, 25 in US, 1/2 edu, most of rest are research
- 189 traceroute servers
- dec 99-jan 00
- pairwise, poisson w mean interval 10min
- remove pathologies
- remove bad sites?
- >=50 traceroutes for 450 src,dst pairs, exclude others
Paths heavily dominated by single prevalent route
85% of routes had same router-level path >90% of time

Q:
we are going to have an issue w old DNS names.  does harsha have them or old clusters at least?},
	Author = {Y. Zhang and V. Paxson and S. Shenker},
	Date-Modified = {2011-07-06 21:02:11 -0700},
	Journal = {ACIRI Technical Report},
	Keywords = {stability,tr-paths},
	Title = {The Stationarity of {I}nternet Path Properties: Routing, Loss, and Throughput},
	Year = {2000},
	Bdsk-Url-1 = {citeseer.ist.psu.edu/zhang00stationarity.html}}

@article{paxson-e2e,
	Abstract = {The large-scale behavior of routing in the Internet has gone virtually without any formal study, the exception being Chinoy's analysis of the dynamics of Internet routing information [Ch93]. We report on an analysis of 40,000 end-to-end route measurements conducted using repeated "traceroutes" between 37 Internet sites. We analyze the routing behavior for pathological conditions, routing stability, and routing symmetry. For pathologies, we characterize the prevalence of routing loops, erroneous routing, infrastructure failures, and temporary outages. We find that the likelihood of encountering a major routing pathology more than doubled between the end of 1994 and the end of 1995, rising from 1.5% to 3.4%. For routing stability, we define two separate types of stability, "prevalence" meaning the overall likelihood that a particular route is encountered, and "persistence," the likelihood that a route remains unchanged over a long period of time. We find that Internet paths are heavily dominated by a single prevalent route, but that the time periods over which routes persist show wide variation, ranging from seconds up to days. About 2/3's of the Internet paths had routes persisting for either days or weeks. For routing symmetry, we look at the likelihood that a path through the Internet visits at least one different city in the two directions. At the end of 1995, this was the case half the time, and at least one different autonomous system was visited 30% of the time.},
	Annote = {ON REPRESENTATIVENESS: weight each AS by its likelihood of occuring in an AS path

- 37 sites, mostly academic
- D_1 mean interval of 1-2 days between measuring a path
- D_2 60% mean inter-measurement of 2 hrs, 40% 2.75 days
looks at:
- unreachable due to "host unreachable," TTL exceded
- persistent loops that dont resolve by end of traceroute
- temporary loops that resolve by end of tracroute
- two separate types of stability: 
-- "prevalence" meaning the overall likelihood that a particular route is encountered; "given that i observed route r at the present, how likely am i to observe r again in the future?"
-- "persistence," the likelihood that a route remains unchanged over a long period of time; "given that i observed route r at time t, how long before that route is likely to have changed?"
- Internet paths are heavily dominated by a single prevalent route
- but that the time periods over which routes persist show wide variation, ranging from seconds up to days.
METHODOLOGY
- remove measurements w pathologies
-- require same set of routers 3 times to be a forwarding loop
- remove measurements missing hops
- merge equivalent routers
- considered 3 granularities: hostnames, cities, ASes
- 57% of host changes were also city, 36% were also AS
- prevalence parameter gives steady-state probability that a path at an arbitrary point in time uses route r
- look at dominant route
- look at aggregate variations by source and by destination

Q:
- look at variations by destio
},
	Author = {Vern Paxson},
	Date-Modified = {2011-10-28 22:00:02 -0700},
	Journal = {IEEE/ACM TON},
	Keywords = {stability,representativeness,asymmetry,tr-geo,tr-paths,tr-reach},
	Title = {End-to-end routing behavior in the {I}nternet},
	Year = {1997},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/90.649563}}

@inproceedings{hubble,
	Annote = {-  collected a sample of BitTorrent users by crawling 18,370 target swarms. 
- for a month starting December 20, 2007, repeatedly requested membership information from the swarms
- observed 14,380,622 distinct IPs, representing more than 200 of the nearly 250 DNS country codes
- 99% of them belong to ASes containing prefixes monitored by Hubble.

 - evaluate diversity of paths seen from PL compared to BGP paths from RIPE (447 peers)
- consider the downhill portion of BGP paths
- more than 90% of failed traceroutes terminate within two AS hops of the destination
- for 90% of prefixes, the probes include at least half of the ASes seen in BGP paths
- for 70% of prefixes, the traceroutes include at least 70% of ASes
- they include all ASes for more than 60% of prefixes
},
	Author = {Ethan Katz-Bassett and Harsha V. Madhyastha and John P. John and Arvind Krishnamurthy and David Wetherall and Thomas Anderson},
	Booktitle = {NSDI},
	Date-Added = {2008-03-17 23:29:24 -0600},
	Date-Modified = {2009-04-03 22:46:15 -0700},
	Keywords = {planetlab, representativeness,nsdi 2008,tr-paths,tr-reach},
	Title = {Studying Black Holes in the {I}nternet with {H}ubble},
	Year = {2008}}

@unpublished{imap,
	Abstract = {Many distributed applications can benefit from accurate 
predictions of Internet performance between arbitrary endpoints. Existing approaches
either 1) achieve high accuracy for sophisticated path properties, but adopt
an unscalable centralized approach, or 2) are lightweight and decentralized,
but work primarily for latency prediction.

In this paper, we present \iMap, a system designed to achieve the best
of both worlds. The key idea is to develop a compact but accurate
representation of a snapshot of Internet routing that can be
downloaded to endhosts.  In just 10MB, \iMap\ captures the Internet's
structure and routing policies and uses them to predict AS-level paths
with 70\% accuracy. Furthermore, we develop new techniques for 
measuring
one-way path latencies and use them to annotate \iMap\ with link
latencies. Our experiments using a separate validation set suggest
that \iMap\ can predict Internet routes, latencies, and loss rates with
accuracy comparable to existing approaches, in much less space.},
	Annote = {- 845 DIMES agents to 100 randomly chosen destinations each over a week
- PL finds 900K IP-level links
- DIMES adds 30K links
- extrapolating, including traceroutes from all 100K prefixes at edge would increase the number of links to 4M, a four-fold increase

Q:
- how many new router level (after alias)?  cluster level?  AS level?},
	Author = {Harsha V. Madhyastha and Ethan Katz-Bassett and Thomas Anderson and Arvind Krishnamurthy and Arun Venkataramani},
	Date-Added = {2008-03-17 16:30:16 -0600},
	Date-Modified = {2008-03-18 00:18:05 -0600},
	Keywords = {representativeness,planetlab},
	Note = {in submission},
	Title = {iMap: Compact Internet Maps for Accurate Performance Prediction}}

@inproceedings{lordofthelinks,
	Annote = {- find 40% more AS links, using 33 more BGP dumps (vs routeviews), IRR, IXPs, then validate w traceroutes
- 300% more p2p
- all new links found in either BGP RIB snapshots or verified by their RETRO traceroute tool
- 83% of new edges are in IRR.  IRR has 50K+ more extra edges
- most missing links are p2p
- most are at IXPs
- many are in IRR
- identify IXP participants
-- infer IXP participants by IXP IP addresses and "web-achieves"
-- heuristics to guess from sources such as traceroutes and whois/dns
-- 80-90% accuracy, <15% false positive
-- identify a superset of possible IXP edges
- RETRO (REverse Trace Route)
-- from 1200+ public traceroute servers, 350 ASes
-- verify if suspected link exists
-- to verify AB, try to traceroute from A to B
-- count it if they see IP_a-IP_b or IP_a-IP_ixp-IP_b
},
	Author = {Yihua He and Georgos Siganos and Michalis Faloutsos and Srikanth Krishnamurthy},
	Booktitle = {NSDI},
	Date-Added = {2008-03-17 12:46:58 -0600},
	Date-Modified = {2009-04-10 14:27:19 -0700},
	Keywords = {representativeness,topology,tr-topo},
	Title = {A Systematic Framework for Unearthing the Missing Links},
	Year = {2007}}

@inproceedings{as-taxonomy,
	Abstract = {Although the Internet AS-level topology has been extensively studied over the past few years, little is known about the details of the AS taxonomy. An AS "node" can represent a wide variety of organizations, e.g., large ISP, or small private business, university, with vastly different network characteristics, external connectivity patterns, network growth tendencies, and other properties that we can hardly neglect while working on veracious Internet representations in simulation environments. In this paper, we introduce a radically new approach based on machine learning techniques to map all the ASes in the Internet into a natural AS taxonomy. We successfully classify 95.3% of ASes with expected accuracy of 78.1%. We release to the community the AS-level topology dataset augmented with: 1) the AS taxonomy information and 2) the set of AS attributes we used to classify ASes. We believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the Internet.},
	Annote = {- large ISPs (intercontinental tier-1s), small ISPs (regional/access providers), customer ASes, universities (typically larger networks than customer AS), Internet exchange points (IXPs), network information centers (NICs) such as root or TLD servers 
-  successfully classify 95.3% of ASes with expected accuracy of 78.1%
- machine learning instead of heuristics and ad-hoc thresholds to distinguish types
- AS graphs, IRR records, inferred relationships, IP prefixes
- specify representative set of AS classes by unique signatures of network properties
- dataset released at http://www.ece.gatech.edu/research/labs/MANIACS/as_taxonomy/
RELATED WORK:
- Z. Ge, D. Figueiredo, S. Jaiwal, , andL. Gao. On the hierarchical structure of the logical Internet graph. In SPIE ITCOM, 2001. 
-- 7 tiers based on inferred c2p relationships
-  L. Subramanian, S. Agarwal, J. Rexford, and R. H. Katz. Characterizing the Internet hierarchy from multiple vantage points. In IEEE INFOCOM, 2002.
-- 5 tiers based on c2p and p2p},
	Author = {Xenofontas Dimitropoulos and Dmitri Krioukov and George Riley and kc claffy},
	Booktitle = {Passive and Active Measurement (PAM) Workshop},
	Date-Added = {2008-03-17 11:47:42 -0600},
	Date-Modified = {2008-03-17 12:07:35 -0600},
	Keywords = {representativeness},
	Title = {Revealing the Autonomous System Taxonomy: The Machine Learning Approach},
	Year = {2006}}

@article{as-relationships,
	Abstract = {Research on performance, robustness, and evolution of the global Internet is fundamentally handicapped without accurate and complete knowledge of the nature and structure of the contractual relationships between Autonomous Systems (ASs). In this work, we first examine the state-of-the-art in inferring AS relationships. We carefully analyze existing techniques and pinpoint limitations and inadequacies associated with them. We then introduce new, improved heuristics addressing the problems we have identified. Seeking to increase the value and reliability of our inference results, we then proceed to direct validation. We perform a survey with ASs' network administrators to collect information on the actual connectivity and policies of the surveyed ASs. Based on the survey results, we find that our new AS relationship inference techniques achieve high levels of accuracy: we correctly infer 96.5% customer to provider (c2p), 82.8% peer to peer (p2p), and 90.3% sibling to sibling (s2s) relationships. We then cross-compare the reported AS connectivity with the AS connectivity data contained in BGP tables. We regret to report that BGP tables miss up to 86.2% of the true adjacencies of the surveyed ASs. The majority of the missing links are of the p2p type, meaning that, in reality, peering links are likely to be more dominant than have been previously reported or conjectured. Finally, to make our results easily accessible and practically useful for the community, we open an AS relationship repository where we archive, on a weekly basis, and make publicly available the complete Internet AS-level topologies enriched with AS relationship information for every pair of AS neighbors.},
	Address = {New York, NY, USA},
	Annote = {DID NOT READ ENTIRE, JUST AS SURVEY AND VALIDATION SECTION 
-  BGP tables miss up to 86.2% of the true adjacencies of the surveyed ASs (86% of one AS's links)
-  majority of the missing links are p2p, meaning that peering links are likely more dominant than previously reported or conjectured
- feedback from 38 ASes
-- 5 tier 1, 13 smaller ISPs, 19 universities, 1 content provider
- bgp tables included only about 1/2 the actual links
- most of the missing ones are peers-- observe only 39%, vs 87% for c2p and 93% for s2s
- would need BGP tables from small edge ASes to see their peer links
- tier 1s have many p2p links, even with much smaller ASes
- p2p and c2p captures most real links, but some are more specialized or hybrids
-- backup is more specialized c2p 
-- p2p at some connection point, c2p at another
-- or for different prefixes
-- in other words, vary across time, space, prefix
-- most complex relationships are between large ASes, and most links connect at least one small AS
Q
- how many of the missing links are backups or otherwise limited?},
	Author = {Xenofontas Dimitropoulos and Dmitri Krioukov and Marina Fomenkov and Bradley Huffaker and Young Hyun and kc claffy and George Riley},
	Date-Modified = {2011-07-06 21:02:11 -0700},
	Issn = {0146-4833},
	Journal = {SIGCOMM Comput. Commun. Rev.},
	Keywords = {representativeness},
	Number = {1},
	Pages = {29--40},
	Publisher = {ACM},
	Title = {AS relationships: inference and validation},
	Volume = {37},
	Year = {2007},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1198255.1198259}}

@inproceedings{ron2,
	Annote = {- failure: 3 consecutive lost probes, > 2 min
- if lost, traceroute
- does source see BGP message for dest?
- some links experience many failures, many experience some
- 30% longer than 5 min
- 31 nodes, probe each path every 45 sec, logging to detect 1-way failures
- bgp feeds at 8
- determine location, duration, whether multihomed
- failures near endhosts are less likely to correlate with BGP updates
- 25 paths for which RON masked all failures-- all multihomed at at least one end, 18 at both
- 136 path for which RON masked no failures-- 106 multihomed at at least one end, 35 at both
},
	Author = {Nick Feamster and David G. Andersen and Hari Balakrishnan and M. Frans Kaashoek},
	Booktitle = {SIGMETRICS},
	Date-Modified = {2011-10-28 21:59:24 -0700},
	Keywords = {failures,tr-reach},
	Title = {Measuring the effects of internet path faults on reactive routing},
	Year = {2003},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/781027.781043}}

@inproceedings{ron,
	Abstract = {A Resilient Overlay Network (RON) is an architecture that allows distributed Internet applications to detect and recover from path outages and periods of degraded performance within several seconds, improving over today's wide-area routing protocols that take at least several minutes to recover. A RON is an application-layer overlay on top of the existing Internet routing substrate. The RON nodes monitor the functioning and quality of the Internet paths among themselves, and use this information to decide whether to route packets directly over the Internet or by way of other RON nodes, optimizing application-specific routing metrics.Results from two sets of measurements of a working RON deployed at sites scattered across the Internet demonstrate the benefits of our architecture. For instance, over a 64-hour sampling period in March 2001 across a twelve-node RON, there were 32 significant outages, each lasting over thirty minutes, over the 132 measured paths. RON's routing mechanism was able to detect, recover, and route around all of them, in less than twenty seconds on average, showing that its methods for fault detection and recovery work well at discovering alternate paths in the Internet. Furthermore, RON was able to improve the loss rate, latency, or throughput perceived by data transfers; for example, about 5% of the transfers doubled their TCP throughput and 5% of our transfers saw their loss probability reduced by 0.05. We found that forwarding packets via at most one intermediate RON node is sufficient to overcome faults and improve performance in most cases. These improvements, particularly in the area of fault detection and recovery, demonstrate the benefits of moving some of the control over routing into the hands of end-systems.},
	Annote = {- notes from SOSP slides
- there is also a SIGOPS Operating Systems Review version: http://portal.acm.org/citation.cfm?doid=502059.502048 with the same abstract
- paxson 95-97 3.3% of routes had "serious problems"
- labovitzt 97,00 10% routes available < 95% of time; 65% routes < 99.9% of time; 3-min minimum detect+recover time, often 15min; 40% of outages took 30+min to repair
- chandra 01 5% of faults > 2.75 hrs
- goal: improve communication availability for small (3-50 node) communities
1) frequently measure all inter-node paths
2) exchange routing info
3) route along app-specific best path
- probe every random(14) seconds, 3 packets.  timeout based on RTT + variance
- if N lost probes, notify outage
- store probes in performance database
- link-state between nodes
2 datasets:
- ron_1: 12 nodes, 64 hrs, mar 2001
- ron_2: 16 nodes, 85 hrs, may 2001
- RON takes ~10sec to route around failues
- many outages avoidable
- comparison on RON vs Internet 30 min loss rate },
	Author = {David Andersen and Hari Balakrishnan and Frans Kaashoek and Robert Morris},
	Booktitle = {SOSP},
	Date-Modified = {2009-04-10 06:56:16 -0700},
	Keywords = {failures},
	Title = {Resilient overlay networks},
	Year = {2001},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/502034.502048}}

@inproceedings{sosr,
	Abstract = {Recent work has focused on increasing availability in the face of Internet path failures. To date, proposed solutions have relied on complex routing and path-monitoring schemes, trading scalability for availability among a relatively small set of hosts.

This paper proposes a simple, scalable approach to recover from Internet path failures. Our contributions are threefold. First, we conduct a broad measurement study of Internet path failures on a collection of 3,153 Internet destinations consisting of popular Web servers, broad-band hosts, and randomly selected nodes. We monitored these destinations from 67 PlanetLab vantage points over a period of seven days, and found availabilities ranging from 99.6% for servers to 94.4% for broadband hosts. When failures do occur, many appear too close to the destination (e.g., last-hop and end-host failures) to be mitigated through alternative routing techniques of any kind. Second, we show that for the failures that can be addressed through routing, a simple, scalable technique, called one-hop source routing, can achieve close to the maximum benefit available with very low overhead. When a path failure occurs, our scheme attempts to recover from it by routing indirectly through a small set of randomly chosen intermediaries.

Third, we implemented and deployed a prototype one-hop source routing infrastructure on PlanetLab. Over a three day period, we repeatedly fetched documents from 982 popular Internet Web servers and used one-hop source routing to attempt to route around the failures we observed. Our results show that our prototype successfully recovered from 56% of network failures. However, we also found a large number of server failures that cannot be addressed through alternative routing.

Our research demonstrates that one-hop source routing is easy to implement, adds negligible overhead, and achieves close to the maximum benefit available to indirect routing schemes, without the need for path monitoring, history, or a-priori knowledge of any kind.},
	Annote = {Dataset:
- aug 20-27, 2004
- if received response within X, declared path to be normal
- if a loss, probe path more frequently to distinguish between failure and short-lived congestion, and to measure the failure duration
- traceroutes to determine where failure occured
- sent one-hop detours
- TCP ACK "pings," and response it TCP RST
- validated that destinations would respond to a burst of 10 ACKs, to make sure it wouldn't rate-limit
- TCP ACK-based traceroute, probing multiple hops in parallel, to find locations of even short failures
- 67 PL nodes that were down for at most 24 hrs during study, 39 as detours
- destinations were:
* 378 "popular web servers" from the 2000 most popular Web sites on www.rankings.com (represents contacting well-provisioned server)
* 1139 broadband hosts from a 2002 Gnutella crawl, only including major broadband providers (represenents P2P or VoiP)
* 1636 random IPs
- each destination probed BY ONLY ONE VANTAGE POINT
- probe each path every 15 seconds, declare loss if no response after 3 seconds
- loss period ends after 10 consecutive responses
- during loss, probe every 5 seconds both directly and (for first 10 probe intervals) through intermediaries
- declare a failure for 3 consecutive probe losses AND initial traceroute fails
- their "random IP" dataset sees a greater rate of destination-side failures (on downward path, excluding lasthop) than both servers and broadband hosts
- ave server failure was 11 min, ave broadband faiure 84 min, and lasthop failures an order of magnitude longer for both (reducing efficacy of SOSR, bc hard to route around randomly)
- 66% of server failures had at least one intermediate node able to reach, 39% of broadband
- if a node heard back from a detour before directly, consider successful
- they saw more failures in 7 days than RON saw in 9 months
- RON monitoring is not scalable
- random-4
- history-k (k-1 random, plus last that worked) and BGP-k (k-most disjoint) don't improve much over random at "high" k
- final proposal is to begin recovery after a single packet loss, 4 rounds of detours to same 4 random nodes 
- "client experience" study used 3 UW machines to repeatedly fetch Web pages from the servers, w the same 39 detours
- one fetch per second, 279 per server
- reduced number of network failures, but application-leval failures increased
- "given the extremely low failure rate..., we do not believe that SOSR would lead to any noticeable improvement in a person's Web browsing experience," though other apps might

Q:
- their "paths to broadband hosts" study seems like BS.  you don't need a P2P/VoiP path to a host when it is off, which is what most of the failures probably are
- how many of the failures they routed around were simply transients that had already fixed? 
- why did we see different results?
* each destination probed by only one vantage point?  bc they don't see problems that don't affect that vantage point? "reachable from all" as goal, vs "reachable from particular"
* the makeup of the destination set?
* bc of the frequency of probing?
* they count "sputtering" paths as failed
* they only try to route around for 50 seconds
* a detour is considering successful if a ping fails, then it tries a detour and receives a response before re-pinging
* we exclude source-problems (though these are hard to route around by random detour)
- it is "more important" to route around long failures, so it seems ok to count each round vs each failure (like we did, unlike what they did)},
	Author = {Krishna P. Gummadi and Harsha V. Madhyastha and Steven D. Gribble and Henry M. Levy and David Wetherall},
	Booktitle = {OSDI},
	Optaddress = {Berkeley, CA, USA},
	Optdate-Modified = {2009-04-10 13:33:55 -0700},
	Optkeywords = {failures,tr-reach},
	Optlocation = {San Francisco, CA},
	Optpages = {13--13},
	Optpublisher = {USENIX Association},
	Title = {Improving the reliability of {Internet} paths with one-hop source routing},
	Year = {2004}}

@article{pl-best-practices,
	Address = {New York, NY, USA},
	Annote = {Perception: PL is not representative of the Internet
Verdict: Reality; but what is representative of the Internet?
- "exactly what it means to be representative of the Internet is an open and interesting research question"
- "a good definition could help drive node placement in the future and help drive node placement... and help researchers select... existing nodes"
- all results need to be interpreted according to the service/experiment's sensitivity to various network properties
- the key question is "how PL's network connectivity affects research"
- observing the rest of the Internet is not particularly handicapped
* bc 60% are either in transit ASes or multi-homed ASes (w a commercial provider)
* sufficient vantage points from which the full Internet can be probed
* cites the number of ASes seen by PL at each tier

- DSL/cable hosts at research sites add commercial Internet},
	Author = {Neil Spring and Larry Peterson and Andy Bavier and Vivek Pai},
	Date-Modified = {2011-07-06 21:02:11 -0700},
	Issn = {0163-5980},
	Journal = {SIGOPS Oper. Syst. Rev.},
	Keywords = {planetlab, representativeness},
	Number = {1},
	Pages = {17--24},
	Publisher = {ACM},
	Title = {Using PlanetLab for network research: myths, realities, and best practices},
	Volume = {40},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1113361.1113368}}

@inproceedings{measurement-strategies,
	Annote = {- misconception-- equating what we are actually measuring with what we wish to measure-- can be a big problem
- "the general problem of vantage point: that the location of exactly where a measurement is performed can significantly skew the interpretation of the measurement, in quite non-apparent ways"
- not representative: properties vary across point in the internet and across time at the same point
* suggests if at all possble to gather more than one type of dataset (different location, different time), to help you realize that the phenomenon might be more diverse},
	Author = {Vern Paxson},
	Booktitle = {IMC},
	Date-Modified = {2009-04-10 17:54:53 -0700},
	Keywords = {representativeness},
	Title = {Strategies for sound internet measurement},
	Year = {2004},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1028788.1028824}}

@inproceedings{pucha-testbeds,
	Abstract = {An important stage of wide-area systems and networking research is to prototype a system to understand its performance when deployed in the real Internet. A key requirement of prototyping is that results obtained from the prototype experiments be representative of the behavior if the system were deployed over nodes connected to commercial ISPs. Recently, distributed testbeds such as PlanetLab and RON have become increasingly popular for performing wide-area experimentation. However, such testbeds typically consist of a significant fraction of nodes with connectivity to research and education networks which potentially hinder their usability in prototyping systems.In this paper, we investigate the impact of testbeds with connectivity to research and education networks on the applications and network services so that such testbeds can be leveraged for evaluation and prototyping. Specifically, we investigate when the representativeness of wide-area experiments deployed on such testbeds is affected by studying the routing paths that applications use over such testbeds. We then investigate how the representativeness of wide-area experiments is affected by studying the performance properties of such paths. We further measure the impact of using such testbeds on application performance via application case studies. Finally, we propose a technique that uses the currently available testbeds but reduces their bias by exposing applications evaluated to network conditions more reflective of the conditions in the commercial Internet.},
	Address = {New York, NY, USA},
	Annote = {- says PL is 85% and RON 50% GREN
- additional contribution: "a methodology to compare and calibrate various network performance metrics compared with commercial testbeds"
- paths from GREN to nodes with commercial connectivity traverse a large fraction "in" commercial networks and experience representative conditions
- overlay routing can expose traffic to representative conditions
- paper does not explore diversity within commercial networks, just GREN vs commercial  
- when and how the representativeness of wide-area experiments (applications and services) is affected, by studying the routing paths and performance properties of non-representative paths
- if both end point within GREN, path is almost always exclusively within GREN
- for GREN source, non-GREN dest: 
* almost all the RTT is incurred outside GREN, even though the hops are more evenly
split. (hot potato routing)
* of those w <10% of RTT in GREN, 2/3 exit origin AS directly into commercial network and 30% traverse only 2 GREN ASes
* most have < 10ms within GREN
- non-GREN src, GREN dst is similar, little RTT in GREN
* they claim this is late-exit (which they say is common for customer networks), but really they only look at GREN/non-GREN, not how early it exits each individual AS
* sometimes forward path is GREN, reverse is commercial.  they claim this is curious, but really it just seems like fancy hot potato.
- commercial to commercial does not traverse GREN, except for that berkeley intel node
- measure 6 path performance properties-- TCP RTT, loss, TCP throughput, available bandwidth, bottleneck capacity, bottleneck location
- use 22 PL nodes, 11 in GREN, 11 not, geographically paired.  Cambridge, Warsaw, Amsterdam only non-US nodes (no Asia!)
- comparing only 110 paths each seems pretty limited
- min RTT distribution very similar, but average and variance higher for C2C
* they say due to path inflation, but min being same seems to contradict this.  queueing?
- much higher capacity and available bandwidth in GREN
- most chokepoints are in interior of network (rather than access links)
- paths G2C and C2G are closer to C2C in most properties (except RTT, which is equal) than they are to G2G, so are fairly representative
- verify that G2G differs from C2C and that G2C and C2G are close to C2C on multicast, network-coordinate latency prediction
- advocates not using G2G routes in testbeds.  either discard them, or detour them through a C node (like in SOSR)
- all pairs traceroutes between 155 G nodes traversed only 182 unique ASes (out of 1322 total G ASes), with 901 G-G AS level links

QUESTIONS:
- since they don't look at diversity within commercial, what parts of commercial does PL cover or not cover?
- they exclude failed traceroutes ("failure in receiving a reply from the intermediate routers").  this was 10% for N. American dataset and 20% for world, and these paths seem much more likely to go through commercial networks, which seem more likely to be configured to not respond.
- they claim that some GREN nodes "route to specific commercial nodes [such as planet3.berkeley.intel-research.net] through paths entirely in GREN."  doesn't this make the destination in GREN too?  yes, i think so, as they claim the reverse too, that it routes to them entirely within GREN.  seems that this means their classification of GREN ASes is off.
- how many GREN ASes are transit?
- route stability of G vs C? },
	Author = {Himabindu Pucha and Y. Charlie Hu and Z. Morley Mao},
	Booktitle = {IMC '06: Proceedings of the 6th ACM SIGCOMM conference on Internet measurement},
	Date-Modified = {2011-07-06 21:02:11 -0700},
	Isbn = {1-59593-561-4},
	Keywords = {planetlab, representativeness},
	Location = {Rio de Janeriro, Brazil},
	Pages = {133--146},
	Publisher = {ACM},
	Title = {On the impact of research network based testbeds on wide-area experiments},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1177080.1177097}}

@inproceedings{planetlab-connectivity,
	Abstract = {In this paper we investigate the interdomain connectivity of PlanetLab 
nodes. We note that about 85 percent of the hosts are located within what we call 
the Global Research and Educational Network (GREN) --- an interconnected 
network of high speed research networks such as Internet2 in the USA and Dante 
in Europe. Since traffic with source and destination on the GREN is very likely to 
be transited solely by the GREN, this means that over 70 percent of the end-to-end 
measurements between PlanetLab node pairs represent measurements of GREN 
characteristics. We suggest that it may be possible to systematically choose the 
placement of new nodes so that as the PlanetLab platform grows it becomes a 
closer and closer approximation to the Global Internet. },
	Address = {http://www.planet-lab.org/files/pdn/PDN-04-019/pdn-04-019.pdf},
	Annote = {- 85 percent of the hosts are located within what we call the Global Research and Educational Network (GREN), which includes I2 (runs Abilene) (US) and Dante (runs Geant) (Europe)
- 120 sites, 300 nodes
- providing an Internet measurement infrastructure has never been among the primary goals of the project. 
- ARENA project (http://arena.internet2.edu) provides a very useful online compendium of information about the networks making up the GREN. 
- an AS is research if it appears in paths announced by Abilene (after excluding the small number that are obviously commercial).  a site/host is research if it is originated by a research AS
class number percent 
MOAS 14 5.1 
Commercial 27 9.8 
Research 235 85.1 
Table 1. Breakdown of hosts. 
class number percent 
MOAS 7 5.7 
Commercial 12 9.8 
Research 104 84.5 
Table 2. Breakdown of sites. 

region number percent 
LA 1 0.8 
AP 6 4.9 
EMEA (europe/mideast/africa) 25 20.3 
NA 91 74.0 
Table 3. Breakdown by region. 

class region number percent 
Commercial EMEA 1 0.8 
Research LA 1 0.8 
Research AP 6 4.9 
Commercial NA 11 8.9 
Research EMEA 23 18.7 
Research NA 74 60.2 
Research NA or EMEA 97 78.9  (eg mostly abilene and geant)
Table 4. Combination of regions and types. 

- their case study is triangle inequality violations (of RTT between PL nodes)
- they find that commercial ones violate more and worse than GREN
- "How can we choose a set of nodes in the Internet so that internode experiments can reasonably be taken to represent behavior on the Internet as a whole?"
- "How can we systematically choose the placement of new nodes so that as the PlanetLab platform grows it becomes a closer and closer approximation to the Global Internet?"
- solution of increasing number of nodes on commercial network has shortcomings
- but could work some BGP magic, only announce PL prefixes to commercial provider
- they advocate instead trying to get PL to be GREN diverse-- such as adding non-CS departments, geographic diversity
},
	Author = {Suman Banerjee and Timothy G. Griffin and Marcelo Pias},
	Booktitle = {Proceedings of the Passive and Active Measurement Workshop (PAM2004)},
	Date-Added = {2008-02-29 18:24:28 -0700},
	Date-Modified = {2008-03-12 14:33:21 -0600},
	Keywords = {planetlab, representativeness},
	Title = {{The Interdomain Connectivity of PlanetLab Nodes}},
	Year = {2004}}

@misc{sobgp,
	Author = {R White},
	Howpublished = {draft-white-sobgp-bgp-deployment-01.txt},
	Title = {Deployment considerations for secure origin {BGP}},
	Year = {2003}}

@misc{sbgp,
	Author = {Charles Lynn and Joanne Mikkelson and Karen Seo},
	Date-Modified = {2011-10-03 16:25:30 -0700},
	Howpublished = {draft-clynn-s-bgp-protocol-01.txt},
	Title = {Secure {BGP} ({S-BGP})},
	Year = {2001}}

@inproceedings{goldberg:how-secure,
	Author = {Sharon Goldberg and Michael Schapira and Peter Hummon and Jennifer Rexford},
	Booktitle = {SIGCOMM},
	Title = {How secure are secure interdomain routing protocols},
	Year = {2010}}

@inproceedings{cunha:blackhole,
	Author = {\'{I}talo Cunha and Renata Teixeira and Nick Feamster and Christophe Diot},
	Booktitle = {IMC},
	Title = {Measurement methods for fast and accurate blackhole identification with binary tomography},
	Year = {2009}}

@inproceedings{iplane-nano,
	Author = {H. Madhyastha and E. Katz-Bassett and T. Anderson and A. Krishnamurthy and A. Venkataramani},
	Booktitle = {NSDI},
	Date-Modified = {2011-10-28 21:59:38 -0700},
	Title = {{iPlane Nano: Path Prediction for Peer-to-Peer Applications}},
	Year = 2009}

@inproceedings{choffnes:news,
	Author = {David Choffnes and Fabian Bustamante and Zihui Ge},
	Booktitle = {SIGCOMM},
	Optaddress = {New Dehli, India},
	Optmonth = {August},
	Title = {Using the Crowd to Monitor the Cloud: Network Event Detection from Edge Systems},
	Year = {2010}}

@inproceedings{virtual_synchrony,
	Author = {Kenneth P. Birman and Thomas A. Joseph},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {{Proc. of Symposium on Operating Systems Principles}},
	Title = {Exploiting Virtual Synchrony in Distributed Systems},
	Year = {1987}}

@inproceedings{valleyfree,
	Author = {Sophie Y. Qiu and Patrick D. McDaniel and Fabian Monrose},
	Booktitle = {IEEE ICC},
	Date-Added = {2007-10-09 11:49:00 -0700},
	Date-Modified = {2007-10-09 11:50:05 -0700},
	Title = {Toward Valley-free Inter-domain Routing},
	Year = {2007}}

@misc{fastreroute,
	Author = {Mike Shand and Stewart Bryant},
	Date-Added = {2007-10-09 11:05:53 -0700},
	Date-Modified = {2007-10-09 11:08:20 -0700},
	Howpublished = {IETF Draft, 2007},
	Title = {{IP Fast Reroute Framework}},
	Url = {draft-ietf-rtgwg-ipfrr-framework-07.txt},
	Bdsk-Url-1 = {draft-ietf-rtgwg-ipfrr-framework-07.txt}}

@techreport{consensus-tr,
	Author = {John P. John and Ethan Katz-Bassett and Arvind Krishnamurthy and Thomas Anderson and Arun Venkataramani},
	Date-Added = {2007-10-09 03:44:39 -0700},
	Date-Modified = {2007-10-09 16:51:16 -0700},
	Institution = {University of Washington},
	Number = {UW-CSE-08-02-01},
	Title = {{Consensus Routing}},
	Url = {ftp://ftp.cs.washington.edu/tr/2008/01/UW-CSE-08-02-01.pdf},
	Year = {2007},
	Bdsk-Url-1 = {ftp://ftp.cs.washington.edu/tr/2008/01/UW-CSE-08-02-01.pdf}}

@misc{aspi,
	Date-Added = {2007-10-08 18:47:37 -0700},
	Date-Modified = {2007-10-08 18:59:36 -0700},
	Key = {personal communication},
	Title = {{Personal communication with Aspi Siganporia of Google Inc.}}}

@article{paxos-simple,
	Author = {Leslie Lamport},
	Date-Added = {2007-10-08 18:43:52 -0700},
	Date-Modified = {2007-10-08 18:45:33 -0700},
	Journal = {ACM SIGACT News},
	Number = {4},
	Title = {Paxos made Simple},
	Volume = {32},
	Year = {2001}}

@article{griffin-wilfgong-sheperd,
	Author = {Timothy G. Griffin and Bruce F. Shepherd and Gordon Wilfong},
	Date-Added = {2007-10-08 18:41:23 -0700},
	Date-Modified = {2013-01-31 23:41:33 +0000},
	Journal = {IEEE/ACM ToN},
	Number = {2},
	Title = {The stable paths problem and interdomain routing},
	Volume = {10},
     issn = {1063-6692},
      pages = {232--243},
	Year = {2002}}

@inproceedings{Griffin,
	Author = {Timothy G. Griffin and Gordon Wilfong},
	Booktitle = {Proc. of ACM SIGCOMM},
	Date-Added = {2007-10-08 18:39:37 -0700},
	Date-Modified = {2007-10-08 18:40:49 -0700},
	Title = {On the correctness of {iBGP} configuration},
	Year = {2002}}

@inproceedings{PVloops,
	Author = {Dan Pei and Xiolian Zhao and Dan Massey and Lixia Zhang},
	Booktitle = {ICDCS},
	Date-Added = {2007-10-08 18:35:29 -0700},
	Date-Modified = {2007-10-08 18:36:38 -0700},
	Title = {A Study of {BGP} path vector route looping behavior},
	Year = {2004}}

@book{poiroot,
	Author = {Agatha Christie},
	Publisher = {The Bodley Head},
	Title = {{Murder on the Links}},
	Year = {1923}}


@book{BGP4,
	Author = {John W. Stewart},
	Date-Added = {2007-10-08 18:34:31 -0700},
	Date-Modified = {2007-10-08 18:53:35 -0700},
	Publisher = {Addison-Wesley},
	Title = {BGP4: Inter-Domain Routing in the Internet},
	Year = {1998}}

@article{greenberg05,
	Author = {Albert Greenberg and Gisli Hjalmtysson and David A. Maltz and Andy Myers and Jennifer Rexford and Geoffrey Xie and Hong Yan and Jibin Zhan and Hui Zhang},
	Date-Modified = {2007-10-08 23:12:27 -0700},
	Journal = {SIGCOMM CCR},
	Number = {5},
	Title = {A clean slate {4D} approach to network control and management},
	Volume = {35},
	Year = {2005}}

@conference{chang03,
	Author = {D. Chang and R. Govindan and J. Heidemann},
	Booktitle = {ICNP},
	Date-Modified = {2007-10-07 20:22:46 -0700},
	Title = {{The Temporal and Topological Characteristics of BGP Path Changes}},
	Year = {2003}}

@article{gao01,
	Address = {Piscataway, NJ, USA},
	Author = {Lixin Gao and Jennifer Rexford},
	Date-Modified = {2007-10-08 23:11:53 -0700},
	Doi = {http://dx.doi.org/10.1109/90.974523},
	Issn = {1063-6692},
	Journal = {IEEE/ACM Transactions on Networking},
	Number = {6},
	Pages = {681--692},
	Publisher = {IEEE Press},
	Title = {Stable {Internet} routing without global coordination},
	Volume = {9},
	Year = {2001},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/90.974523}}

@inproceedings{hengartner02,
	Author = {Urs Hengartner and Sue Moon and Richard Mortier and Christophe Diot},
	Booktitle = {Proc. of International Measurements Workshop},
	Date-Modified = {2007-10-07 20:25:38 -0700},
	Title = {Detection and analysis of routing loops in packet traces},
	Year = {2002}}

@inproceedings{sridharan03,
	Author = {Ashwin Sridharan and Sue B. Moon and Christophe Diot},
	Booktitle = {Proc. of International Measurements Conference},
	Date-Modified = {2007-10-07 21:44:07 -0700},
	Title = {On the correlation between route dynamics and routing loops},
	Year = {2003}}

@article{hearme,
	Author = {N. Kushman and S. Kandula and D. Katabi},
	Booktitle = {ACM Journal of Computer and Communication Review},
	Date-Modified = {2007-10-08 23:14:02 -0700},
	Journal = {CCR},
	Number = {2},
	Pages = {75-84},
	Title = {Can You Hear Me Now?! {It} Must Be {BGP}},
	Volume = {37},
	Year = {2007}}

@inproceedings{fcp,
	Author = {Karthik Kalambur Lakshminarayanan and Matthew Chapman Caesar and Murali Rangan and Thomas Anderson and Scott Shenker and Ion Stoica},
	Booktitle = {Proc. of ACM SIGCOMM},
	Date-Modified = {2007-10-07 21:38:23 -0700},
	Title = {Achieving Convergence-Free Routing using Failure-Carrying Packets},
	Year = {2007}}

@article{paxson,
	Address = {Piscataway, NJ, USA},
	Author = {Vern Paxson},
	Date-Modified = {2007-10-08 23:16:41 -0700},
	Doi = {http://dx.doi.org/10.1109/90.649563},
	Issn = {1063-6692},
	Journal = {IEEE/ACM Transactions on Networking},
	Number = {5},
	Pages = {601--615},
	Publisher = {IEEE Press},
	Title = {End-to-end routing behavior in the {Internet}},
	Volume = {5},
	Year = {1997},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/90.649563}}

@article{chandy-lamport,
	Author = {K. M. Chandy and L. Lamport},
	Journal = {ACM Transactions on Computer Systems},
	Month = {February},
	Number = {1},
	Pages = {63--75},
	Title = {Distributed snapshots: Determining global states of distributed systems.},
	Volume = {3},
	Year = {1985}}

@misc{xorp,
	Author = {http://www.xorp.org},
	Title = {{XORP}: Open Source {IP} router.},
	Url = {http://www.xorp.org},
	Bdsk-Url-1 = {http://www.xorp.org}}

@misc{caida,
	Author = {http://www.caida.org/data/active/as-relationships/},
	Title = {The {CAIDA} {AS} Relationships Dataset, {N}ovember 2006.},
	Url = {http://www.caida.org/data/active/as-relationships/},
	Bdsk-Url-1 = {http://www.caida.org/data/active/as-relationships/}}

@techreport{C-BGP,
	Author = {Nate Kushman and Dina Katabi and John Wroclawski},
	Date-Modified = {2007-10-08 23:14:52 -0700},
	Institution = {MIT},
	Number = {MIT-CSAIL-TR-2006-006},
	Title = {{A Consistency Management Layer for Inter-Domain Routing}},
	Year = 2006}

@article{BGP-RCN,
	Author = {Dan Pei and Matt Azuma and Dan Massey and Lixia Zhang},
	Date-Modified = {2013-01-31 23:43:55 +0000},
	Journal = {Computer Networks},
	Number = {2},
	Pages = {175--194},
	Title = {{BGP-RCN}: Improving {BGP} convergence through root cause notification},
	Volume = {48},
	Year = {2005}}

@conference{RCP,
	Author = {Matthew Caesar and Donald Caldwell and Nick Feamster and Jennifer Rexford and Aman Shaikh and Jacobus van der Merwe},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Date-Modified = {2007-10-07 20:21:46 -0700},
	Title = {{Design and Implementation of a Routing Control Platform}},
	Year = 2005}

@article{rocketfuel-ton,
	Author = {Neil Spring and Ratul Mahajan and David Wetherall and Tom Anderson},
	Date-Added = {2006-04-24 03:37:52 -0700},
	Date-Modified = {2006-04-24 19:05:52 -0700},
	Journal = {{IEEE/ACM} Transactions on Networking},
	Title = {Measuring {ISP} Topologies with {R}ocketfuel},
	Year = {2004}}

@inproceedings{reverse,
	Author = {Neil Spring and David Wetherall and Tom Anderson},
	Booktitle = {{Proc. of Workshop on Hot Topics in Networks}},
	Title = {Reverse-Engineering the {Internet}},
	Year = {2003}}

@conference{consensus-nsdi,
	Author = {J. John and E. Katz-Bassett and A. Krishnamurthy and T. Anderson and A. Venkataramani},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Title = {{Consensus routing: the Internet as a distributed system}},
	Year = 2008}

@inproceedings{francois,
	Author = {P. Francois and O. Bonaventure},
	Booktitle = {INFOCOM},
	Date-Modified = {2007-10-07 18:47:20 -0700},
	Title = {{Avoiding transient loops during IGP Convergence in IP Networks}},
	Year = {2005}}

@inproceedings{dual,
	Author = {J. J. Garcia-Luna-Aceves},
	Booktitle = {Proc. of ACM SIGCOMM},
	Date-Modified = {2007-10-07 20:24:11 -0700},
	Title = {A unified approach to loop-free routing using distance vectors or link states},
	Year = {1989}}

@inproceedings{p-bgp,
	Author = {Josh Karlin and Stephanie Forrest and Jennifer Rexford},
	Booktitle = {ICNP},
	Date-Modified = {2007-10-07 21:28:43 -0700},
	Title = {{Pretty Good BGP: Improving BGP by Cautiously Adopting Routes}},
	Year = 2006}

@techreport{mrai-timer,
	Author = {Y. Rekhter and T. Li},
	Days = 15,
	Institution = {Internet Engineering Task Force},
	Month = mar,
	Number = 1771,
	Pages = 57,
	Title = {A Border Gateway Protocol 4 {(BGP-4)}},
	Type = {RFC},
	Url = {http://www.rfc-editor.org/rfc/rfc1771.txt},
	Year = 1995,
	Bdsk-Url-1 = {http://www.rfc-editor.org/rfc/rfc1771.txt}}

@techreport{damping,
	Author = {C. Villamizar and R. Chandra and R. Govindan},
	Days = 15,
	Institution = {Internet Engineering Task Force},
	Month = nov,
	Number = 2439,
	Pages = 37,
	Title = {{BGP} Route Flap Damping},
	Type = {RFC},
	Url = {http://www.rfc-editor.org/rfc/rfc2439.txt},
	Year = 1998,
	Bdsk-Url-1 = {http://www.rfc-editor.org/rfc/rfc2439.txt}}

@misc{kushmantalk,
	Author = {Nate Kushman},
	Booktitle = {NANOG-36},
	Date-Modified = {2007-10-09 01:43:26 -0700},
	Month = feb,
	Number = 36,
	Title = {An Inter-domain Consistency Management Layer},
	Url = {http://www.nanog.org/mtg-0602/kushman.html},
	Year = 2006,
	Bdsk-Url-1 = {http://www.nanog.org/mtg-0602/kushman.html}}

@inproceedings{iannaccone,
	Author = {G. Iannaccone and C.-N. Chuah and R. Mortier and S. Bhattacharyya and C.Diot},
	Booktitle = {Proc. of International Measurements Workshop},
	Title = {{Analysis of link failures in an IP backbone}},
	Year = 2002}

@inproceedings{ratul-path-inflation,
	Author = {Neil Spring and Ratul Mahajan and Thomas Anderson},
	Booktitle = {Proc. of ACM SIGCOMM},
	Date-Modified = {2007-10-07 21:43:40 -0700},
	Title = {The causes of path inflation},
	Year = {2003}}

@article{soBGP,
	Author = {Russ White},
	Date-Modified = {2007-10-07 21:46:30 -0700},
	Journal = {{Internet Protocol Journal}},
	Number = 3,
	Title = {Securing {BGP} Through {Secure Origin BGP}},
	Volume = 6,
	Year = 2003}

@article{SPV,
	Author = {Yih-Chun Hu and Adrian Perrig and Marvin Sirbu},
	Date-Modified = {2007-10-08 23:13:09 -0700},
	Journal = {SIGCOMM CCR},
	Number = {4},
	Title = {{SPV}: Secure Path Vector routing for securing {BGP}},
	Volume = {34},
	Year = {2004}}

@inproceedings{listen,
	Author = {Lakshminarayanan Subramanian and Volker Roth and Ion Stoica and Scott Shenker and Randy Katz},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Date-Modified = {2007-10-08 19:32:29 -0700},
	Title = {{Listen and Whisper: Security Mechanisms for BGP}},
	Year = {2004}}

@article{beware,
	Author = {Ola Nordstrm and Constantinos Dovrolis},
	Date-Modified = {2007-10-08 23:16:21 -0700},
	Issn = {0146-4833},
	Journal = {SIGCOMM CCR},
	Number = {2},
	Publisher = {ACM Press},
	Title = {{Beware of BGP attacks}},
	Volume = {34},
	Year = {2004}}

@article{paxos,
	Address = {New York, NY, USA},
	Author = {Leslie Lamport},
	Date-Modified = {2007-10-08 23:15:17 -0700},
	Doi = {http://doi.acm.org/10.1145/279227.279229},
	Issn = {0734-2071},
	Journal = {ACM TOCS},
	Number = {2},
	Pages = {133--169},
	Publisher = {ACM Press},
	Title = {The part-time parliament},
	Volume = {16},
	Year = {1998},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/279227.279229}}

@inproceedings{offense,
	Author = {Michael Walfish and Mythili Vutukuru and Hari Balakrishnan and David Karger and Scott Shenker},
	Booktitle = {Proc. of ACM SIGCOMM},
	Title = {DDoS Defense by Offense},
	Year = {2006}}

@inproceedings{tva-hotnets,
	Author = {Tom Anderson and Timothy Roscoe and David Wetherall},
	Booktitle = {{Proc. of Workshop on Hot Topics in Networks}},
	Title = {Preventing Internet Denial-of-Service with Capabilities},
	Year = {2003}}

@techreport{i3-tr,
	Author = {Daniel Adkins and Karthik Lakshminarayanan and Adrian Perrig and Ion Stoica},
	Institution = {UC Berkeley},
	Title = {Towards a More Functional and Secure Network Infrastructure},
	Year = {2003}}

@inproceedings{i3-podc,
	Author = {Karthik Lakshminarayanan and Daniel Adkins and Adrian Perrig and Ion Stoica},
	Booktitle = {PODC},
	Title = {Towards a Secure Indirection Infrastructure (Brief Announcement)},
	Year = {2004}}

@inproceedings{aitf-hotnets,
	Author = {Katerina Argyraki and David Cheriton},
	Booktitle = {{Proc. of Workshop on Hot Topics in Networks}},
	Title = {Network Capabilities: The Good, the Bad and the Ugly},
	Year = {2005}}

@inproceedings{mayday,
	Author = {David G. Andersen},
	Booktitle = {USITS},
	Title = {Mayday: Distributed Filtering for Internet Services},
	Year = {2003}}

@inproceedings{SOS,
	Author = {Angelos D. Keromytis and Vishal Misra and Dan Rubenstein},
	Booktitle = {Proc. of ACM SIGCOMM},
	Title = {SOS: Secure Overlay Services},
	Year = {2002}}

@techreport{overdose,
	Author = {Elaine Shi and Ion Stoica and David Andersen and Adrian Perrig},
	Institution = {Carnegie Mellon University},
	Title = {OverDoSe: A Generic DDoS Protection Service Using an Overlay Network},
	Year = {2006}}

@techreport{fastpass,
	Author = {Dan Wendlant and David G. Andersen and Adrian Perrig},
	Institution = {Carnegie Mellon University},
	Title = {Bypassing Network Flooding Attacks using FastPass},
	Year = 2006}

@techreport{flow-cookies-tr,
	Author = {Martin Casado and Pei Cao and Aditya Akella and Neils Provos},
	Institution = {Stanford},
	Title = {Flow-Cookies: Using Bandwidth Amplification to Defend Against DDoS Flooding Attacks},
	Year = {2006}}

@inproceedings{flow-cookies,
	Author = {Martin Casado and Pei Cao and Aditya Akella and Neils Provos},
	Booktitle = {IWQoS},
	Title = {Flow-Cookies: Using Bandwidth Amplification to Defend Against DDoS Flooding Attacks},
	Year = {2006}}

@inproceedings{tva-sruti,
	Author = {Xin Liu and Xiaowei Yang and David Wetherall and Tom Anderson},
	Booktitle = {SRUTI},
	Title = {Efficient and Secure Source Authentication with Packet Passports},
	Year = {2006}}

@inproceedings{AITF,
	Author = {Katerina Argyraki and David R. Cheriton},
	Booktitle = {USENIX},
	Title = {Real-time Response to Denial-of-service Attacks},
	Year = {2005}}

@inproceedings{offbydefault,
	Author = {Hitesh Ballani and Yatin Chawathe and Sylvia Ratnasamy and Timothy Roscoe and Scott Shenker},
	Booktitle = {{Proc. of Workshop on Hot Topics in Networks}},
	Title = {Off by Default!},
	Year = {2005}}

@article{SBGP,
	Author = {Stephen Kent and Charles Lynn and Karen Seo},
	Date-Modified = {2007-10-08 23:13:42 -0700},
	Journal = {IEEE JSAC},
	Number = 4,
	Pages = {582--592},
	Title = {{Secure Border Gateway Protocol}},
	Volume = 18,
	Year = 2000}

@inproceedings{MRAI,
	Author = {S. Deshpande and B. Sikdar},
	Booktitle = {Global Telecommunications Conference, 2004. GLOBECOM '04},
	Title = {{On the impact of route processing and MRAI timers on BGP convergence times}},
	Year = 2004}

@article{labovitz01,
	Author = {Craig Labovitz and Abha Ahuja and Abhijit Bose and Franam Jahanian},
	Journal = {IEEE/ACM Transactions on Networking},
	Month = {June},
	Number = {3},
	Title = {{Delayed Internet Routing Convergence}},
	Volume = {9},
	Www_Important = {1},
	Www_Pdf_Url = {http://www.eecs.umich.edu/~farnam/pubs/2001-lab-ton.pdf},
	Www_Section = {routing},
	Year = {2001}}

@inproceedings{hengartner02detection,
	Author = {Urs Hengartner and Sue Moon and Richard Mortier and Christophe Diot},
	Booktitle = {Proceedings of the 2nd ACM SIGCOMM Workshop on Internet measurment},
	Pages = {107--112},
	Title = {Detection and analysis of routing loops in packet traces},
	Year = {2002}}

@inproceedings{tva,
	Author = {Xiaowei Yang and David Wetherall and Thomas Anderson},
	Booktitle = {Proc. of ACM SIGCOMM},
	Date-Added = {2006-12-13 15:01:23 -0800},
	Date-Modified = {2007-06-19 16:04:45 -0700},
	Local-Url = {file://localhost/Users/colin/Documents/networking%20papers/paper-YanWet.pdf},
	Title = {A {DoS}-limiting Network Architecture},
	Year = {2005}}

@inproceedings{geoloc,
	Author = {Ethan Katz-Bassett and John P. John and Arvind Krishnamurthy and David Wetherall and Thomas Anderson and Yatin Chawathe},
	Booktitle = {Proc. of International Measurements Conference},
	Title = {Towards {IP} Geolocation using Delay and Topology Measurements},
	Year = 2006}

@inproceedings{rfd-exacerbates,
	Author = {Zhuoqing Morley Mao and Ramesh Govindan and George Varghese and Randy H. Katz},
	Booktitle = {Proc. of ACM SIGCOMM},
	Date-Modified = {2007-10-08 23:15:52 -0700},
	Title = {Route flap damping exacerbates internet routing convergence},
	Year = {2002}}

@inproceedings{byzantine-routing,
	Author = {I. Avramopoulos and H. Kobayashi and R. Wang and A. Krishnamurthy},
	Booktitle = {Proceedings of Infocom},
	Title = {Highly Secure and Efficient Routing},
	Year = 2004}

@inproceedings{mtcp,
	Author = {M. Zhang and J. Lai and A. Krishnamurthy and L. Peterson and R. Wang},
	Booktitle = {Usenix Annual Technical Conference},
	Title = {A Transport Layer Approach for Improving End-to-End Performance Using Redundant Paths},
	Year = 2004}

@inproceedings{sigcomm-codons,
	Author = {Venugopalan Ramasubramanian and Emin G\&\#252;n Sirer},
	Booktitle = {Proc. of ACM SIGCOMM},
	Pages = {331--342},
	Title = {The design and implementation of a next generation name service for the internet},
	Year = {2004}}

@inproceedings{i3,
	Address = {Pittsburgh, PA},
	Author = {Ion Stoica and Daniel Adkins and Shelley Zhuang and Scott She\ nker and Sonesh Surana},
	Booktitle = {Proc. of ACM SIGCOMM},
	Month = {Aug},
	Organization = {{ACM}},
	Title = {Internet Indirection Infrastructure},
	Url = {http://www.acm.org/sigcomm/sigcomm2002/papers/i3.pdf},
	Year = {2002},
	Bdsk-Url-1 = {http://www.acm.org/sigcomm/sigcomm2002/papers/i3.pdf}}

@inproceedings{i3-ddos,
	Author = {Karthik Lakshminarayanan and Daniel Adkins and Adrian Perrig and Ion Stoica},
	Booktitle = {{Proc. of Workshop on Hot Topics in Networks}},
	Title = {Taming IP Packet Flooding Attacks},
	Year = 2003}

@inproceedings{botz4sale,
	Author = {Srikanth Kandula and Dina Katabi and Matthias Jacob and Arthur W. Berger},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Date-Modified = {2007-10-07 21:31:09 -0700},
	Title = {{Botz-4-Sale: Surviving Organized DDoS Attacks That Mimic Flash Crowds}},
	Year = {2005}}

@inproceedings{hotnetsdns,
	Author = {Hitesh Ballani and Paul Francis},
	Booktitle = {{Proc. of Workshop on Hot Topics in Networks}},
	Title = {A Simple Approach to DNS DoS Defense},
	Year = 2006}

@inproceedings{BAR,
	Author = {Amitanand S. Aiyer and Lorenzo Alvisi and Allen Clement and Michael Dahlin and Jean-Philippe Martin and Carl Porth},
	Booktitle = {{Proc. of Symposium on Operating Systems Principles}},
	Month = oct,
	Title = {BAR Fault Tolerance for Cooperative Services},
	Year = 2005}

@article{FLP,
	Author = {Michael J. Fischer and Nancy A. Lynch and Michael S. Paterson},
	Journal = {J. ACM},
	Number = {2},
	Pages = {374--382},
	Title = {Impossibility of distributed consensus with one faulty process},
	Volume = {32},
	Year = {1985}}

@article{kelly98,
	Author = {F. Kelly and A. Maulloo and D. Tan},
	Journal = {Journal of the Operational Research Society},
	Title = {Rate control in communication networks: shadow prices, proportional fairness and stability},
	Volume = {49},
	Year = {1998}}

@article{4D,
	Author = {Albert Greenberg and Gisli Hjalmtysson and David A. Maltz and Andy Myers and Jennifer Rexford and Geoffrey Xie and Hong Yan and Jibin Zhan and Hui Zhang},
	Date-Modified = {2007-10-07 20:24:27 -0700},
	Journal = {ACM SIGCOMM Computer Communication Review},
	Title = {A Clean Slate {4D} Approach to Network Control and Management},
	Year = 2005}

@inproceedings{mahajan02understanding,
	Author = {Ratul Mahajan and David Wetherall and Tom Anderson},
	Booktitle = {Proc. of ACM SIGCOMM},
	Doi = {http://doi.acm.org/10.1145/633025.633027},
	Pages = {3--16},
	Title = {{Understanding BGP misconfiguration}},
	Year = {2002},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/633025.633027}}

@inproceedings{GENIsecurity,
	Author = {T. Anderson and M. Reiter},
	Booktitle = {{GENI Design Document 06-23}},
	Title = {{GENI Facility Security}},
	Year = 2006}

@misc{AS7007,
	Author = {V. J. Bono},
	Howpublished = {http://www.merit.edu/mail.archives/nanog/1997-04/msg00444.html},
	Key = {AS7007},
	Month = {April},
	Title = {{7007 Explanation and Apology}},
	Year = {1997}}

@inproceedings{zhao01analysis,
	Author = {Xiaoliang Zhao and Dan Pei and Lan Wang and Dan Massey and Allison Mankin and S. Felix Wu and Lixia Zhang},
	Booktitle = {First ACM SIGCOMM Workshop on Internet Measurement},
	Doi = {http://doi.acm.org/10.1145/505202.505207},
	Pages = {31--35},
	Title = {{An analysis of BGP multiple origin AS (MOAS) conflicts}},
	Year = {2001},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/505202.505207}}

@article{nordstrom04beware,
	Address = {New York, NY, USA},
	Author = {Ola Nordstrm and Constantinos Dovrolis},
	Doi = {http://doi.acm.org/10.1145/997150.997152},
	Issn = {0146-4833},
	Journal = {SIGCOMM Comput. Commun. Rev.},
	Number = {2},
	Pages = {1--8},
	Publisher = {ACM Press},
	Title = {{Beware of BGP attacks}},
	Volume = {34},
	Year = {2004},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/997150.997152}}

@misc{RFD,
	Author = {C. Villamizar and R. Chandra and R. Govindan},
	Booktitle = {Network Working Group, RFC 2439},
	Month = {Nov.},
	Title = {BGP Route Flap Damping},
	Year = {1998}}

@misc{wedgies,
	Author = {T. Griffin and G. Huston},
	Howpublished = {Network Working Group, RFC 4264},
	Month = {Nov.},
	Title = {{BGP} Wedgies},
	Year = {2005}}

@inproceedings{afergan04,
	Author = {Mike Afergan and John Wroclawski},
	Booktitle = {PINS},
	Date-Modified = {2007-10-07 18:43:45 -0700},
	Pages = {197--204},
	Title = {On the benefits and feasibility of incentive based routing infrastructure},
	Year = {2004}}

@article{pei04framework,
	Author = {Dan Pei and Dan Massey and Lixia Zhang},
	Journal = {IEEE Network special issue on Protection, Restoration, and Disaster Recovery},
	Month = {April},
	Title = {{A Framework for Resilient Internet Routing Protocols}},
	Year = {2004}}

@inproceedings{tyrant,
	Author = {Michael Piatek and Tomas Isdal and Arvind Krishnamurthy and Thomas Anderson},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Title = {Do incentives build robustness in {B}it{T}orrent?},
	Year = {2007}}

@inproceedings{PHAS,
	Author = {Mohit Lad and Dan Massey and Dan Pei and Yiguo Wu and Beichuan Zhang and Lixia Zhang},
	Booktitle = {USENIX Security Symposium},
	Month = {August},
	Title = {{PHAS: a Prefix Hijack Alert System}},
	Year = {2006}}

@article{aspnes03,
	Author = {James Aspnes},
	Journal = {Distributed Computing},
	Number = {2-3},
	Pages = {165--175},
	Publisher = {Springer-Verlag},
	Title = {Randomized protocols for asynchronous consensus},
	Volume = {16},
	Year = {2003}}

@article{mostfaoui04condition,
	Address = {London, UK},
	Author = {Achour Mostfaoui and Sergio Rajsbaum and Michel Raynal and Matthieu Roy},
	Doi = {http://dx.doi.org/10.1007/s00446-003-0093-9},
	Issn = {0178-2770},
	Journal = {Distrib. Comput.},
	Number = {1},
	Pages = {1--20},
	Publisher = {Springer-Verlag},
	Title = {Condition-based consensus solvability: a hierarchy of conditions and efficient protocols},
	Volume = {17},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s00446-003-0093-9}}

@inproceedings{wendlandt06,
	Author = {D. Wendlandt and I. Avramopoulos and D. Andersen and J. Rexford},
	Booktitle = {{Proc. of Workshop on Hot Topics in Networks}},
	Month = {November},
	Title = {{Don't Secure Routing Protocols, Secure Data Delivery}},
	Year = {2006}}

@article{chandra96unreliable,
	Address = {New York, NY, USA},
	Author = {Tushar Deepak Chandra and Sam Toueg},
	Doi = {http://doi.acm.org/10.1145/226643.226647},
	Issn = {0004-5411},
	Journal = {J. ACM},
	Number = {2},
	Pages = {225--267},
	Publisher = {ACM Press},
	Title = {Unreliable failure detectors for reliable distributed systems},
	Volume = {43},
	Year = {1996},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/226643.226647}}

@article{dolev93,
	Author = {Danny Dolev and Cynthia Dwork and Orli Waarts and Moti Yung},
	Journal = {J. ACM},
	Number = {1},
	Pages = {17--47},
	Title = {Perfectly secure message transmission},
	Volume = {40},
	Year = {1993}}

@article{dolev81,
	Author = {Danny Dolev},
	Journal = {J. ACM},
	Pages = {14--30},
	Title = {The Byzantine Generals strike again},
	Year = {1981}}

@article{beimel05,
	Author = {Amos Beimel and Lior Malka},
	Journal = {Distrib. Comput.},
	Number = {1},
	Pages = {1--19},
	Title = {Efficient reliable communication over partially authenticated networks},
	Volume = {18},
	Year = {2005}}

@article{gibbens99resource,
	Author = {R. J. Gibbens and F. P. Kelly},
	Journal = {Automatica},
	Title = {{Resource pricing and the evolution of congestion control}},
	Volume = {35},
	Year = {1999}}

@inproceedings{kokku07multipath,
	Author = {{R. Kokku and A. Bohra and S. Ganguly and A. Venkataramani}},
	Booktitle = {IEEE Infocom},
	Month = {May},
	Title = {A Multipath Background Network Architecture},
	Year = {2007}}

@inproceedings{perrig05clean,
	Author = {Adrian Perrig and Steven Bellovin and David Clark and Dawn Song},
	Booktitle = {Report of an NSF workshop held at CMU},
	Month = {July},
	Title = {A Clean-Slate Design for the Next-Generation Secure Internet},
	Year = {2005}}

@misc{IPsec,
	Author = {S. Kent and R. Atkinson},
	Howpublished = {RFC 2401},
	Key = {IPsec},
	Title = {{Security Architecture for the Internet Protocol}}}

@inproceedings{pi,
	Author = {Abraham Yaar and Adrian Perrig and Dawn Song},
	Booktitle = {IEEE Symposium on Security and Privacy},
	Pages = {93},
	Title = {Pi: A Path Identification Mechanism to Defend against DDoS Attacks},
	Year = {2003}}

@misc{syncookie,
	Author = {D. J. Bernstein},
	Howpublished = {http://cr.yp.to/syncookies.html},
	Key = {syncookie},
	Title = {{SYN Cookies}}}

@inproceedings{guirguis05reduction,
	Author = {Mina Guirguis and Azer Bestavros and Ibrahim Matta and Yuting Zhang},
	Booktitle = {IEEE INFOCOM},
	Month = {March},
	Title = {{Reduction of Quality (RoQ) Attacks on Internet End-Systems}},
	Year = {2005}}

@misc{dosmafia,
	Author = {K. Poulsen},
	Howpublished = {http://www.securityfocus.com/news/9411},
	Key = {dosmafia},
	Title = {{FBI Busts Alleged DoS Mafia}}}

@misc{hellweg04,
	Author = {E. Hellweg},
	Howpublished = {MIT TechnologyReview},
	Key = {hellweg04},
	Month = {September},
	Title = {{When BotNets Attack}},
	Year = {2004}}

@article{adler05,
	Author = {Micah Adler},
	Journal = {J. ACM},
	Number = {2},
	Pages = {217--244},
	Title = {{Trade-offs in probabilistic packet marking for IP traceback}},
	Volume = {52},
	Year = {2005}}

@inproceedings{SANE,
	Author = {Martin Casado and Tal Garfinkel and Aditya Akella and Michael Freedman and Dan Boneh and Nick McKweon and Scott Shenker},
	Booktitle = {USENIX Security Symposium},
	Title = {{SANE: A Protection Architecture for Enterprise Networks}},
	Year = {2006}}

@inproceedings{sybilguard,
	Author = {Haifeng Yu and Michael Kaminsky and Phillip B. Gibbons and Abraham Flaxman},
	Booktitle = {Proc. of ACM SIGCOMM},
	Pages = {267--278},
	Title = {SybilGuard: defending against sybil attacks via social networks},
	Year = {2006}}

@misc{dnssec,
	Author = {R. Arends and R. Austein and M. Larson and D. Massey and S. Rose},
	Booktitle = {RFC 4033},
	Month = {March},
	Title = {{DNS Security Introduction and Requirements}},
	Year = {2005}}

@inproceedings{flowcookies,
	Author = {Martin Casado, Pei Cao, Aditya Akella and Neils Provos},
	Booktitle = {IWQoS},
	Title = {Flow Cookies: Using Bandwidth Amplification to Defend Against DDoS Flooding Attacks},
	Year = {2006}}

@inproceedings{VINI,
	Author = {Andy Bavier and Nick Feamster and Mark Huang and Larry Peterson and Jennifer Rexford},
	Booktitle = {Proc. of ACM SIGCOMM},
	Location = {Pisa, Italy},
	Pages = {3--14},
	Title = {In VINI veritas: realistic and controlled network experimentation},
	Year = {2006}}

@misc{GENI,
	Howpublished = {http://www.geni.net/},
	Key = {GENI},
	Title = {{Global Network for Network Innovations}}}

@techreport{ssn,
	Author = {Thomas Anderson and Arun Venkataramani},
	Institution = {UMass Amherst},
	Month = {August},
	Number = {TR-06-43},
	Title = {{Social Security for the Internet}},
	Year = {2006}}

@article{kellyMP,
	Author = {Frank Kelly and Thomas Voice},
	Journal = {SIGCOMM Comput. Commun. Rev.},
	Number = {2},
	Pages = {5--12},
	Title = {Stability of end-to-end algorithms for joint routing and rate control},
	Volume = {35},
	Year = {2005}}

@inproceedings{awerbuch,
	Author = {Baruch Awerbuch and David Holmer and Cristina Nita-Rotaru and Herbert Rubens},
	Booktitle = {WiSE '02: Proceedings of the 3rd ACM workshop on Wireless security},
	Pages = {21--30},
	Title = {An on-demand secure routing protocol resilient to byzantine failures},
	Year = {2002}}

@inproceedings{terry95,
	Author = {D. Terry and M. Theimer and K. Petersen and A. Demers and M. Spreitzer and C. Hauser},
	Booktitle = {{Proc. of Symposium on Operating Systems Principles}},
	Month = Dec,
	Title = {{Managing Update Conflicts in Bayou, a Weakly Connected Replicated Storage System}},
	Year = 1995}

@article{dahlin-failure-TON03,
	Author = {M. Dahlin and B. Chandra and L. Gao and A. Nayate},
	Journal = {IEEE/ACM Transactions on Networking},
	Title = {End-to-end WAN Service Availability},
	Year = 2003}

@article{deshpande04,
	Author = {Deshpande, S. and Sikdar, B.},
	Date-Modified = {2007-10-07 20:23:15 -0700},
	Journal = {GLOBECOM},
	Title = {{On the impact of route processing and MRAI timers on BGP convergence times}},
	Year = {2004}}

@inproceedings{griffin01,
	Author = {T. Griffin and B. Premore},
	Booktitle = {ICNP},
	Date-Modified = {2007-10-08 23:12:47 -0700},
	Title = {{An Experimental Analysis of BGP Convergence Time}},
	Year = {2001}}

@article{qiu04,
	Author = {Jian Qiu and Ruibing Hao and Xing Li},
	Date-Modified = {2007-10-07 21:43:04 -0700},
	Journal = {IEICE Transactions on Communications},
	Month = {September},
	Number = 4,
	Pages = {1338--1346},
	Title = {The Optimal Rate-Limiting Timer of {BGP} for Routing Convergence},
	Volume = {E88-B},
	Year = {2004}}

@inproceedings{PBFT,
	Author = {Miguel Castro and Barbara Liskov},
	Booktitle = {Proc. of Operatings System Design and Implementation},
	Date-Modified = {2007-10-07 20:22:09 -0700},
	Title = {Practical Byzantine fault tolerance},
	Year = {1999}}

@conference{QU,
	Author = {Michael Abd-El-Malek and Gregory R. Ganger and Garth R. Goodson and Michael K. Reiter and Jay J. Wylie},
	Booktitle = {{Proc. of Symposium on Operating Systems Principles}},
	Date-Modified = {2007-10-07 20:21:33 -0700},
	Rating = {5},
	Read = {No},
	Title = {Fault-scalable Byzantine fault-tolerant services},
	Year = {2005}}

@article{quoitin03interdomain,
	Author = {B. Quoitin and S. Uhlig and C. Pelsser and L. Swinnen and O. Bonaventure},
	Journal = {IEEE Communications Magazine},
	Title = {Interdomain traffic engineering with {BGP}},
	Url = {citeseer.ist.psu.edu/quoitin03interdomain.html},
	Year = {2003},
	Bdsk-Url-1 = {citeseer.ist.psu.edu/quoitin03interdomain.html}}

@inproceedings{consistency-assertions,
	Author = {D. Pei and X. Zhao and L. Wang and D. Massey and A. Mankin and S. Wu and L. Zhang},
	Booktitle = {IEEE INFOCOM},
	Text = {D. Pei, X. Zhao, L. Wang, D. Massey, A. Mankin, S. F. Wu, and L. Zhang. Improving BGP Convergence Through Consistency Assertions. Submitted for Publication, 2001.},
	Title = {Improving {BGP} Convergence Through Consistency Assertions},
	Url = {citeseer.ist.psu.edu/pei02improving.html},
	Year = {2001},
	Bdsk-Url-1 = {citeseer.ist.psu.edu/pei02improving.html}}

@inproceedings{kplane,
	Author = {David D. Clark and Craig Partridge and J. Christopher Ramming and John T. Wroclawski},
	Booktitle = {SIGCOMM},
	Date-Added = {2006-04-24 03:10:35 -0700},
	Date-Modified = {2006-04-24 18:54:47 -0700},
	Title = {A knowledge plane for the {I}nternet},
	Year = {2003}}

@techreport{spring-alias,
	Author = {Neil Spring and Mira Dontcheva and Maya Rodrig and David Wetherall},
	Date-Modified = {2008-02-13 21:55:43 -0700},
	Institution = {{Univ. of Washington}},
	Title = {How to Resolve {IP} Aliases,},
	Year = 2004}

@article{shed-light,
	Author = {Franck Le and Geoffrey G. Xie and Dan Pei and Jia Wang and Hui Zhang},
	Journal = {SIGCOMM Comput. Commun. Rev.},
	Number = {4},
	Pages = {39--50},
	Publisher = {ACM},
	Title = {Shedding light on the glue logic of the internet routing architecture},
	Volume = {38},
	Year = {2008}}

@inproceedings{nexit,
	Author = {Ratul Mahajan and David Wetherall and Thomas E. Anderson},
	Booktitle = {NSDI},
	Title = {{Negotiation-Based Routing Between Neighboring ISPs}},
	Year = {2005}}

@inproceedings{mit-ron,
	Author = {David G. Anderson and Hari Balakrishnan and M. Frans Kaawhoek and Robert Morris},
	Booktitle = {SOSP},
	Date-Modified = {2007-10-09 05:19:01 -0700},
	Title = {{Resilient Overlay Networks}},
	Year = 2001}

@inproceedings{ohsr,
	Author = {Krishna P. Gummadi and Harsha V. Madhyastha and Steven D. Gribble and Henry M. Levy and David Wetherall},
	Booktitle = {OSDI},
	Date-Modified = {2007-10-09 05:09:11 -0700},
	Title = {Improving the Reliability of {I}nternet Paths with One-hop Source Routing},
	Year = {2004}}

@inproceedings{ratul,
	Author = {Ratul Mahajan and David Wetherall and Tom Anderson},
	Booktitle = {SIGCOMM},
	Date-Modified = {2007-10-09 05:25:37 -0700},
	Title = {Understanding {BGP} misconfiguration},
	Year = {2002}}

@inproceedings{beacons,
	Author = {Z. Morley Mao and Randy Bush and Timothy G. Griffin and Matthew Roughan},
	Booktitle = {IMC},
	Date-Modified = {2007-10-09 05:26:22 -0700},
	Title = {{BGP} beacons},
	Year = {2003}}

@misc{darkspaces,
	Author = {C. Labovitz and Abha Ahuja and Michael Bailey},
	Date-Modified = {2013-01-31 23:43:32 +0000},
	Howpublished = {\url{http://web.eecs.umich.edu/~mibailey/publications/dark_address_space.pdf}},
	Title = {{Shining Light on Dark Address Space}},
	Year = {2001}}

@inproceedings{kompella-infocom,
	Author = {Ramana Kompella and Jennifer Yates and Albert Greenberg and Alex Snoeren},
	Booktitle = {INFOCOM},
	Date-Modified = {2008-02-13 21:59:07 -0700},
	Title = {Detection and Localization of Network Black Holes},
	Year = 2007}

@misc{awduche,
	Author = {D. Awduche and A. Chiu and A. Elwalid and I. Widjaja and X. Xiao},
	Key = {Awduche},
	Title = {Overview and Principles of Internet Traffic Engineering, RFC-3272},
	Year = {2002}}

@article{quoitin,
	Author = {B. Quoitin and S. Uhlig and C. Pelsser and L. Swinnen and O. Bonaventure},
	Journal = {IEEE Communications Magazine},
	Pages = {122--128},
	Title = {Interdomain traffic engineering with BGP},
	Volume = {41},
	Year = {2003}}

@inproceedings{FGHK02,
	Author = {A. Fiat and A. Goldberg and J. Hartline},
	Booktitle = {{Proceedings of 34th ACM Symposium on Theory of Computing}},
	Title = {{Generalized Competitive Auctions}},
	Year = 2002}

@inproceedings{DGHK02,
	Author = {K. Deshmukh and A. Goldberg and J. Hartline and A. Karlin},
	Booktitle = {{Proceedings of European Symposium on Algorithms}},
	Title = {{Truthful and Competitive Market Clearing}},
	Year = 2002}

@inproceedings{GHKS04,
	Author = {A. Goldberg and J. Hartline and A. Karlin and M. Saks},
	Booktitle = {{21st Symposium on Theoretical Aspects of Computer Science}},
	Title = {{A Lower Bound on the Competitive Ratio of Truthful Auctions}},
	Year = 2004}

@inproceedings{GHKKKM05,
	Author = {V. Guruswami and J. Hartline and A. Karlin and D. Kempe and C. Kenyon and F. McSherry},
	Booktitle = {{Proceedings of 16th ACM Symposium on Discrete Algorithms}},
	Title = {{On Profit-Maximizing Envy-Free Pricing}},
	Year = 2005}

@inproceedings{KKT05,
	Author = {A. Karlin and D. Kempe and T. Tamir},
	Booktitle = {{Proceedings of 46th IEEE Conference on Foundations of Computer Science}},
	Title = {{Beyond VCG: Frugality in Truthful Mechanisms}},
	Year = 2005}

@article{GHKSW06,
	Author = {A. Goldberg and J. Hartline and A. Karlin and M. Saks and A. Wright},
	Journal = {{Games and Economic Behavior}},
	Title = {{Competitive Auctions}},
	Volume = 55,
	Year = 2006}

@inproceedings{CDEGHKMS07,
	Author = {M. Cary and A. Das and B. Edelman and I. Giotis and K. Heimerl and A. Karlin and C. Mathieu and M. Schwarz},
	Booktitle = {{ACM Conference on Electronic Commerce}},
	Title = {{Greedy Bidding Strategies for Keyword Auctions}},
	Year = 2007}

@inproceedings{IKMT07,
	Author = {N. Immorlica and A. Karlin and M. Mahdian and K. Talwar},
	Booktitle = {{Proceedings of 48th IEEE Conference on Foundations of Computer Science}},
	Title = {{Balloon Popping with Applications to Ascending Auctions}},
	Year = 2007}

@inproceedings{CK07,
	Author = {N. Chen and A. Karlin},
	Booktitle = {{Proceedings of ACM-SIAM Symposium on Discrete Algorithms}},
	Title = {{Cheap Labor Can Be Expensive}},
	Year = 2007}

@inproceedings{CFHK08,
	Author = {M. Cary and A. Flaxman and J. Hartline and A. Karlin},
	Booktitle = {{Proceedings of ACM-SIAM Symposium on Discrete Algorithms}},
	Title = {{Auctions for Structured Procurement}},
	Year = 2008}

@inproceedings{ABKN08,
	Author = {Y. Azar and B. Birnbaum and A. Karlin and C. Thach Nguyen},
	Booktitle = {{Unpublished manuscript}},
	Title = {{Thinking Twice about Second-Price Ad Auctions}},
	Year = 2008}

@inproceedings{ABKMN08,
	Author = {Y. Azar and B. Birnbaum and A. Karlin and C. Mathieu and C. Thach Nguyen},
	Booktitle = {{In 35th International Colloquium on Automata, Languages and Programming}},
	Title = {{Improved Approximation Algorithms for Budgeted Allocations}},
	Year = 2008}

@inproceedings{GK08,
	Author = {Y. Giotis and A. Karlin},
	Booktitle = {{Workshop on Internet and Network Economics}},
	Title = {{On the equilibria and efficiency of the GSP mechanism in keyword auctions with externalities}},
	Year = 2008}

@inproceedings{DGKM08,
	Author = {A. Das and Y. Giotis and A. Karlin and C. Mathieu},
	Booktitle = {{Unpublished manuscript}},
	Title = {{On the Effects of Competing Advertisements in Keyword Auctions}},
	Year = 2008}

@inproceedings{ACKLMNX07,
	Author = {Esteban Arcaute and Ning Chen and Ravi Kumar and David Liben-Nowell and Mohammad Mahdian and Hamid Nazerzadeh and Ying Xu},
	Booktitle = {{Workshop on Algorithms and Models for the Web-Graph}},
	Title = {{Deterministic Decentralized Search in Random Graphs}},
	Year = 2007}

@inproceedings{CENRRS07,
	Author = {Ning Chen and Roee Engelberg and C. Thach Nguyen and Prasad Raghavendra and Atri Rudra and Gyanit Singh},
	Booktitle = {{International Workshop on Approximation Algorithms for Combinatorial Optimization Problems}},
	Title = {{Improved Approximation Algorithms for the Spanning Star Forest Problem}},
	Year = 2007}

@inproceedings{BCCRSS07,
	Author = {Nikhil Bansal and Ning Chen and Neva Cherniavsky and Atri Rudra and Baruch Schieber and Maxim Sviridenko},
	Booktitle = {{ACM-SIAM Symposium on Discrete Algorithms}},
	Title = {{Dynamic Pricing for Impatient Bidders}},
	Year = 2007}

@inproceedings{NGV08,
	Author = {Ning Chen and Arpita Ghosh and Sergei Vassilvitskii},
	Booktitle = {{ACM Conference on Electronic Commerce}},
	Title = {{Optimal Envy-free Pricing with Metric Substitutability}},
	Year = 2008}

@inproceedings{C08,
	Author = {Ning Chen},
	Booktitle = {{ACM-SIAM Symposium on Discrete Algorithms}},
	Title = {{On the Approximability of Influence in Social Networks}},
	Year = 2008}

@inproceedings{botnets,
	Author = {J. John and A. Moshchuk and S. Gribble and A. Krishnamurthy},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Title = {{Studying Spamming Botnets using Botlab}},
	Year = 2009}

@inproceedings{p4p,
	Author = {H. Xie and R. Yang and A. Krishnamurthy and Y. Liu and A. Silberschatz},
	Booktitle = {Proceedings of SIGCOMM},
	Title = {{P4P: Provider Portal for (P2P) Applications}},
	Year = 2008}

@inproceedings{adeona,
	Author = {T. Ristenpart and G. Maganis and A. Krishnamurthy and T. Kohno},
	Booktitle = {Proceedings of Usenix Security},
	Title = {{Privacy-Preserving Location Tracking of Lost or Stolen Devices: Cryptographic Techniques and Replacing Trusted Third Parties with DHTs}},
	Year = 2008}

@inproceedings{onehop,
	Author = {M. Piatek and T. Isdal and A. Krishnamurthy and T. Anderson},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Title = {{One hop Reputations for Peer-to-Peer File Sharing Workloads}},
	Year = 2008}

@inproceedings{phalanx,
	Author = {C. Dixon and T. Anderson and A. Krishnamurthy},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Title = {{Phalanx: Withstanding multimillion-node botnets}},
	Year = 2008}

@inproceedings{structural-imc,
	Author = {H. Madhyastha and T. Anderson and A. Krishnamurthy and N. Spring and A. Venkataramani},
	Booktitle = {{Proceedings of Internet Measurement Conference}},
	Title = {{A Structural Approach to Latency Prediction}},
	Year = 2006}

@inproceedings{pcp,
	Author = {T. Anderson and A. Collins and A. Krishnamurthy and J. Zahorjan},
	Booktitle = {{Proc. of Networked Systems Design and Implementation}},
	Title = {{PCP: Efficient Endpoint Congestion Control}},
	Year = 2006}

@inproceedings{teixeira,
	Author = {Renata Teixeira and Jennifer Rexford},
	Booktitle = {ACM SIGCOMM workshop on Network Troubleshooting},
	Date-Modified = {2007-10-09 05:28:52 -0700},
	Title = {A measurement framework for pin-pointing routing changes},
	Year = {2004}}

@inproceedings{lifeguard,
	Author = {Katz-Bassett, Ethan and Scott, Colin and Choffnes, David R. and Cunha, \'{I}talo and Valancius, Vytautas and Feamster, Nick and Madhyastha, Harsha V. and Anderson, Thomas and Krishnamurthy, Arvind},
	Booktitle = {SIGCOMM},
	Optacmid = {2342435},
	Optaddress = {New York, NY, USA},
	Optdoi = {10.1145/2342356.2342435},
	Optisbn = {978-1-4503-1419-0},
	Optkeywords = {availability, bgp, internet, measurement, outages, repair, routing},
	Optlocation = {Helsinki, Finland},
	Optnumpages = {12},
	Optpages = {395--406},
	Optpublisher = {ACM},
	Optseries = {SIGCOMM '12},
	Opturl = {http://doi.acm.org/10.1145/2342356.2342435},
	Title = {{LIFEGUARD}: {P}ractical repair of persistent route failures},
	Year = {2012}}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>Group</string>
		<key>keys</key>
		<string></string>
	</dict>
</array>
</plist>
}}
